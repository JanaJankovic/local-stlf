{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "017dc145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyWavelets\n",
      "  Downloading pywavelets-1.8.0-cp310-cp310-win_amd64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\janav\\.pyenv\\pyenv-win\\versions\\3.10.6\\lib\\site-packages (from PyWavelets) (2.1.2)\n",
      "Downloading pywavelets-1.8.0-cp310-cp310-win_amd64.whl (4.2 MB)\n",
      "   ---------------------------------------- 0.0/4.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.2/4.2 MB 50.7 MB/s eta 0:00:00\n",
      "Installing collected packages: PyWavelets\n",
      "Successfully installed PyWavelets-1.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\janav\\.pyenv\\pyenv-win\\versions\\3.10.6\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\janav\\.pyenv\\pyenv-win\\versions\\3.10.6\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\janav\\.pyenv\\pyenv-win\\versions\\3.10.6\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install PyWavelets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19a3a481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model' from 'c:\\\\Users\\\\janav\\\\Documents\\\\load forecasting\\\\local-stlf\\\\wavelet-transform\\\\model.py'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import model \n",
    "importlib.reload(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d0d60fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "from model import SwtForecastingModel, swt_decompose, swt_reconstruct, EarlyStopping\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7696dc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# --- DEVICE SETUP ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"🚀 Using device: {DEVICE}\")\n",
    "\n",
    "# --- DECOMPOSITION ---\n",
    "def decompose_batch(batch, level=2):\n",
    "    required_multiple = 2 ** level\n",
    "    bands = [[] for _ in range(4)]\n",
    "    for seq in batch:\n",
    "        seq = np.asarray(seq).flatten()\n",
    "        valid_len = (len(seq) // required_multiple) * required_multiple\n",
    "        if valid_len % 2 != 0:\n",
    "            valid_len -= 1\n",
    "        seq = seq[:valid_len]\n",
    "        coeffs = swt_decompose(seq, level=level)\n",
    "        a2, d2 = coeffs[0]\n",
    "        d1 = coeffs[1][1]\n",
    "        zero_pad = np.zeros_like(d1)\n",
    "        for i, band in enumerate([a2, d2, d1, zero_pad]):\n",
    "            bands[i].append(band)\n",
    "    return [torch.tensor(np.array(b), dtype=torch.float32).unsqueeze(-1).to(DEVICE) for b in bands]\n",
    "\n",
    "def decompose_targets(batch, level=2):\n",
    "    bands = [[] for _ in range(4)]\n",
    "    for seq in batch:\n",
    "        seq = np.asarray(seq).flatten()\n",
    "        valid_len = (len(seq) // (2 ** level)) * (2 ** level)\n",
    "        seq = seq[:valid_len]\n",
    "        coeffs = swt_decompose(seq, level=level)\n",
    "        a2, d2 = coeffs[0]\n",
    "        d1 = coeffs[1][1]\n",
    "        zero_pad = np.zeros_like(d1)\n",
    "        for i, band in enumerate([a2, d2, d1, zero_pad]):\n",
    "            bands[i].append(band)\n",
    "    return [torch.tensor(np.array(b), dtype=torch.float32).unsqueeze(-1).to(DEVICE) for b in bands]\n",
    "\n",
    "# --- CONFIG ---\n",
    "args = {\n",
    "    \"t\": 0.2,\n",
    "    \"s\": 24,\n",
    "    \"w\": 48,\n",
    "    \"level\": 3\n",
    "}\n",
    "\n",
    "# --- DATA LOADING ---\n",
    "df = pd.read_csv(\"mm79158.csv\", parse_dates=['ts'])\n",
    "df.set_index('ts', inplace=True)\n",
    "data = df['vrednost'].values.reshape(-1, 1)\n",
    "\n",
    "X_raw, y_raw = [], []\n",
    "for i in range(len(data) - args['w'] - args['s'] + 1):\n",
    "    X_raw.append(data[i:i + args['w']])\n",
    "    y_raw.append(data[i + args['w']:i + args['w'] + args['s']])\n",
    "\n",
    "X_raw = np.array(X_raw)\n",
    "y_raw = np.array(y_raw)\n",
    "\n",
    "# --- SPLIT ---\n",
    "test_size = int(len(X_raw) * args['t'])\n",
    "val_size = test_size\n",
    "train_size = len(X_raw) - test_size - val_size\n",
    "\n",
    "X_train, y_train = X_raw[:train_size], y_raw[:train_size]\n",
    "X_val, y_val = X_raw[train_size:train_size + val_size], y_raw[train_size:train_size + val_size]\n",
    "X_test, y_test = X_raw[train_size + val_size:], y_raw[train_size + val_size:]\n",
    "\n",
    "# --- SCALE ---\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train.reshape(-1, 1)).reshape(X_train.shape)\n",
    "X_val = scaler.transform(X_val.reshape(-1, 1)).reshape(X_val.shape)\n",
    "X_test = scaler.transform(X_test.reshape(-1, 1)).reshape(X_test.shape)\n",
    "\n",
    "# --- DECOMPOSE ---\n",
    "X_train_tensors = decompose_batch(X_train, level=args['level'])\n",
    "X_val_tensors = decompose_batch(X_val, level=args['level'])\n",
    "X_test_tensors = decompose_batch(X_test, level=args['level'])\n",
    "\n",
    "y_train_tensors = decompose_targets(y_train, level=args['level'])\n",
    "y_val_tensors = decompose_targets(y_val, level=args['level'])\n",
    "\n",
    "# --- DATASET ---\n",
    "train_dataset = TensorDataset(*X_train_tensors, *y_train_tensors)\n",
    "val_dataset = TensorDataset(*X_val_tensors, *y_val_tensors)\n",
    "\n",
    "test_dataset = TensorDataset(*X_test_tensors, torch.tensor(y_test, dtype=torch.float32).to(DEVICE))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "# --- MODEL ---\n",
    "model = SwtForecastingModel(\n",
    "    input_size=1,\n",
    "    time2vec_k=8,\n",
    "    d_model=480,\n",
    "    n_heads=12,\n",
    "    d_ff=128,\n",
    "    n_enc_layers=2,\n",
    "    n_dec_layers=1,\n",
    "    forecast_steps=args['s'],\n",
    "    output_bands=len(X_train_tensors)\n",
    ").to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a85d1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01/30\n",
      " - Batch 284/284 - loss: 3.468350\n",
      "[Epoch 01] Train loss: 4.179733 | Val loss: 4.885832\n",
      "\n",
      "Epoch 02/30\n",
      " - Batch 284/284 - loss: 3.596560\n",
      "[Epoch 02] Train loss: 3.669994 | Val loss: 4.904720\n",
      "\n",
      "Epoch 03/30\n",
      " - Batch 284/284 - loss: 3.438471\n",
      "[Epoch 03] Train loss: 3.668981 | Val loss: 4.928848\n",
      "\n",
      "Epoch 04/30\n",
      " - Batch 267/284 - loss: 4.194942"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     36\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 37\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m y_stack\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Print mini-batch progress\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m - Batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_batches\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = SwtForecastingModel(\n",
    "    input_size=1,\n",
    "    time2vec_k=8,\n",
    "    d_model=480,\n",
    "    n_heads=12,\n",
    "    d_ff=128,\n",
    "    n_enc_layers=2,\n",
    "    n_dec_layers=1,\n",
    "    forecast_steps=args['s'],\n",
    "    output_bands=len(X_train_tensors)  # e.g., 4 for [(A2, D2), (A1, D1)]\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "early_stopper = EarlyStopping(patience=10, min_delta=1e-4)\n",
    "\n",
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    num_batches = len(train_loader)\n",
    "    print(f\"\\nEpoch {epoch+1:02d}/{30}\")\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        num_bands = len(batch) // 2\n",
    "        x_band_tensor = [x.to(DEVICE) for x in batch[:num_bands]]\n",
    "        y_band_tensor = [y.to(DEVICE) for y in batch[num_bands:]]\n",
    "\n",
    "        x_stack = torch.stack(x_band_tensor, dim=1)  # [B, bands, W, 1]\n",
    "        y_stack = torch.stack(y_band_tensor, dim=1)  # [B, bands, s, 1]\n",
    "\n",
    "        preds = model(x_stack)  # [B, bands, s, 1]\n",
    "        loss = loss_fn(preds, y_stack)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * y_stack.size(0)\n",
    "\n",
    "        # Print mini-batch progress\n",
    "        print(f\"\\r - Batch {batch_idx+1}/{num_batches} - loss: {loss.item():.6f}\", end=\"\")\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # === Validation ===\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            num_bands = len(batch) // 2\n",
    "            x_band_tensor = [x.to(DEVICE) for x in batch[:num_bands]]\n",
    "            y_band_tensor = [y.to(DEVICE) for y in batch[num_bands:]]\n",
    "\n",
    "            x_stack = torch.stack(x_band_tensor, dim=1)  # [B, bands, W, 1]\n",
    "            y_stack = torch.stack(y_band_tensor, dim=1)  # [B, bands, s, 1]\n",
    "\n",
    "            preds = model(x_stack)\n",
    "            loss = loss_fn(preds, y_stack)\n",
    "            val_loss += loss.item() * y_stack.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "\n",
    "    print(f\"\\n[Epoch {epoch+1:02d}] Train loss: {train_loss:.6f} | Val loss: {val_loss:.6f}\")\n",
    "\n",
    "    early_stopper(val_loss, model)\n",
    "    if early_stopper.early_stop:\n",
    "        print(\"⏹️ Early stopping triggered.\")\n",
    "        model.load_state_dict(early_stopper.best_state_dict)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd4619be",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "632efe91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SwtForecastingModel(\n",
       "  (core): SwtTransformerCore(\n",
       "    (time2vec): Time2Vec(\n",
       "      (w0): Linear(in_features=1, out_features=1, bias=True)\n",
       "      (wp): Linear(in_features=1, out_features=7, bias=True)\n",
       "    )\n",
       "    (proj): Linear(in_features=8, out_features=480, bias=True)\n",
       "    (encoder_stack): ModuleList(\n",
       "      (0-1): 2 x EncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=480, out_features=480, bias=True)\n",
       "        )\n",
       "        (dropout_attn): Dropout(p=0.1, inplace=False)\n",
       "        (norm_attn): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff1): FeedForward(\n",
       "          (linear1): Linear(in_features=480, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=128, out_features=480, bias=True)\n",
       "        )\n",
       "        (dropout_ff1): Dropout(p=0.1, inplace=False)\n",
       "        (norm_ff1): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff2): FeedForward(\n",
       "          (linear1): Linear(in_features=480, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=128, out_features=480, bias=True)\n",
       "        )\n",
       "        (dropout_ff2): Dropout(p=0.1, inplace=False)\n",
       "        (norm_ff2): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (decoder_stack): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=480, out_features=480, bias=True)\n",
       "        )\n",
       "        (dropout_attn): Dropout(p=0.1, inplace=False)\n",
       "        (norm_attn): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff1): FeedForward(\n",
       "          (linear1): Linear(in_features=480, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=128, out_features=480, bias=True)\n",
       "        )\n",
       "        (dropout_ff1): Dropout(p=0.1, inplace=False)\n",
       "        (norm_ff1): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (global_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "    (head): Sequential(\n",
       "      (0): Dropout(p=0.1, inplace=False)\n",
       "      (1): Linear(in_features=480, out_features=480, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "      (4): Linear(in_features=480, out_features=24, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SwtForecastingModel(\n",
    "    input_size=1,\n",
    "    time2vec_k=8,\n",
    "    d_model=480,\n",
    "    n_heads=12,\n",
    "    d_ff=128,\n",
    "    n_enc_layers=2,\n",
    "    n_dec_layers=1,\n",
    "    forecast_steps=args['s'],\n",
    "    output_bands=len(X_train_tensors)  # e.g., 4 for [(A2, D2), (A1, D1)]\n",
    ").to(DEVICE)\n",
    "model.load_state_dict(torch.load(\"model_weights.pth\"))\n",
    "model.to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90dec3c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;241m*\u001b[39mx_bands, y_batch \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;66;03m# === Predict and squeeze to [B, bands, s]\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_bands\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [B, bands, s]\u001b[39;00m\n\u001b[0;32m      9\u001b[0m         B, bands, s \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(B):\n\u001b[0;32m     12\u001b[0m             \u001b[38;5;66;03m# Prepare coefficients for swt_reconstruct\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\janav\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\janav\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\janav\\Documents\\load forecasting\\local-stlf\\wavelet-transform\\model.py:115\u001b[0m, in \u001b[0;36mSwtForecastingModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;66;03m# x: [B, bands, W, 1]\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     B, bands, W, _ \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[0;32m    116\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(B \u001b[38;5;241m*\u001b[39m bands, W, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten bands into batch dimension\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcore(x)  \u001b[38;5;66;03m# [B * bands, s, 1]\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "preds = []\n",
    "y_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for *x_bands, y_batch in test_loader:\n",
    "        # === Predict and squeeze to [B, bands, s]\n",
    "        out = model(x_bands).squeeze(-1)  # [B, bands, s]\n",
    "        B, bands, s = out.shape\n",
    "\n",
    "        for b in range(B):\n",
    "            # Prepare coefficients for swt_reconstruct\n",
    "            band_preds = out[b].detach().cpu().numpy()  # [bands, s]\n",
    "\n",
    "            # Assume SWT level = 2, so we reverse engineer coeffs\n",
    "            # Format: [(a2, d2), (a1, d1), ...]\n",
    "            coeffs = []\n",
    "            if bands >= 3:\n",
    "                # Build from predicted subbands\n",
    "                a2 = band_preds[0]\n",
    "                d2 = band_preds[1]\n",
    "                d1 = band_preds[2]\n",
    "                a1 = np.zeros_like(d1)\n",
    "                coeffs = [(a2, d2), (a1, d1)]\n",
    "            else:\n",
    "                raise ValueError(\"At least 3 bands are needed for reconstruction.\")\n",
    "\n",
    "            # Optional: add more levels if you're using level > 2\n",
    "\n",
    "            # === Reconstruct signal\n",
    "            recon = swt_reconstruct(coeffs)  # full reconstructed sequence\n",
    "            recon_tensor = torch.tensor(recon[-args['s']:], dtype=torch.float32)  # last `s` steps\n",
    "\n",
    "            # === Inverse scale\n",
    "            recon_unscaled = scaler.inverse_transform(recon_tensor.view(-1, 1)).flatten()\n",
    "            preds.append(torch.tensor(recon_unscaled, dtype=torch.float32))\n",
    "\n",
    "            # === Unscale ground truth\n",
    "            y_true_cpu = y_batch[b].detach().cpu().view(-1, 1).numpy()\n",
    "            y_true.append(torch.tensor(y_true_cpu, dtype=torch.float32))\n",
    "\n",
    "# === Stack & Evaluate\n",
    "preds = torch.stack(preds)  # [B, s]\n",
    "y_true = torch.stack(y_true)  # [B, s]\n",
    "\n",
    "preds_flat = preds.reshape(-1).numpy()\n",
    "y_true_flat = y_true.reshape(-1).numpy()\n",
    "\n",
    "mae = mean_absolute_error(y_true_flat, preds_flat)\n",
    "mse = mean_squared_error(y_true_flat, preds_flat)\n",
    "mape = mean_absolute_percentage_error(y_true_flat, preds_flat)\n",
    "\n",
    "print(\"\\n📊 Final Flattened Evaluation:\")\n",
    "print(f\"MAE:  {mae:.4f}\")\n",
    "print(f\"MSE:  {mse:.4f}\")\n",
    "print(f\"MAPE: {mape:.2%}\")\n",
    "\n",
    "# === Plot first time step of each sequence\n",
    "y_true_unrolled = y_true[:, 0]\n",
    "pred_unrolled = preds[:, 0]\n",
    "\n",
    "plt.figure(figsize=(30, 7))\n",
    "plt.plot(y_true_unrolled, color='blue', linewidth=0.5, label='True Values')\n",
    "plt.plot(pred_unrolled, color='red', linewidth=0.5, label='Predicted Values')\n",
    "plt.title(\"Predicted vs True Values per Sequence\")\n",
    "plt.xlabel(\"Forecast Step\")\n",
    "plt.ylabel(\"Rescaled Value\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
