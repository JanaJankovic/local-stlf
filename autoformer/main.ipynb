{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "357b2cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from model import AutoformerForecast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "from torch.utils.data import TensorDataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "126d19ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(load_df, weather_df):\n",
    "    load_df['hour'] = load_df['ts'].dt.floor('h')\n",
    "    hourly_load = load_df.groupby('hour')['vrednost'].sum().reset_index()\n",
    "    hourly_load.rename(columns={'hour': 'datetime', 'vrednost': 'load_kWh'}, inplace=True)\n",
    "\n",
    "    weather_df = weather_df[['datetime', 'temperature_2m', 'relative_humidity_2m',\n",
    "                             'windspeed_10m', 'winddirection_10m', 'precipitation']]\n",
    "\n",
    "    merged_df = pd.merge(hourly_load, weather_df, on='datetime', how='inner')\n",
    "    merged_df = merged_df.sort_values('datetime').reset_index(drop=True)\n",
    "    print(\"Loaded and merged data.\")\n",
    "    return merged_df\n",
    "\n",
    "def create_sequences(data, input_len=24, forecast_horizon=24):\n",
    "    load_seq = []\n",
    "    weather_hist_seq = []\n",
    "    weather_fore_seq = []\n",
    "    target_seq = []\n",
    "\n",
    "    total_len = input_len + forecast_horizon\n",
    "\n",
    "    for i in range(len(data) - total_len):\n",
    "        input_block = data[i : i + input_len]\n",
    "        forecast_block = data[i + input_len : i + total_len]\n",
    "\n",
    "        load_seq.append(input_block[:, 0])\n",
    "        weather_hist_seq.append(input_block[:, 1:])\n",
    "        weather_fore_seq.append(forecast_block[:, 1:])\n",
    "        target_seq.append(forecast_block[:, 0])\n",
    "\n",
    "    print(f\"Created {len(load_seq)} sequences of length {input_len} with horizon {forecast_horizon}.\")\n",
    "    return (\n",
    "        np.array(load_seq),\n",
    "        np.array(weather_hist_seq),\n",
    "        np.array(weather_fore_seq),\n",
    "        np.array(target_seq)\n",
    "    )\n",
    "\n",
    "def evaluate_model(model, dataloader, y_true, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for xb, wh, wf in dataloader:\n",
    "            xb, wh, wf = xb.to(device), wh.to(device), wf.to(device)\n",
    "            out = model(xb, wh, wf)[:, 0, :].cpu().numpy()\n",
    "            preds.append(out)\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    mae = mean_absolute_error(y_true, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, preds))\n",
    "    mape = mean_absolute_percentage_error(y_true, preds)\n",
    "    print(\"Evaluation results:\")\n",
    "    print(f\"MAE: {mae:.4f}, RMSE: {rmse:.4f}, MAPE: {mape:.4f}\")\n",
    "    return mae, rmse, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "581cab19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading data...\n",
      "Loaded and merged data.\n",
      "Scaled data.\n",
      "Data split into train: 21179, val: 6051, test: 3026\n",
      "Created 21131 sequences of length 24 with horizon 24.\n",
      "Created 6003 sequences of length 24 with horizon 24.\n",
      "Created 2978 sequences of length 24 with horizon 24.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(\"Loading data...\")\n",
    "df_load = pd.read_csv('mm79158.csv', parse_dates=['ts'])\n",
    "df_weather = pd.read_csv('slovenia_hourly_weather.csv', parse_dates=['datetime'])\n",
    "df = load_data(df_load, df_weather)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df[['load_kWh', 'temperature_2m', 'relative_humidity_2m',\n",
    "                                        'windspeed_10m', 'winddirection_10m', 'precipitation']])\n",
    "print(\"Scaled data.\")\n",
    "\n",
    "split_1 = int(0.7 * len(scaled_data))\n",
    "split_2 = int(0.9 * len(scaled_data))\n",
    "train_data, val_data, test_data = scaled_data[:split_1], scaled_data[split_1:split_2], scaled_data[split_2:]\n",
    "print(f\"Data split into train: {len(train_data)}, val: {len(val_data)}, test: {len(test_data)}\")\n",
    "\n",
    "seq_len = 24\n",
    "horizon = 24\n",
    "\n",
    "X_train_l, X_train_w_hist, X_train_w_fore, y_train = create_sequences(train_data, seq_len, horizon)\n",
    "X_val_l, X_val_w_hist, X_val_w_fore, y_val = create_sequences(val_data, seq_len, horizon)\n",
    "X_test_l, X_test_w_hist, X_test_w_fore, y_test = create_sequences(test_data, seq_len, horizon)\n",
    "\n",
    "# Convert to tensors\n",
    "train_ds = TensorDataset(torch.tensor(X_train_l).unsqueeze(1).float(),\n",
    "                            torch.tensor(X_train_w_hist).float(),\n",
    "                            torch.tensor(X_train_w_fore).float(),\n",
    "                            torch.tensor(y_train).float())\n",
    "\n",
    "val_ds = TensorDataset(torch.tensor(X_val_l).unsqueeze(1).float(),\n",
    "                        torch.tensor(X_val_w_hist).float(),\n",
    "                        torch.tensor(X_val_w_fore).float(),\n",
    "                        torch.tensor(y_val).float())\n",
    "\n",
    "test_ds = TensorDataset(torch.tensor(X_test_l).unsqueeze(1).float(),\n",
    "                        torch.tensor(X_test_w_hist).float(),\n",
    "                        torch.tensor(X_test_w_fore).float())\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=256, shuffle=False)\n",
    "val_loader = DataLoader(val_ds, batch_size=256)\n",
    "test_loader = DataLoader(test_ds, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2162df",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1\n",
    "num_factors = X_train_w_hist.shape[2]\n",
    "seq_len = 24\n",
    "horizon = 24\n",
    "model = AutoformerForecast(in_channels=C, num_factors=num_factors, forecast_horizon=horizon).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6bb0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training complete. Evaluating on test set...\")\n",
    "test_y_tensor = torch.tensor(y_test).float()\n",
    "evaluate_model(model, test_loader, test_y_tensor.numpy(), device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
