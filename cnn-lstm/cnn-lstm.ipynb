{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b847d17",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f60efc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# === Load and preprocess energy data ===\n",
    "df = pd.read_csv(\"mm79158.csv\", sep=';', decimal=',')\n",
    "df['ts'] = pd.to_datetime(df['ts'])\n",
    "df.set_index('ts', inplace=True)\n",
    "\n",
    "# Resample to 30-minute intervals and interpolate\n",
    "df_resampled = df.resample('30min').mean()\n",
    "df_resampled['vrednost'] = df_resampled['vrednost'].interpolate(method='time')\n",
    "\n",
    "# Extract time-based features\n",
    "df_resampled['hour_48'] = df_resampled.index.map(lambda x: (x.hour * 2 + x.minute // 30) + 1)\n",
    "df_resampled['day_of_week'] = df_resampled.index.dayofweek\n",
    "\n",
    "# === Load holidays and tag rows ===\n",
    "holidays = pd.read_csv(\"slovenian_holidays_2016_2018.csv\")\n",
    "holidays['holiday_date'] = pd.to_datetime(holidays['holiday_date'])\n",
    "holiday_set = set(holidays['holiday_date'].dt.normalize())\n",
    "df_resampled['is_holiday'] = df_resampled.index.normalize().isin(holiday_set).astype(int)\n",
    "\n",
    "# === One-hot encode hour_48, day_of_week, and is_holiday ===\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded = encoder.fit_transform(df_resampled[['hour_48', 'day_of_week', 'is_holiday']])\n",
    "encoded_df = pd.DataFrame(\n",
    "    encoded,\n",
    "    columns=encoder.get_feature_names_out(['hour_48', 'day_of_week', 'is_holiday']),\n",
    "    index=df_resampled.index\n",
    ")\n",
    "\n",
    "# === Combine with original value and sort\n",
    "df_final = pd.concat([df_resampled[['vrednost']], encoded_df], axis=1)\n",
    "df_final = df_final.sort_index(ascending=True)\n",
    "df = df_final.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cee2081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def prepare_sequences(df, input_window=48, forecast_horizon=1, val_ratio=0.1, test_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Prepares sliding window sequences for multistep forecasting and applies MinMax scaling to 'vrednost' safely.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with 'vrednost' as the first column and features after\n",
    "    - input_window: number of timesteps in the input window\n",
    "    - forecast_horizon: number of timesteps to predict\n",
    "    - val_ratio: validation size ratio\n",
    "    - test_ratio: test size ratio\n",
    "\n",
    "    Returns:\n",
    "    - X_train, y_train, X_val, y_val, X_test, y_test, vrednost_scaler\n",
    "    \"\"\"\n",
    "    df = df.copy()  # avoid modifying original\n",
    "\n",
    "    # === Step 1: Determine sizes\n",
    "    total_len = len(df) - input_window - forecast_horizon + 1\n",
    "    val_size = int(total_len * val_ratio)\n",
    "    test_size = int(total_len * test_ratio)\n",
    "    train_size = total_len - val_size - test_size\n",
    "\n",
    "    # Find raw index range for safe fitting\n",
    "    fit_end_idx = train_size + input_window\n",
    "\n",
    "    # === Step 2: Fit MinMaxScaler on 'vrednost' using only training range\n",
    "    # Fit scaler on training data only\n",
    "    vrednost_scaler = MinMaxScaler()\n",
    "    df.loc[:df.index[fit_end_idx - 1], 'vrednost'] = vrednost_scaler.fit_transform(\n",
    "        df.loc[:df.index[fit_end_idx - 1], ['vrednost']]\n",
    "    ).ravel()\n",
    "\n",
    "    # Transform validation + test data\n",
    "    df.loc[df.index[fit_end_idx:], 'vrednost'] = vrednost_scaler.transform(\n",
    "        df.loc[df.index[fit_end_idx:], ['vrednost']]\n",
    "    ).ravel()\n",
    "\n",
    "\n",
    "    # === Step 4: Generate sequences\n",
    "    values = df.values\n",
    "    X, y = [], []\n",
    "    for i in range(total_len):\n",
    "        X.append(values[i:i + input_window])\n",
    "        y.append(values[i + input_window:i + input_window + forecast_horizon, 0])  # target = 'vrednost'\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    if forecast_horizon == 1:\n",
    "        y = y.reshape(-1, 1)\n",
    "\n",
    "    # === Step 5: Final chronological split\n",
    "    X_train, y_train = X[:train_size], y[:train_size]\n",
    "    X_val, y_val = X[train_size:train_size + val_size], y[train_size:train_size + val_size]\n",
    "    X_test, y_test = X[train_size + val_size:], y[train_size + val_size:]\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, vrednost_scaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e51fdf6",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84e52686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout, LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanAbsoluteError\n",
    "\n",
    "def build_cnn_lstm_model(input_shape, output_size=1):\n",
    "    \"\"\"\n",
    "    Builds a CNN-LSTM model with up to 3 MaxPooling layers.\n",
    "    The number of pooling layers is reduced based on input sequence length\n",
    "    to avoid collapsing the sequence dimension.\n",
    "\n",
    "    Parameters:\n",
    "    - input_shape: (timesteps, features)\n",
    "    - output_size: number of forecast steps (e.g., 1, 2, 6)\n",
    "\n",
    "    Returns:\n",
    "    - compiled Keras model\n",
    "    \"\"\"\n",
    "    time_steps = input_shape[0]\n",
    "    model = Sequential()\n",
    "\n",
    "    # Conv 1\n",
    "    model.add(Conv1D(48, 3, activation='relu', padding='same', input_shape=input_shape))\n",
    "    if time_steps >= 4:\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        time_steps //= 2\n",
    "\n",
    "    # Conv 2\n",
    "    model.add(Conv1D(32, 3, activation='relu', padding='same'))\n",
    "    if time_steps >= 4:\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        time_steps //= 2\n",
    "\n",
    "    # Conv 3\n",
    "    model.add(Conv1D(16, 3, activation='relu', padding='same'))\n",
    "    if time_steps >= 4:\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        time_steps //= 2\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # LSTM Layers\n",
    "    model.add(LSTM(20, return_sequences=True))\n",
    "    model.add(LSTM(20, return_sequences=True))\n",
    "    model.add(LSTM(20, return_sequences=False))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # Fully connected\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(output_size))  # Output layer (linear)\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss=MeanAbsoluteError())\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf3807d",
   "metadata": {},
   "source": [
    "## Training wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3bab4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanAbsoluteError\n",
    "from tensorflow.keras.metrics import MeanAbsoluteError as MAEMetric\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def train_model(model, X_train, y_train, X_val, y_val, model_path):\n",
    "    \"\"\"\n",
    "    Trains the CNN-LSTM model with ReduceLROnPlateau based on validation MAE.\n",
    "    Saves the best model based on validation MAE (not loss).\n",
    "    \"\"\"\n",
    "    # Compile with MAE as loss and metric\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss=MeanAbsoluteError(),\n",
    "                  metrics=[MAEMetric(name='mae')])\n",
    "\n",
    "    # Learning rate scheduler based on val_mae\n",
    "    lr_schedule = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        factor=0.8,\n",
    "        min_lr=1e-5,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Save best model based on val_mae\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        model_path,\n",
    "        monitor='val_mae',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=150,\n",
    "        batch_size=128,\n",
    "        callbacks=[lr_schedule, checkpoint],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    print(history.history.keys())\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d26d80",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bee7897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_forecasting_model(model, X_test, y_test, scaler):\n",
    "    \"\"\"\n",
    "    Evaluates a forecasting model and prints MAE, RMSE, MAPE.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: trained Keras model\n",
    "    - X_test: test input features\n",
    "    - y_test: true test values (scaled or unscaled)\n",
    "    - scaler: fitted MinMaxScaler used for target (optional, for inverse scaling)\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary of MAE, RMSE, MAPE\n",
    "    \"\"\"\n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Inverse scale if scaler is given\n",
    "    if scaler is not None:\n",
    "        y_pred = scaler.inverse_transform(y_pred)\n",
    "        y_test = scaler.inverse_transform(y_test)\n",
    "\n",
    "    # Evaluation metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / (y_test + 1e-8))) * 100\n",
    "\n",
    "    print(f\"📊 Evaluation Metrics:\")\n",
    "    print(f\"MAE:  {mae:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAPE: {mape:.2f}%\")\n",
    "\n",
    "    return {\"mae\": mae, \"rmse\": rmse, \"mape\": mape}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c293b2e1",
   "metadata": {},
   "source": [
    "## Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eced36f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 Training with lookback=2, horizon=1\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janav\\.pyenv\\pyenv-win\\versions\\3.10.6\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m324/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0511 - mae: 0.0511\n",
      "Epoch 1: val_mae improved from inf to 0.01788, saving model to best_model_2_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0506 - mae: 0.0506 - val_loss: 0.0179 - val_mae: 0.0179 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m322/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0194 - mae: 0.0194\n",
      "Epoch 2: val_mae improved from 0.01788 to 0.01450, saving model to best_model_2_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0145 - val_mae: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m323/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0170 - mae: 0.0170\n",
      "Epoch 3: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0147 - val_mae: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m329/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0165 - mae: 0.0165\n",
      "Epoch 4: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0169 - val_mae: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m330/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0165 - mae: 0.0165\n",
      "Epoch 5: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0212 - val_mae: 0.0212 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m326/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0157 - mae: 0.0157\n",
      "Epoch 6: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0155 - val_mae: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0142 - mae: 0.0142\n",
      "Epoch 7: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.0155 - val_mae: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m326/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0138 - mae: 0.0138\n",
      "Epoch 8: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0157 - val_mae: 0.0157 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0147 - mae: 0.0147\n",
      "Epoch 9: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.0180 - val_mae: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m330/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 10: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0247 - val_mae: 0.0247 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0129 - mae: 0.0129\n",
      "Epoch 11: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0230 - val_mae: 0.0230 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m324/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 12: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0203 - val_mae: 0.0203 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0119 - mae: 0.0119\n",
      "Epoch 13: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0192 - val_mae: 0.0192 - learning_rate: 8.0000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m329/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0114 - mae: 0.0114\n",
      "Epoch 14: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0183 - val_mae: 0.0183 - learning_rate: 8.0000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 15: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0207 - val_mae: 0.0207 - learning_rate: 8.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0113 - mae: 0.0113\n",
      "Epoch 16: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0230 - val_mae: 0.0230 - learning_rate: 8.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 17: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0221 - val_mae: 0.0221 - learning_rate: 8.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m323/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0113 - mae: 0.0113\n",
      "Epoch 18: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0200 - val_mae: 0.0200 - learning_rate: 8.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0111 - mae: 0.0111\n",
      "Epoch 19: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0173 - val_mae: 0.0173 - learning_rate: 8.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 20: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0193 - val_mae: 0.0193 - learning_rate: 8.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m321/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0114 - mae: 0.0114\n",
      "Epoch 21: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0200 - val_mae: 0.0200 - learning_rate: 8.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m321/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0110 - mae: 0.0110\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 22: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0201 - val_mae: 0.0201 - learning_rate: 8.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m321/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0108 - mae: 0.0108\n",
      "Epoch 23: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0202 - val_mae: 0.0202 - learning_rate: 6.4000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m327/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0105 - mae: 0.0105\n",
      "Epoch 24: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0199 - val_mae: 0.0199 - learning_rate: 6.4000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m323/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0106 - mae: 0.0106\n",
      "Epoch 25: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 6.4000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m327/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0108 - mae: 0.0108\n",
      "Epoch 26: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0206 - val_mae: 0.0206 - learning_rate: 6.4000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m324/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0105 - mae: 0.0105\n",
      "Epoch 27: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0181 - val_mae: 0.0181 - learning_rate: 6.4000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0111 - mae: 0.0111\n",
      "Epoch 28: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0211 - val_mae: 0.0211 - learning_rate: 6.4000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0103 - mae: 0.0103\n",
      "Epoch 29: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 6.4000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m329/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0112 - mae: 0.0112\n",
      "Epoch 30: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0189 - val_mae: 0.0189 - learning_rate: 6.4000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m327/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0110 - mae: 0.0110\n",
      "Epoch 31: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0220 - val_mae: 0.0220 - learning_rate: 6.4000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0105 - mae: 0.0105\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 32: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 6.4000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0106 - mae: 0.0106\n",
      "Epoch 33: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 5.1200e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0103 - mae: 0.0103\n",
      "Epoch 34: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0216 - val_mae: 0.0216 - learning_rate: 5.1200e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0103 - mae: 0.0103\n",
      "Epoch 35: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0249 - val_mae: 0.0249 - learning_rate: 5.1200e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m327/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0102 - mae: 0.0102\n",
      "Epoch 36: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0220 - val_mae: 0.0220 - learning_rate: 5.1200e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0101 - mae: 0.0101\n",
      "Epoch 37: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0207 - val_mae: 0.0207 - learning_rate: 5.1200e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m330/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0103 - mae: 0.0103\n",
      "Epoch 38: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0203 - val_mae: 0.0203 - learning_rate: 5.1200e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0103 - mae: 0.0103\n",
      "Epoch 39: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0196 - val_mae: 0.0196 - learning_rate: 5.1200e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m327/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0103 - mae: 0.0103\n",
      "Epoch 40: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0229 - val_mae: 0.0229 - learning_rate: 5.1200e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0103 - mae: 0.0103\n",
      "Epoch 41: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0210 - val_mae: 0.0210 - learning_rate: 5.1200e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0103 - mae: 0.0103\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 42: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0220 - val_mae: 0.0220 - learning_rate: 5.1200e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m329/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0099 - mae: 0.0099\n",
      "Epoch 43: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0227 - val_mae: 0.0227 - learning_rate: 4.0960e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m327/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0099 - mae: 0.0099\n",
      "Epoch 44: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0206 - val_mae: 0.0206 - learning_rate: 4.0960e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m329/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0101 - mae: 0.0101\n",
      "Epoch 45: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 4.0960e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m329/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0100 - mae: 0.0100\n",
      "Epoch 46: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0246 - val_mae: 0.0246 - learning_rate: 4.0960e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m319/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0100 - mae: 0.0100\n",
      "Epoch 47: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0213 - val_mae: 0.0213 - learning_rate: 4.0960e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0098 - mae: 0.0098\n",
      "Epoch 48: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0203 - val_mae: 0.0203 - learning_rate: 4.0960e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0100 - mae: 0.0100\n",
      "Epoch 49: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0225 - val_mae: 0.0225 - learning_rate: 4.0960e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m321/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0099 - mae: 0.0099\n",
      "Epoch 50: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0216 - val_mae: 0.0216 - learning_rate: 4.0960e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m324/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0098 - mae: 0.0098\n",
      "Epoch 51: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0248 - val_mae: 0.0248 - learning_rate: 4.0960e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m327/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0101 - mae: 0.0101\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 52: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0243 - val_mae: 0.0243 - learning_rate: 4.0960e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0099 - mae: 0.0099\n",
      "Epoch 53: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0223 - val_mae: 0.0223 - learning_rate: 3.2768e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m322/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0097 - mae: 0.0097\n",
      "Epoch 54: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 3.2768e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m330/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0098 - mae: 0.0098\n",
      "Epoch 55: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0236 - val_mae: 0.0236 - learning_rate: 3.2768e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m321/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0098 - mae: 0.0098\n",
      "Epoch 56: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0233 - val_mae: 0.0233 - learning_rate: 3.2768e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m322/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0100 - mae: 0.0100\n",
      "Epoch 57: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0241 - val_mae: 0.0241 - learning_rate: 3.2768e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0099 - mae: 0.0099\n",
      "Epoch 58: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0213 - val_mae: 0.0213 - learning_rate: 3.2768e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0095 - mae: 0.0095\n",
      "Epoch 59: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0244 - val_mae: 0.0244 - learning_rate: 3.2768e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m330/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0098 - mae: 0.0098\n",
      "Epoch 60: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0225 - val_mae: 0.0225 - learning_rate: 3.2768e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m322/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0097 - mae: 0.0097\n",
      "Epoch 61: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0232 - val_mae: 0.0232 - learning_rate: 3.2768e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m330/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0097 - mae: 0.0097\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 62: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0222 - val_mae: 0.0222 - learning_rate: 3.2768e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0098 - mae: 0.0098\n",
      "Epoch 63: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0232 - val_mae: 0.0232 - learning_rate: 2.6214e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0095 - mae: 0.0095\n",
      "Epoch 64: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0243 - val_mae: 0.0243 - learning_rate: 2.6214e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0097 - mae: 0.0097\n",
      "Epoch 65: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0222 - val_mae: 0.0222 - learning_rate: 2.6214e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m323/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0095 - mae: 0.0095\n",
      "Epoch 66: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0224 - val_mae: 0.0224 - learning_rate: 2.6214e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0097 - mae: 0.0097\n",
      "Epoch 67: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0219 - val_mae: 0.0219 - learning_rate: 2.6214e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m319/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0097 - mae: 0.0097\n",
      "Epoch 68: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0224 - val_mae: 0.0224 - learning_rate: 2.6214e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0094 - mae: 0.0094\n",
      "Epoch 69: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0223 - val_mae: 0.0223 - learning_rate: 2.6214e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m329/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0099 - mae: 0.0099\n",
      "Epoch 70: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 2.6214e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0095 - mae: 0.0095\n",
      "Epoch 71: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0244 - val_mae: 0.0244 - learning_rate: 2.6214e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m327/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0096 - mae: 0.0096\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 72: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0225 - val_mae: 0.0225 - learning_rate: 2.6214e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m323/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0094 - mae: 0.0094\n",
      "Epoch 73: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0236 - val_mae: 0.0236 - learning_rate: 2.0972e-04\n",
      "Epoch 74/150\n",
      "\u001b[1m326/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0094 - mae: 0.0094\n",
      "Epoch 74: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 2.0972e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m322/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0094 - mae: 0.0094\n",
      "Epoch 75: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0219 - val_mae: 0.0219 - learning_rate: 2.0972e-04\n",
      "Epoch 76/150\n",
      "\u001b[1m321/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0096 - mae: 0.0096\n",
      "Epoch 76: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 2.0972e-04\n",
      "Epoch 77/150\n",
      "\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0094 - mae: 0.0094\n",
      "Epoch 77: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 2.0972e-04\n",
      "Epoch 78/150\n",
      "\u001b[1m327/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0096 - mae: 0.0096\n",
      "Epoch 78: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 2.0972e-04\n",
      "Epoch 79/150\n",
      "\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 79: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0232 - val_mae: 0.0232 - learning_rate: 2.0972e-04\n",
      "Epoch 80/150\n",
      "\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0094 - mae: 0.0094\n",
      "Epoch 80: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0232 - val_mae: 0.0232 - learning_rate: 2.0972e-04\n",
      "Epoch 81/150\n",
      "\u001b[1m323/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0095 - mae: 0.0095\n",
      "Epoch 81: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0230 - val_mae: 0.0230 - learning_rate: 2.0972e-04\n",
      "Epoch 82/150\n",
      "\u001b[1m319/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0097 - mae: 0.0097\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 82: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0227 - val_mae: 0.0227 - learning_rate: 2.0972e-04\n",
      "Epoch 83/150\n",
      "\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 83: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 1.6777e-04\n",
      "Epoch 84/150\n",
      "\u001b[1m329/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0095 - mae: 0.0095\n",
      "Epoch 84: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0227 - val_mae: 0.0227 - learning_rate: 1.6777e-04\n",
      "Epoch 85/150\n",
      "\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0094 - mae: 0.0094\n",
      "Epoch 85: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0227 - val_mae: 0.0227 - learning_rate: 1.6777e-04\n",
      "Epoch 86/150\n",
      "\u001b[1m324/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0096 - mae: 0.0096\n",
      "Epoch 86: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0221 - val_mae: 0.0221 - learning_rate: 1.6777e-04\n",
      "Epoch 87/150\n",
      "\u001b[1m327/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0094 - mae: 0.0094\n",
      "Epoch 87: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0223 - val_mae: 0.0223 - learning_rate: 1.6777e-04\n",
      "Epoch 88/150\n",
      "\u001b[1m323/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0096 - mae: 0.0096\n",
      "Epoch 88: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0233 - val_mae: 0.0233 - learning_rate: 1.6777e-04\n",
      "Epoch 89/150\n",
      "\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0094 - mae: 0.0094\n",
      "Epoch 89: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0223 - val_mae: 0.0223 - learning_rate: 1.6777e-04\n",
      "Epoch 90/150\n",
      "\u001b[1m327/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 90: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0224 - val_mae: 0.0224 - learning_rate: 1.6777e-04\n",
      "Epoch 91/150\n",
      "\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 91: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0226 - val_mae: 0.0226 - learning_rate: 1.6777e-04\n",
      "Epoch 92/150\n",
      "\u001b[1m321/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 92: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0226 - val_mae: 0.0226 - learning_rate: 1.6777e-04\n",
      "Epoch 93/150\n",
      "\u001b[1m327/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0094 - mae: 0.0094\n",
      "Epoch 93: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0233 - val_mae: 0.0233 - learning_rate: 1.3422e-04\n",
      "Epoch 94/150\n",
      "\u001b[1m330/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 94: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 1.3422e-04\n",
      "Epoch 95/150\n",
      "\u001b[1m326/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 95: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0223 - val_mae: 0.0223 - learning_rate: 1.3422e-04\n",
      "Epoch 96/150\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0097 - mae: 0.0097\n",
      "Epoch 96: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 1.3422e-04\n",
      "Epoch 97/150\n",
      "\u001b[1m329/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0096 - mae: 0.0096\n",
      "Epoch 97: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0230 - val_mae: 0.0230 - learning_rate: 1.3422e-04\n",
      "Epoch 98/150\n",
      "\u001b[1m321/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 98: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0241 - val_mae: 0.0241 - learning_rate: 1.3422e-04\n",
      "Epoch 99/150\n",
      "\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0094 - mae: 0.0094\n",
      "Epoch 99: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 1.3422e-04\n",
      "Epoch 100/150\n",
      "\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 100: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0226 - val_mae: 0.0226 - learning_rate: 1.3422e-04\n",
      "Epoch 101/150\n",
      "\u001b[1m327/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 101: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 1.3422e-04\n",
      "Epoch 102/150\n",
      "\u001b[1m319/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0094 - mae: 0.0094\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 102: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0241 - val_mae: 0.0241 - learning_rate: 1.3422e-04\n",
      "Epoch 103/150\n",
      "\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 103: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0228 - val_mae: 0.0228 - learning_rate: 1.0737e-04\n",
      "Epoch 104/150\n",
      "\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 104: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 1.0737e-04\n",
      "Epoch 105/150\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 105: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0225 - val_mae: 0.0225 - learning_rate: 1.0737e-04\n",
      "Epoch 106/150\n",
      "\u001b[1m326/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 106: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0230 - val_mae: 0.0230 - learning_rate: 1.0737e-04\n",
      "Epoch 107/150\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 107: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 1.0737e-04\n",
      "Epoch 108/150\n",
      "\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 108: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 1.0737e-04\n",
      "Epoch 109/150\n",
      "\u001b[1m327/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 109: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0229 - val_mae: 0.0229 - learning_rate: 1.0737e-04\n",
      "Epoch 110/150\n",
      "\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 110: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 1.0737e-04\n",
      "Epoch 111/150\n",
      "\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0094 - mae: 0.0094\n",
      "Epoch 111: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 1.0737e-04\n",
      "Epoch 112/150\n",
      "\u001b[1m330/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 112: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0228 - val_mae: 0.0228 - learning_rate: 1.0737e-04\n",
      "Epoch 113/150\n",
      "\u001b[1m330/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 113: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0233 - val_mae: 0.0233 - learning_rate: 8.5899e-05\n",
      "Epoch 114/150\n",
      "\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 114: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 8.5899e-05\n",
      "Epoch 115/150\n",
      "\u001b[1m326/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 115: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0236 - val_mae: 0.0236 - learning_rate: 8.5899e-05\n",
      "Epoch 116/150\n",
      "\u001b[1m321/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0090 - mae: 0.0090\n",
      "Epoch 116: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0232 - val_mae: 0.0232 - learning_rate: 8.5899e-05\n",
      "Epoch 117/150\n",
      "\u001b[1m323/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 117: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0229 - val_mae: 0.0229 - learning_rate: 8.5899e-05\n",
      "Epoch 118/150\n",
      "\u001b[1m326/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 118: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0239 - val_mae: 0.0239 - learning_rate: 8.5899e-05\n",
      "Epoch 119/150\n",
      "\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 119: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 8.5899e-05\n",
      "Epoch 120/150\n",
      "\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 120: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 8.5899e-05\n",
      "Epoch 121/150\n",
      "\u001b[1m321/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 121: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0227 - val_mae: 0.0227 - learning_rate: 8.5899e-05\n",
      "Epoch 122/150\n",
      "\u001b[1m322/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 122: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 8.5899e-05\n",
      "Epoch 123/150\n",
      "\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 123: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0232 - val_mae: 0.0232 - learning_rate: 6.8719e-05\n",
      "Epoch 124/150\n",
      "\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 124: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 6.8719e-05\n",
      "Epoch 125/150\n",
      "\u001b[1m321/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 125: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0227 - val_mae: 0.0227 - learning_rate: 6.8719e-05\n",
      "Epoch 126/150\n",
      "\u001b[1m329/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 126: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0232 - val_mae: 0.0232 - learning_rate: 6.8719e-05\n",
      "Epoch 127/150\n",
      "\u001b[1m322/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 127: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0228 - val_mae: 0.0228 - learning_rate: 6.8719e-05\n",
      "Epoch 128/150\n",
      "\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 128: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0229 - val_mae: 0.0229 - learning_rate: 6.8719e-05\n",
      "Epoch 129/150\n",
      "\u001b[1m319/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 129: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 6.8719e-05\n",
      "Epoch 130/150\n",
      "\u001b[1m330/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 130: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 6.8719e-05\n",
      "Epoch 131/150\n",
      "\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 131: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0229 - val_mae: 0.0229 - learning_rate: 6.8719e-05\n",
      "Epoch 132/150\n",
      "\u001b[1m329/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0090 - mae: 0.0090\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "\n",
      "Epoch 132: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 6.8719e-05\n",
      "Epoch 133/150\n",
      "\u001b[1m322/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 133: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 5.4976e-05\n",
      "Epoch 134/150\n",
      "\u001b[1m330/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 134: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 5.4976e-05\n",
      "Epoch 135/150\n",
      "\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 135: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 5.4976e-05\n",
      "Epoch 136/150\n",
      "\u001b[1m329/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 136: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0233 - val_mae: 0.0233 - learning_rate: 5.4976e-05\n",
      "Epoch 137/150\n",
      "\u001b[1m323/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0089 - mae: 0.0089\n",
      "Epoch 137: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0228 - val_mae: 0.0228 - learning_rate: 5.4976e-05\n",
      "Epoch 138/150\n",
      "\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0090 - mae: 0.0090\n",
      "Epoch 138: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0233 - val_mae: 0.0233 - learning_rate: 5.4976e-05\n",
      "Epoch 139/150\n",
      "\u001b[1m322/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0090 - mae: 0.0090\n",
      "Epoch 139: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 5.4976e-05\n",
      "Epoch 140/150\n",
      "\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 140: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0233 - val_mae: 0.0233 - learning_rate: 5.4976e-05\n",
      "Epoch 141/150\n",
      "\u001b[1m319/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 141: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0228 - val_mae: 0.0228 - learning_rate: 5.4976e-05\n",
      "Epoch 142/150\n",
      "\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "\n",
      "Epoch 142: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0236 - val_mae: 0.0236 - learning_rate: 5.4976e-05\n",
      "Epoch 143/150\n",
      "\u001b[1m323/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 143: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0232 - val_mae: 0.0232 - learning_rate: 4.3980e-05\n",
      "Epoch 144/150\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 144: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 4.3980e-05\n",
      "Epoch 145/150\n",
      "\u001b[1m329/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 145: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0236 - val_mae: 0.0236 - learning_rate: 4.3980e-05\n",
      "Epoch 146/150\n",
      "\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 146: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 4.3980e-05\n",
      "Epoch 147/150\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0090 - mae: 0.0090\n",
      "Epoch 147: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0230 - val_mae: 0.0230 - learning_rate: 4.3980e-05\n",
      "Epoch 148/150\n",
      "\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 148: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0232 - val_mae: 0.0232 - learning_rate: 4.3980e-05\n",
      "Epoch 149/150\n",
      "\u001b[1m319/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0090 - mae: 0.0090\n",
      "Epoch 149: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 4.3980e-05\n",
      "Epoch 150/150\n",
      "\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0088\n",
      "Epoch 150: val_mae did not improve from 0.01450\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 4.3980e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mae', 'val_loss', 'val_mae', 'learning_rate'])\n",
      "✅ Loaded saved model from: best_model_2_1.h5\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "📊 Evaluation Metrics:\n",
      "MAE:  0.5273\n",
      "RMSE: 0.9056\n",
      "MAPE: 22.38%\n",
      "\n",
      "🔁 Training with lookback=2, horizon=2\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janav\\.pyenv\\pyenv-win\\versions\\3.10.6\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0526 - mae: 0.0526\n",
      "Epoch 1: val_mae improved from inf to 0.01793, saving model to best_model_2_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0521 - mae: 0.0521 - val_loss: 0.0179 - val_mae: 0.0179 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0207 - mae: 0.0207\n",
      "Epoch 2: val_mae improved from 0.01793 to 0.01649, saving model to best_model_2_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0207 - mae: 0.0207 - val_loss: 0.0165 - val_mae: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0188\n",
      "Epoch 3: val_mae did not improve from 0.01649\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0165 - val_mae: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0181 - mae: 0.0181\n",
      "Epoch 4: val_mae improved from 0.01649 to 0.01600, saving model to best_model_2_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0160 - val_mae: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0174 - mae: 0.0174\n",
      "Epoch 5: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0173 - val_mae: 0.0173 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0166 - mae: 0.0166\n",
      "Epoch 6: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0196 - val_mae: 0.0196 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0160 - mae: 0.0160\n",
      "Epoch 7: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0199 - val_mae: 0.0199 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0156 - mae: 0.0156\n",
      "Epoch 8: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0209 - val_mae: 0.0209 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0155 - mae: 0.0155\n",
      "Epoch 9: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0207 - val_mae: 0.0207 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0150 - mae: 0.0150\n",
      "Epoch 10: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0216 - val_mae: 0.0216 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0147 - mae: 0.0147\n",
      "Epoch 11: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.0216 - val_mae: 0.0216 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0146 - mae: 0.0146\n",
      "Epoch 12: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0220 - val_mae: 0.0220 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0146 - mae: 0.0146\n",
      "Epoch 13: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0223 - val_mae: 0.0223 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m317/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0144 - mae: 0.0144\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 14: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0224 - val_mae: 0.0224 - learning_rate: 0.0010\n",
      "Epoch 15/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0140 - mae: 0.0140\n",
      "Epoch 15: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 8.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m319/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0141 - mae: 0.0141\n",
      "Epoch 16: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0224 - val_mae: 0.0224 - learning_rate: 8.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m318/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0143 - mae: 0.0143\n",
      "Epoch 17: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 8.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0137 - mae: 0.0137\n",
      "Epoch 18: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 8.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m318/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0138 - mae: 0.0138\n",
      "Epoch 19: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0227 - val_mae: 0.0227 - learning_rate: 8.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m318/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0138 - mae: 0.0138\n",
      "Epoch 20: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0226 - val_mae: 0.0226 - learning_rate: 8.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0137 - mae: 0.0137\n",
      "Epoch 21: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0242 - val_mae: 0.0242 - learning_rate: 8.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m318/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0136 - mae: 0.0136\n",
      "Epoch 22: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0227 - val_mae: 0.0227 - learning_rate: 8.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0135 - mae: 0.0135\n",
      "Epoch 23: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 8.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0137 - mae: 0.0137\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 24: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 8.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0133 - mae: 0.0133\n",
      "Epoch 25: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0232 - val_mae: 0.0232 - learning_rate: 6.4000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0134 - mae: 0.0134\n",
      "Epoch 26: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0232 - val_mae: 0.0232 - learning_rate: 6.4000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 27: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 6.4000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0132 - mae: 0.0132\n",
      "Epoch 28: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0239 - val_mae: 0.0239 - learning_rate: 6.4000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m319/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0132 - mae: 0.0132\n",
      "Epoch 29: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 6.4000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m317/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0133 - mae: 0.0133\n",
      "Epoch 30: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 6.4000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0133 - mae: 0.0133\n",
      "Epoch 31: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0229 - val_mae: 0.0229 - learning_rate: 6.4000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m319/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0131 - mae: 0.0131\n",
      "Epoch 32: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 6.4000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0134 - mae: 0.0134\n",
      "Epoch 33: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 6.4000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 34: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0241 - val_mae: 0.0241 - learning_rate: 6.4000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0132 - mae: 0.0132\n",
      "Epoch 35: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0250 - val_mae: 0.0250 - learning_rate: 5.1200e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m319/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0131 - mae: 0.0131\n",
      "Epoch 36: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0232 - val_mae: 0.0232 - learning_rate: 5.1200e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m317/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0131 - mae: 0.0131\n",
      "Epoch 37: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 5.1200e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 38: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0244 - val_mae: 0.0244 - learning_rate: 5.1200e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m319/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 39: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0224 - val_mae: 0.0224 - learning_rate: 5.1200e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0129 - mae: 0.0129\n",
      "Epoch 40: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0236 - val_mae: 0.0236 - learning_rate: 5.1200e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0129 - mae: 0.0129\n",
      "Epoch 41: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 5.1200e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m316/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0128 - mae: 0.0128\n",
      "Epoch 42: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0221 - val_mae: 0.0221 - learning_rate: 5.1200e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 43: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0242 - val_mae: 0.0242 - learning_rate: 5.1200e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0129 - mae: 0.0129\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 44: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 5.1200e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 45: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0242 - val_mae: 0.0242 - learning_rate: 4.0960e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0126 - mae: 0.0126\n",
      "Epoch 46: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0243 - val_mae: 0.0243 - learning_rate: 4.0960e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 47: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0243 - val_mae: 0.0243 - learning_rate: 4.0960e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0127 - mae: 0.0127\n",
      "Epoch 48: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 4.0960e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0127 - mae: 0.0127\n",
      "Epoch 49: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 4.0960e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0127 - mae: 0.0127\n",
      "Epoch 50: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 4.0960e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m318/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0127 - mae: 0.0127\n",
      "Epoch 51: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 4.0960e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0129 - mae: 0.0129\n",
      "Epoch 52: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0232 - val_mae: 0.0232 - learning_rate: 4.0960e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0128 - mae: 0.0128\n",
      "Epoch 53: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0248 - val_mae: 0.0248 - learning_rate: 4.0960e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 54: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 4.0960e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0126 - mae: 0.0126\n",
      "Epoch 55: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0243 - val_mae: 0.0243 - learning_rate: 3.2768e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m319/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0127 - mae: 0.0127\n",
      "Epoch 56: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0242 - val_mae: 0.0242 - learning_rate: 3.2768e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0127 - mae: 0.0127\n",
      "Epoch 57: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 3.2768e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m318/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 58: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0233 - val_mae: 0.0233 - learning_rate: 3.2768e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0126 - mae: 0.0126\n",
      "Epoch 59: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0245 - val_mae: 0.0245 - learning_rate: 3.2768e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m316/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 60: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0242 - val_mae: 0.0242 - learning_rate: 3.2768e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 61: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0243 - val_mae: 0.0243 - learning_rate: 3.2768e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0126 - mae: 0.0126\n",
      "Epoch 62: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 3.2768e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 63: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0236 - val_mae: 0.0236 - learning_rate: 3.2768e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 64: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0243 - val_mae: 0.0243 - learning_rate: 3.2768e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0126 - mae: 0.0126\n",
      "Epoch 65: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0251 - val_mae: 0.0251 - learning_rate: 2.6214e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m318/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0124\n",
      "Epoch 66: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 2.6214e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m317/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0124\n",
      "Epoch 67: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 2.6214e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 68: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0241 - val_mae: 0.0241 - learning_rate: 2.6214e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 69: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 2.6214e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 70: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0243 - val_mae: 0.0243 - learning_rate: 2.6214e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m318/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 71: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0243 - val_mae: 0.0243 - learning_rate: 2.6214e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 72: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0239 - val_mae: 0.0239 - learning_rate: 2.6214e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 73: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0249 - val_mae: 0.0249 - learning_rate: 2.6214e-04\n",
      "Epoch 74/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0124\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 74: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0245 - val_mae: 0.0245 - learning_rate: 2.6214e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0124\n",
      "Epoch 75: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0243 - val_mae: 0.0243 - learning_rate: 2.0972e-04\n",
      "Epoch 76/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0124 - mae: 0.0124\n",
      "Epoch 76: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0239 - val_mae: 0.0239 - learning_rate: 2.0972e-04\n",
      "Epoch 77/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0124\n",
      "Epoch 77: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0243 - val_mae: 0.0243 - learning_rate: 2.0972e-04\n",
      "Epoch 78/150\n",
      "\u001b[1m317/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 78: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0242 - val_mae: 0.0242 - learning_rate: 2.0972e-04\n",
      "Epoch 79/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0124 - mae: 0.0124\n",
      "Epoch 79: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0242 - val_mae: 0.0242 - learning_rate: 2.0972e-04\n",
      "Epoch 80/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0124 - mae: 0.0124\n",
      "Epoch 80: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0239 - val_mae: 0.0239 - learning_rate: 2.0972e-04\n",
      "Epoch 81/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 81: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0241 - val_mae: 0.0241 - learning_rate: 2.0972e-04\n",
      "Epoch 82/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0124\n",
      "Epoch 82: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 2.0972e-04\n",
      "Epoch 83/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 83: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0241 - val_mae: 0.0241 - learning_rate: 2.0972e-04\n",
      "Epoch 84/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0124\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 84: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0244 - val_mae: 0.0244 - learning_rate: 2.0972e-04\n",
      "Epoch 85/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 85: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0239 - val_mae: 0.0239 - learning_rate: 1.6777e-04\n",
      "Epoch 86/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 86: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 1.6777e-04\n",
      "Epoch 87/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0124\n",
      "Epoch 87: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0242 - val_mae: 0.0242 - learning_rate: 1.6777e-04\n",
      "Epoch 88/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 88: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0242 - val_mae: 0.0242 - learning_rate: 1.6777e-04\n",
      "Epoch 89/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0122\n",
      "Epoch 89: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0244 - val_mae: 0.0244 - learning_rate: 1.6777e-04\n",
      "Epoch 90/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 90: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0241 - val_mae: 0.0241 - learning_rate: 1.6777e-04\n",
      "Epoch 91/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 91: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 1.6777e-04\n",
      "Epoch 92/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 92: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0246 - val_mae: 0.0246 - learning_rate: 1.6777e-04\n",
      "Epoch 93/150\n",
      "\u001b[1m317/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 93: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0250 - val_mae: 0.0250 - learning_rate: 1.6777e-04\n",
      "Epoch 94/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 94: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 1.6777e-04\n",
      "Epoch 95/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0122\n",
      "Epoch 95: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0244 - val_mae: 0.0244 - learning_rate: 1.3422e-04\n",
      "Epoch 96/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 96: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0239 - val_mae: 0.0239 - learning_rate: 1.3422e-04\n",
      "Epoch 97/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0122\n",
      "Epoch 97: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 1.3422e-04\n",
      "Epoch 98/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 98: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0242 - val_mae: 0.0242 - learning_rate: 1.3422e-04\n",
      "Epoch 99/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0122\n",
      "Epoch 99: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0242 - val_mae: 0.0242 - learning_rate: 1.3422e-04\n",
      "Epoch 100/150\n",
      "\u001b[1m315/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0122\n",
      "Epoch 100: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0244 - val_mae: 0.0244 - learning_rate: 1.3422e-04\n",
      "Epoch 101/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 101: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0244 - val_mae: 0.0244 - learning_rate: 1.3422e-04\n",
      "Epoch 102/150\n",
      "\u001b[1m318/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 102: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0242 - val_mae: 0.0242 - learning_rate: 1.3422e-04\n",
      "Epoch 103/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 103: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 1.3422e-04\n",
      "Epoch 104/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 104: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 1.3422e-04\n",
      "Epoch 105/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0122\n",
      "Epoch 105: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 1.0737e-04\n",
      "Epoch 106/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 106: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0241 - val_mae: 0.0241 - learning_rate: 1.0737e-04\n",
      "Epoch 107/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 107: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 1.0737e-04\n",
      "Epoch 108/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 108: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 1.0737e-04\n",
      "Epoch 109/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 109: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 1.0737e-04\n",
      "Epoch 110/150\n",
      "\u001b[1m315/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0122\n",
      "Epoch 110: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0241 - val_mae: 0.0241 - learning_rate: 1.0737e-04\n",
      "Epoch 111/150\n",
      "\u001b[1m319/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 111: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0239 - val_mae: 0.0239 - learning_rate: 1.0737e-04\n",
      "Epoch 112/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 112: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0247 - val_mae: 0.0247 - learning_rate: 1.0737e-04\n",
      "Epoch 113/150\n",
      "\u001b[1m315/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0122\n",
      "Epoch 113: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0242 - val_mae: 0.0242 - learning_rate: 1.0737e-04\n",
      "Epoch 114/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 114: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 114: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 1.0737e-04\n",
      "Epoch 115/150\n",
      "\u001b[1m318/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 115: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0239 - val_mae: 0.0239 - learning_rate: 8.5899e-05\n",
      "Epoch 116/150\n",
      "\u001b[1m319/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0122 - mae: 0.0122\n",
      "Epoch 116: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0241 - val_mae: 0.0241 - learning_rate: 8.5899e-05\n",
      "Epoch 117/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 117: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 8.5899e-05\n",
      "Epoch 118/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 118: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0242 - val_mae: 0.0242 - learning_rate: 8.5899e-05\n",
      "Epoch 119/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 119: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0239 - val_mae: 0.0239 - learning_rate: 8.5899e-05\n",
      "Epoch 120/150\n",
      "\u001b[1m317/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0122 - mae: 0.0122\n",
      "Epoch 120: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0242 - val_mae: 0.0242 - learning_rate: 8.5899e-05\n",
      "Epoch 121/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 121: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0242 - val_mae: 0.0242 - learning_rate: 8.5899e-05\n",
      "Epoch 122/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 122: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 8.5899e-05\n",
      "Epoch 123/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 123: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0242 - val_mae: 0.0242 - learning_rate: 8.5899e-05\n",
      "Epoch 124/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 124: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 124: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0241 - val_mae: 0.0241 - learning_rate: 8.5899e-05\n",
      "Epoch 125/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0122\n",
      "Epoch 125: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0243 - val_mae: 0.0243 - learning_rate: 6.8719e-05\n",
      "Epoch 126/150\n",
      "\u001b[1m319/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 126: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0243 - val_mae: 0.0243 - learning_rate: 6.8719e-05\n",
      "Epoch 127/150\n",
      "\u001b[1m319/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 127: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 6.8719e-05\n",
      "Epoch 128/150\n",
      "\u001b[1m317/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 128: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0245 - val_mae: 0.0245 - learning_rate: 6.8719e-05\n",
      "Epoch 129/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 129: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0241 - val_mae: 0.0241 - learning_rate: 6.8719e-05\n",
      "Epoch 130/150\n",
      "\u001b[1m319/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 130: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0244 - val_mae: 0.0244 - learning_rate: 6.8719e-05\n",
      "Epoch 131/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0122 - mae: 0.0122\n",
      "Epoch 131: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0243 - val_mae: 0.0243 - learning_rate: 6.8719e-05\n",
      "Epoch 132/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 132: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0243 - val_mae: 0.0243 - learning_rate: 6.8719e-05\n",
      "Epoch 133/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 133: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0242 - val_mae: 0.0242 - learning_rate: 6.8719e-05\n",
      "Epoch 134/150\n",
      "\u001b[1m317/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 134: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "\n",
      "Epoch 134: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 6.8719e-05\n",
      "Epoch 135/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 135: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 5.4976e-05\n",
      "Epoch 136/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 136: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0239 - val_mae: 0.0239 - learning_rate: 5.4976e-05\n",
      "Epoch 137/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0119 - mae: 0.0119\n",
      "Epoch 137: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 5.4976e-05\n",
      "Epoch 138/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 138: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0242 - val_mae: 0.0242 - learning_rate: 5.4976e-05\n",
      "Epoch 139/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 139: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0242 - val_mae: 0.0242 - learning_rate: 5.4976e-05\n",
      "Epoch 140/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 140: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 5.4976e-05\n",
      "Epoch 141/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 141: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0239 - val_mae: 0.0239 - learning_rate: 5.4976e-05\n",
      "Epoch 142/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 142: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0242 - val_mae: 0.0242 - learning_rate: 5.4976e-05\n",
      "Epoch 143/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 143: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0243 - val_mae: 0.0243 - learning_rate: 5.4976e-05\n",
      "Epoch 144/150\n",
      "\u001b[1m319/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 144: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "\n",
      "Epoch 144: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0241 - val_mae: 0.0241 - learning_rate: 5.4976e-05\n",
      "Epoch 145/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0122\n",
      "Epoch 145: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0241 - val_mae: 0.0241 - learning_rate: 4.3980e-05\n",
      "Epoch 146/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0119 - mae: 0.0119\n",
      "Epoch 146: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0241 - val_mae: 0.0241 - learning_rate: 4.3980e-05\n",
      "Epoch 147/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0122\n",
      "Epoch 147: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0241 - val_mae: 0.0241 - learning_rate: 4.3980e-05\n",
      "Epoch 148/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0122\n",
      "Epoch 148: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 4.3980e-05\n",
      "Epoch 149/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0124\n",
      "Epoch 149: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0239 - val_mae: 0.0239 - learning_rate: 4.3980e-05\n",
      "Epoch 150/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 150: val_mae did not improve from 0.01600\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0241 - val_mae: 0.0241 - learning_rate: 4.3980e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mae', 'val_loss', 'val_mae', 'learning_rate'])\n",
      "✅ Loaded saved model from: best_model_2_2.h5\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "📊 Evaluation Metrics:\n",
      "MAE:  0.6123\n",
      "RMSE: 1.0526\n",
      "MAPE: 26.54%\n",
      "\n",
      "🔁 Training with lookback=2, horizon=6\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janav\\.pyenv\\pyenv-win\\versions\\3.10.6\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0588 - mae: 0.0588\n",
      "Epoch 1: val_mae improved from inf to 0.02581, saving model to best_model_2_6.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0587 - mae: 0.0587 - val_loss: 0.0258 - val_mae: 0.0258 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0281 - mae: 0.0281\n",
      "Epoch 2: val_mae improved from 0.02581 to 0.02555, saving model to best_model_2_6.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0281 - mae: 0.0281 - val_loss: 0.0255 - val_mae: 0.0255 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0265 - mae: 0.0265\n",
      "Epoch 3: val_mae improved from 0.02555 to 0.02428, saving model to best_model_2_6.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0265 - mae: 0.0265 - val_loss: 0.0243 - val_mae: 0.0243 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0257 - mae: 0.0257\n",
      "Epoch 4: val_mae improved from 0.02428 to 0.02419, saving model to best_model_2_6.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0257 - mae: 0.0257 - val_loss: 0.0242 - val_mae: 0.0242 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0253 - mae: 0.0253\n",
      "Epoch 5: val_mae improved from 0.02419 to 0.02383, saving model to best_model_2_6.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0253 - mae: 0.0253 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0250 - mae: 0.0250\n",
      "Epoch 6: val_mae did not improve from 0.02383\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0250 - mae: 0.0250 - val_loss: 0.0242 - val_mae: 0.0242 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0247 - mae: 0.0247\n",
      "Epoch 7: val_mae did not improve from 0.02383\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0247 - mae: 0.0247 - val_loss: 0.0242 - val_mae: 0.0242 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m319/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0243 - mae: 0.0243\n",
      "Epoch 8: val_mae did not improve from 0.02383\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0243 - mae: 0.0243 - val_loss: 0.0249 - val_mae: 0.0249 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0244 - mae: 0.0244\n",
      "Epoch 9: val_mae did not improve from 0.02383\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0244 - mae: 0.0244 - val_loss: 0.0244 - val_mae: 0.0244 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0241 - mae: 0.0241\n",
      "Epoch 10: val_mae did not improve from 0.02383\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0241 - mae: 0.0241 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m319/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0237 - mae: 0.0237\n",
      "Epoch 11: val_mae did not improve from 0.02383\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0237 - mae: 0.0237 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0239 - mae: 0.0239\n",
      "Epoch 12: val_mae did not improve from 0.02383\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0239 - mae: 0.0239 - val_loss: 0.0241 - val_mae: 0.0241 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0238 - mae: 0.0238\n",
      "Epoch 13: val_mae did not improve from 0.02383\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0238 - mae: 0.0238 - val_loss: 0.0244 - val_mae: 0.0244 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0235 - mae: 0.0235\n",
      "Epoch 14: val_mae did not improve from 0.02383\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0235 - mae: 0.0235 - val_loss: 0.0246 - val_mae: 0.0246 - learning_rate: 0.0010\n",
      "Epoch 15/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0231 - mae: 0.0231\n",
      "Epoch 15: val_mae improved from 0.02383 to 0.02331, saving model to best_model_2_6.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0231 - mae: 0.0231 - val_loss: 0.0233 - val_mae: 0.0233 - learning_rate: 0.0010\n",
      "Epoch 16/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0227 - mae: 0.0227\n",
      "Epoch 16: val_mae did not improve from 0.02331\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0227 - mae: 0.0227 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 0.0010\n",
      "Epoch 17/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0225 - mae: 0.0225\n",
      "Epoch 17: val_mae did not improve from 0.02331\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0225 - mae: 0.0225 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 0.0010\n",
      "Epoch 18/150\n",
      "\u001b[1m319/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0222 - mae: 0.0222\n",
      "Epoch 18: val_mae improved from 0.02331 to 0.02311, saving model to best_model_2_6.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0222 - mae: 0.0222 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 0.0010\n",
      "Epoch 19/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0220 - mae: 0.0220\n",
      "Epoch 19: val_mae improved from 0.02311 to 0.02227, saving model to best_model_2_6.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0220 - mae: 0.0220 - val_loss: 0.0223 - val_mae: 0.0223 - learning_rate: 0.0010\n",
      "Epoch 20/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0219 - mae: 0.0219\n",
      "Epoch 20: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0219 - mae: 0.0219 - val_loss: 0.0226 - val_mae: 0.0226 - learning_rate: 0.0010\n",
      "Epoch 21/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0219 - mae: 0.0219\n",
      "Epoch 21: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0219 - mae: 0.0219 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 0.0010\n",
      "Epoch 22/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0217 - mae: 0.0217\n",
      "Epoch 22: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0217 - mae: 0.0217 - val_loss: 0.0224 - val_mae: 0.0224 - learning_rate: 0.0010\n",
      "Epoch 23/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0215 - mae: 0.0215\n",
      "Epoch 23: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0215 - mae: 0.0215 - val_loss: 0.0226 - val_mae: 0.0226 - learning_rate: 0.0010\n",
      "Epoch 24/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0214 - mae: 0.0214\n",
      "Epoch 24: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0214 - mae: 0.0214 - val_loss: 0.0223 - val_mae: 0.0223 - learning_rate: 0.0010\n",
      "Epoch 25/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0213 - mae: 0.0213\n",
      "Epoch 25: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0213 - mae: 0.0213 - val_loss: 0.0228 - val_mae: 0.0228 - learning_rate: 0.0010\n",
      "Epoch 26/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0215 - mae: 0.0215\n",
      "Epoch 26: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0215 - mae: 0.0215 - val_loss: 0.0230 - val_mae: 0.0230 - learning_rate: 0.0010\n",
      "Epoch 27/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0210 - mae: 0.0210\n",
      "Epoch 27: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0210 - mae: 0.0210 - val_loss: 0.0227 - val_mae: 0.0227 - learning_rate: 0.0010\n",
      "Epoch 28/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0212 - mae: 0.0212\n",
      "Epoch 28: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0212 - mae: 0.0212 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 0.0010\n",
      "Epoch 29/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0208 - mae: 0.0208\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 29: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0208 - mae: 0.0208 - val_loss: 0.0232 - val_mae: 0.0232 - learning_rate: 0.0010\n",
      "Epoch 30/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0210 - mae: 0.0210\n",
      "Epoch 30: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0210 - mae: 0.0210 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 8.0000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0208 - mae: 0.0208\n",
      "Epoch 31: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0208 - mae: 0.0208 - val_loss: 0.0233 - val_mae: 0.0233 - learning_rate: 8.0000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0206 - mae: 0.0206\n",
      "Epoch 32: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0206 - mae: 0.0206 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 8.0000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0205 - mae: 0.0205\n",
      "Epoch 33: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0205 - mae: 0.0205 - val_loss: 0.0229 - val_mae: 0.0229 - learning_rate: 8.0000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0203 - mae: 0.0203\n",
      "Epoch 34: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0203 - mae: 0.0203 - val_loss: 0.0241 - val_mae: 0.0241 - learning_rate: 8.0000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0204 - mae: 0.0204\n",
      "Epoch 35: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0204 - mae: 0.0204 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 8.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0202 - mae: 0.0202\n",
      "Epoch 36: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0202 - mae: 0.0202 - val_loss: 0.0232 - val_mae: 0.0232 - learning_rate: 8.0000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0203 - mae: 0.0203\n",
      "Epoch 37: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0203 - mae: 0.0203 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 8.0000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m318/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0202 - mae: 0.0202\n",
      "Epoch 38: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0202 - mae: 0.0202 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 8.0000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0203 - mae: 0.0203\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 39: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0203 - mae: 0.0203 - val_loss: 0.0229 - val_mae: 0.0229 - learning_rate: 8.0000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0200 - mae: 0.0200\n",
      "Epoch 40: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0200 - mae: 0.0200 - val_loss: 0.0233 - val_mae: 0.0233 - learning_rate: 6.4000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0198 - mae: 0.0198\n",
      "Epoch 41: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0198 - mae: 0.0198 - val_loss: 0.0233 - val_mae: 0.0233 - learning_rate: 6.4000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0199 - mae: 0.0199\n",
      "Epoch 42: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0199 - mae: 0.0199 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 6.4000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0201 - mae: 0.0201\n",
      "Epoch 43: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0201 - mae: 0.0201 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 6.4000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0200 - mae: 0.0200\n",
      "Epoch 44: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0200 - mae: 0.0200 - val_loss: 0.0245 - val_mae: 0.0245 - learning_rate: 6.4000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0198 - mae: 0.0198\n",
      "Epoch 45: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0198 - mae: 0.0198 - val_loss: 0.0243 - val_mae: 0.0243 - learning_rate: 6.4000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0200 - mae: 0.0200\n",
      "Epoch 46: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0200 - mae: 0.0200 - val_loss: 0.0250 - val_mae: 0.0250 - learning_rate: 6.4000e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m319/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0200 - mae: 0.0200\n",
      "Epoch 47: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0200 - mae: 0.0200 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 6.4000e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0198 - mae: 0.0198\n",
      "Epoch 48: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0198 - mae: 0.0198 - val_loss: 0.0243 - val_mae: 0.0243 - learning_rate: 6.4000e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0196 - mae: 0.0196\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 49: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0197 - mae: 0.0197 - val_loss: 0.0249 - val_mae: 0.0249 - learning_rate: 6.4000e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0195 - mae: 0.0195\n",
      "Epoch 50: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0195 - mae: 0.0195 - val_loss: 0.0248 - val_mae: 0.0248 - learning_rate: 5.1200e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0196 - mae: 0.0196\n",
      "Epoch 51: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0196 - mae: 0.0196 - val_loss: 0.0245 - val_mae: 0.0245 - learning_rate: 5.1200e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0197 - mae: 0.0197\n",
      "Epoch 52: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0197 - mae: 0.0197 - val_loss: 0.0242 - val_mae: 0.0242 - learning_rate: 5.1200e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0196 - mae: 0.0196\n",
      "Epoch 53: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0196 - mae: 0.0196 - val_loss: 0.0246 - val_mae: 0.0246 - learning_rate: 5.1200e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0194 - mae: 0.0194\n",
      "Epoch 54: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0249 - val_mae: 0.0249 - learning_rate: 5.1200e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0194 - mae: 0.0194\n",
      "Epoch 55: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0248 - val_mae: 0.0248 - learning_rate: 5.1200e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0194 - mae: 0.0194\n",
      "Epoch 56: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0247 - val_mae: 0.0247 - learning_rate: 5.1200e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0199 - mae: 0.0199\n",
      "Epoch 57: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0199 - mae: 0.0199 - val_loss: 0.0243 - val_mae: 0.0243 - learning_rate: 5.1200e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0194 - mae: 0.0194\n",
      "Epoch 58: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0250 - val_mae: 0.0250 - learning_rate: 5.1200e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0196 - mae: 0.0196\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 59: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0196 - mae: 0.0196 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 5.1200e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0194 - mae: 0.0194\n",
      "Epoch 60: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0249 - val_mae: 0.0249 - learning_rate: 4.0960e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0194 - mae: 0.0194\n",
      "Epoch 61: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0249 - val_mae: 0.0249 - learning_rate: 4.0960e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0195 - mae: 0.0195\n",
      "Epoch 62: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0195 - mae: 0.0195 - val_loss: 0.0244 - val_mae: 0.0244 - learning_rate: 4.0960e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0194 - mae: 0.0194\n",
      "Epoch 63: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0249 - val_mae: 0.0249 - learning_rate: 4.0960e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0193 - mae: 0.0193\n",
      "Epoch 64: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0251 - val_mae: 0.0251 - learning_rate: 4.0960e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0194 - mae: 0.0194\n",
      "Epoch 65: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0250 - val_mae: 0.0250 - learning_rate: 4.0960e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0194 - mae: 0.0194\n",
      "Epoch 66: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0253 - val_mae: 0.0253 - learning_rate: 4.0960e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0194 - mae: 0.0194\n",
      "Epoch 67: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0248 - val_mae: 0.0248 - learning_rate: 4.0960e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0195 - mae: 0.0195\n",
      "Epoch 68: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0195 - mae: 0.0195 - val_loss: 0.0251 - val_mae: 0.0251 - learning_rate: 4.0960e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0192 - mae: 0.0192\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 69: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.0245 - val_mae: 0.0245 - learning_rate: 4.0960e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0193 - mae: 0.0193\n",
      "Epoch 70: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 3.2768e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0193 - mae: 0.0193\n",
      "Epoch 71: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0247 - val_mae: 0.0247 - learning_rate: 3.2768e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0193 - mae: 0.0193\n",
      "Epoch 72: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0246 - val_mae: 0.0246 - learning_rate: 3.2768e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0192 - mae: 0.0192\n",
      "Epoch 73: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.0248 - val_mae: 0.0248 - learning_rate: 3.2768e-04\n",
      "Epoch 74/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0194 - mae: 0.0194\n",
      "Epoch 74: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0249 - val_mae: 0.0249 - learning_rate: 3.2768e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0193 - mae: 0.0193\n",
      "Epoch 75: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0251 - val_mae: 0.0251 - learning_rate: 3.2768e-04\n",
      "Epoch 76/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0193 - mae: 0.0193\n",
      "Epoch 76: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0251 - val_mae: 0.0251 - learning_rate: 3.2768e-04\n",
      "Epoch 77/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0193 - mae: 0.0193\n",
      "Epoch 77: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0248 - val_mae: 0.0248 - learning_rate: 3.2768e-04\n",
      "Epoch 78/150\n",
      "\u001b[1m319/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0191 - mae: 0.0191\n",
      "Epoch 78: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0191 - mae: 0.0191 - val_loss: 0.0250 - val_mae: 0.0250 - learning_rate: 3.2768e-04\n",
      "Epoch 79/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0191 - mae: 0.0191\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 79: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0191 - mae: 0.0191 - val_loss: 0.0248 - val_mae: 0.0248 - learning_rate: 3.2768e-04\n",
      "Epoch 80/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0192 - mae: 0.0192\n",
      "Epoch 80: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.0250 - val_mae: 0.0250 - learning_rate: 2.6214e-04\n",
      "Epoch 81/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0191 - mae: 0.0191\n",
      "Epoch 81: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0191 - mae: 0.0191 - val_loss: 0.0253 - val_mae: 0.0253 - learning_rate: 2.6214e-04\n",
      "Epoch 82/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0193 - mae: 0.0193\n",
      "Epoch 82: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0248 - val_mae: 0.0248 - learning_rate: 2.6214e-04\n",
      "Epoch 83/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0192 - mae: 0.0192\n",
      "Epoch 83: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.0250 - val_mae: 0.0250 - learning_rate: 2.6214e-04\n",
      "Epoch 84/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0189 - mae: 0.0189\n",
      "Epoch 84: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0247 - val_mae: 0.0247 - learning_rate: 2.6214e-04\n",
      "Epoch 85/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0192 - mae: 0.0192\n",
      "Epoch 85: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.0249 - val_mae: 0.0249 - learning_rate: 2.6214e-04\n",
      "Epoch 86/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0192 - mae: 0.0192\n",
      "Epoch 86: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 2.6214e-04\n",
      "Epoch 87/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0194 - mae: 0.0194\n",
      "Epoch 87: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0255 - val_mae: 0.0255 - learning_rate: 2.6214e-04\n",
      "Epoch 88/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0190 - mae: 0.0190\n",
      "Epoch 88: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0250 - val_mae: 0.0250 - learning_rate: 2.6214e-04\n",
      "Epoch 89/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0193 - mae: 0.0193\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 89: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0250 - val_mae: 0.0250 - learning_rate: 2.6214e-04\n",
      "Epoch 90/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0190 - mae: 0.0190\n",
      "Epoch 90: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 2.0972e-04\n",
      "Epoch 91/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0190 - mae: 0.0190\n",
      "Epoch 91: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0251 - val_mae: 0.0251 - learning_rate: 2.0972e-04\n",
      "Epoch 92/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0190 - mae: 0.0190\n",
      "Epoch 92: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0253 - val_mae: 0.0253 - learning_rate: 2.0972e-04\n",
      "Epoch 93/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0189 - mae: 0.0189\n",
      "Epoch 93: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0251 - val_mae: 0.0251 - learning_rate: 2.0972e-04\n",
      "Epoch 94/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0189 - mae: 0.0189\n",
      "Epoch 94: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0249 - val_mae: 0.0249 - learning_rate: 2.0972e-04\n",
      "Epoch 95/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0192 - mae: 0.0192\n",
      "Epoch 95: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.0253 - val_mae: 0.0253 - learning_rate: 2.0972e-04\n",
      "Epoch 96/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0191 - mae: 0.0191\n",
      "Epoch 96: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0191 - mae: 0.0191 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 2.0972e-04\n",
      "Epoch 97/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0190 - mae: 0.0190\n",
      "Epoch 97: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0248 - val_mae: 0.0248 - learning_rate: 2.0972e-04\n",
      "Epoch 98/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0190 - mae: 0.0190\n",
      "Epoch 98: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0251 - val_mae: 0.0251 - learning_rate: 2.0972e-04\n",
      "Epoch 99/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0188\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 99: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 2.0972e-04\n",
      "Epoch 100/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0190 - mae: 0.0190\n",
      "Epoch 100: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0251 - val_mae: 0.0251 - learning_rate: 1.6777e-04\n",
      "Epoch 101/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0188\n",
      "Epoch 101: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0249 - val_mae: 0.0249 - learning_rate: 1.6777e-04\n",
      "Epoch 102/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0188\n",
      "Epoch 102: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0249 - val_mae: 0.0249 - learning_rate: 1.6777e-04\n",
      "Epoch 103/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0190 - mae: 0.0190\n",
      "Epoch 103: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 1.6777e-04\n",
      "Epoch 104/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0189 - mae: 0.0189\n",
      "Epoch 104: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0249 - val_mae: 0.0249 - learning_rate: 1.6777e-04\n",
      "Epoch 105/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0188\n",
      "Epoch 105: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0256 - val_mae: 0.0256 - learning_rate: 1.6777e-04\n",
      "Epoch 106/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0191 - mae: 0.0191\n",
      "Epoch 106: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0191 - mae: 0.0191 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 1.6777e-04\n",
      "Epoch 107/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0189 - mae: 0.0189\n",
      "Epoch 107: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 1.6777e-04\n",
      "Epoch 108/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0189 - mae: 0.0189\n",
      "Epoch 108: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0253 - val_mae: 0.0253 - learning_rate: 1.6777e-04\n",
      "Epoch 109/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0191 - mae: 0.0191\n",
      "Epoch 109: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 109: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0191 - mae: 0.0191 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 1.6777e-04\n",
      "Epoch 110/150\n",
      "\u001b[1m318/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0189 - mae: 0.0189\n",
      "Epoch 110: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0253 - val_mae: 0.0253 - learning_rate: 1.3422e-04\n",
      "Epoch 111/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0190 - mae: 0.0190\n",
      "Epoch 111: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0253 - val_mae: 0.0253 - learning_rate: 1.3422e-04\n",
      "Epoch 112/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0190 - mae: 0.0190\n",
      "Epoch 112: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 1.3422e-04\n",
      "Epoch 113/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0190 - mae: 0.0190\n",
      "Epoch 113: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0250 - val_mae: 0.0250 - learning_rate: 1.3422e-04\n",
      "Epoch 114/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0187 - mae: 0.0187\n",
      "Epoch 114: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0250 - val_mae: 0.0250 - learning_rate: 1.3422e-04\n",
      "Epoch 115/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0187 - mae: 0.0187\n",
      "Epoch 115: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0251 - val_mae: 0.0251 - learning_rate: 1.3422e-04\n",
      "Epoch 116/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0188\n",
      "Epoch 116: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0248 - val_mae: 0.0248 - learning_rate: 1.3422e-04\n",
      "Epoch 117/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0189 - mae: 0.0189\n",
      "Epoch 117: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0249 - val_mae: 0.0249 - learning_rate: 1.3422e-04\n",
      "Epoch 118/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0189 - mae: 0.0189\n",
      "Epoch 118: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0250 - val_mae: 0.0250 - learning_rate: 1.3422e-04\n",
      "Epoch 119/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0189 - mae: 0.0189\n",
      "Epoch 119: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 119: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0250 - val_mae: 0.0250 - learning_rate: 1.3422e-04\n",
      "Epoch 120/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0190 - mae: 0.0190\n",
      "Epoch 120: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0253 - val_mae: 0.0253 - learning_rate: 1.0737e-04\n",
      "Epoch 121/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0187 - mae: 0.0187\n",
      "Epoch 121: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 1.0737e-04\n",
      "Epoch 122/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0186 - mae: 0.0186\n",
      "Epoch 122: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 1.0737e-04\n",
      "Epoch 123/150\n",
      "\u001b[1m319/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0188\n",
      "Epoch 123: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 1.0737e-04\n",
      "Epoch 124/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0190 - mae: 0.0190\n",
      "Epoch 124: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0253 - val_mae: 0.0253 - learning_rate: 1.0737e-04\n",
      "Epoch 125/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0190 - mae: 0.0190\n",
      "Epoch 125: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0251 - val_mae: 0.0251 - learning_rate: 1.0737e-04\n",
      "Epoch 126/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0192 - mae: 0.0192\n",
      "Epoch 126: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.0250 - val_mae: 0.0250 - learning_rate: 1.0737e-04\n",
      "Epoch 127/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0190 - mae: 0.0190\n",
      "Epoch 127: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 1.0737e-04\n",
      "Epoch 128/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0188\n",
      "Epoch 128: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 1.0737e-04\n",
      "Epoch 129/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0187 - mae: 0.0187\n",
      "Epoch 129: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 129: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0253 - val_mae: 0.0253 - learning_rate: 1.0737e-04\n",
      "Epoch 130/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0188\n",
      "Epoch 130: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0253 - val_mae: 0.0253 - learning_rate: 8.5899e-05\n",
      "Epoch 131/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0191 - mae: 0.0191\n",
      "Epoch 131: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0191 - mae: 0.0191 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 8.5899e-05\n",
      "Epoch 132/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0188\n",
      "Epoch 132: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 8.5899e-05\n",
      "Epoch 133/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0189 - mae: 0.0189\n",
      "Epoch 133: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 8.5899e-05\n",
      "Epoch 134/150\n",
      "\u001b[1m318/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0186 - mae: 0.0186\n",
      "Epoch 134: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0250 - val_mae: 0.0250 - learning_rate: 8.5899e-05\n",
      "Epoch 135/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0188\n",
      "Epoch 135: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0248 - val_mae: 0.0248 - learning_rate: 8.5899e-05\n",
      "Epoch 136/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0188\n",
      "Epoch 136: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 8.5899e-05\n",
      "Epoch 137/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0189 - mae: 0.0189\n",
      "Epoch 137: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 8.5899e-05\n",
      "Epoch 138/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0187 - mae: 0.0187\n",
      "Epoch 138: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0255 - val_mae: 0.0255 - learning_rate: 8.5899e-05\n",
      "Epoch 139/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0189 - mae: 0.0189\n",
      "Epoch 139: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 139: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 8.5899e-05\n",
      "Epoch 140/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0188\n",
      "Epoch 140: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 6.8719e-05\n",
      "Epoch 141/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0189 - mae: 0.0189\n",
      "Epoch 141: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0251 - val_mae: 0.0251 - learning_rate: 6.8719e-05\n",
      "Epoch 142/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0188\n",
      "Epoch 142: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 6.8719e-05\n",
      "Epoch 143/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0188\n",
      "Epoch 143: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 6.8719e-05\n",
      "Epoch 144/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0187 - mae: 0.0187\n",
      "Epoch 144: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 6.8719e-05\n",
      "Epoch 145/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0188\n",
      "Epoch 145: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0253 - val_mae: 0.0253 - learning_rate: 6.8719e-05\n",
      "Epoch 146/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0189 - mae: 0.0189\n",
      "Epoch 146: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 6.8719e-05\n",
      "Epoch 147/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0188\n",
      "Epoch 147: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 6.8719e-05\n",
      "Epoch 148/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0188\n",
      "Epoch 148: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 6.8719e-05\n",
      "Epoch 149/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0187 - mae: 0.0187\n",
      "Epoch 149: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "\n",
      "Epoch 149: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0251 - val_mae: 0.0251 - learning_rate: 6.8719e-05\n",
      "Epoch 150/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0188\n",
      "Epoch 150: val_mae did not improve from 0.02227\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 5.4976e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mae', 'val_loss', 'val_mae', 'learning_rate'])\n",
      "✅ Loaded saved model from: best_model_2_6.h5\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "📊 Evaluation Metrics:\n",
      "MAE:  0.8759\n",
      "RMSE: 1.4130\n",
      "MAPE: 37.00%\n",
      "\n",
      "🔁 Training with lookback=6, horizon=1\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janav\\.pyenv\\pyenv-win\\versions\\3.10.6\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0493 - mae: 0.0493\n",
      "Epoch 1: val_mae improved from inf to 0.01887, saving model to best_model_6_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0489 - mae: 0.0489 - val_loss: 0.0189 - val_mae: 0.0189 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0216 - mae: 0.0216\n",
      "Epoch 2: val_mae improved from 0.01887 to 0.01608, saving model to best_model_6_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0216 - mae: 0.0216 - val_loss: 0.0161 - val_mae: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0185 - mae: 0.0185\n",
      "Epoch 3: val_mae improved from 0.01608 to 0.01421, saving model to best_model_6_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0142 - val_mae: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0168 - mae: 0.0168\n",
      "Epoch 4: val_mae improved from 0.01421 to 0.01355, saving model to best_model_6_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0135 - val_mae: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0155 - mae: 0.0155\n",
      "Epoch 5: val_mae improved from 0.01355 to 0.01288, saving model to best_model_6_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0129 - val_mae: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0148 - mae: 0.0148\n",
      "Epoch 6: val_mae improved from 0.01288 to 0.01219, saving model to best_model_6_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0148 - mae: 0.0148 - val_loss: 0.0122 - val_mae: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0142 - mae: 0.0142\n",
      "Epoch 7: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.0130 - val_mae: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0139 - mae: 0.0139\n",
      "Epoch 8: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0124 - val_mae: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0132 - mae: 0.0132\n",
      "Epoch 9: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0153 - val_mae: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0134 - mae: 0.0134\n",
      "Epoch 10: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0122 - val_mae: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0129 - mae: 0.0129\n",
      "Epoch 11: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0140 - val_mae: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0124 - mae: 0.0124\n",
      "Epoch 12: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0140 - val_mae: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 13: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0140 - val_mae: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0124 - mae: 0.0124\n",
      "Epoch 14: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0136 - val_mae: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 15/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 15: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0147 - val_mae: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 16/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0119\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 16: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0159 - val_mae: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 17/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0117\n",
      "Epoch 17: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0154 - val_mae: 0.0154 - learning_rate: 8.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0114 - mae: 0.0114\n",
      "Epoch 18: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0146 - val_mae: 0.0146 - learning_rate: 8.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0112 - mae: 0.0112\n",
      "Epoch 19: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0164 - val_mae: 0.0164 - learning_rate: 8.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0113 - mae: 0.0113\n",
      "Epoch 20: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0156 - val_mae: 0.0156 - learning_rate: 8.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0110 - mae: 0.0110\n",
      "Epoch 21: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0160 - val_mae: 0.0160 - learning_rate: 8.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0110 - mae: 0.0110\n",
      "Epoch 22: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0161 - val_mae: 0.0161 - learning_rate: 8.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0108 - mae: 0.0108\n",
      "Epoch 23: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0177 - val_mae: 0.0177 - learning_rate: 8.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0106 - mae: 0.0106\n",
      "Epoch 24: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0166 - val_mae: 0.0166 - learning_rate: 8.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0109 - mae: 0.0109\n",
      "Epoch 25: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0175 - val_mae: 0.0175 - learning_rate: 8.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0108 - mae: 0.0108\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 26: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0168 - val_mae: 0.0168 - learning_rate: 8.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0106 - mae: 0.0106\n",
      "Epoch 27: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0173 - val_mae: 0.0173 - learning_rate: 6.4000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0107 - mae: 0.0107\n",
      "Epoch 28: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0107 - mae: 0.0107 - val_loss: 0.0166 - val_mae: 0.0166 - learning_rate: 6.4000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0104 - mae: 0.0104\n",
      "Epoch 29: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0172 - val_mae: 0.0172 - learning_rate: 6.4000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0102 - mae: 0.0102\n",
      "Epoch 30: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0168 - val_mae: 0.0168 - learning_rate: 6.4000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0104 - mae: 0.0104\n",
      "Epoch 31: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0173 - val_mae: 0.0173 - learning_rate: 6.4000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0101 - mae: 0.0101\n",
      "Epoch 32: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0180 - val_mae: 0.0180 - learning_rate: 6.4000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0101 - mae: 0.0101\n",
      "Epoch 33: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0175 - val_mae: 0.0175 - learning_rate: 6.4000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0102 - mae: 0.0102\n",
      "Epoch 34: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0183 - val_mae: 0.0183 - learning_rate: 6.4000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0100 - mae: 0.0100\n",
      "Epoch 35: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0176 - val_mae: 0.0176 - learning_rate: 6.4000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0100 - mae: 0.0100\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 36: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0184 - val_mae: 0.0184 - learning_rate: 6.4000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0101 - mae: 0.0101\n",
      "Epoch 37: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0178 - val_mae: 0.0178 - learning_rate: 5.1200e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0099 - mae: 0.0099\n",
      "Epoch 38: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0181 - val_mae: 0.0181 - learning_rate: 5.1200e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0100 - mae: 0.0100\n",
      "Epoch 39: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0183 - val_mae: 0.0183 - learning_rate: 5.1200e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0100 - mae: 0.0100\n",
      "Epoch 40: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0185 - val_mae: 0.0185 - learning_rate: 5.1200e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0099 - mae: 0.0099\n",
      "Epoch 41: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0187 - val_mae: 0.0187 - learning_rate: 5.1200e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0098 - mae: 0.0098\n",
      "Epoch 42: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0189 - val_mae: 0.0189 - learning_rate: 5.1200e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0099 - mae: 0.0099\n",
      "Epoch 43: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0191 - val_mae: 0.0191 - learning_rate: 5.1200e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0098 - mae: 0.0098\n",
      "Epoch 44: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0183 - val_mae: 0.0183 - learning_rate: 5.1200e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0100 - mae: 0.0100\n",
      "Epoch 45: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0200 - val_mae: 0.0200 - learning_rate: 5.1200e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0099 - mae: 0.0099\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 46: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0188 - val_mae: 0.0188 - learning_rate: 5.1200e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0096 - mae: 0.0096\n",
      "Epoch 47: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0181 - val_mae: 0.0181 - learning_rate: 4.0960e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0095\n",
      "Epoch 48: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0188 - val_mae: 0.0188 - learning_rate: 4.0960e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0097 - mae: 0.0097\n",
      "Epoch 49: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0186 - val_mae: 0.0186 - learning_rate: 4.0960e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0095\n",
      "Epoch 50: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0186 - val_mae: 0.0186 - learning_rate: 4.0960e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0096 - mae: 0.0096\n",
      "Epoch 51: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0189 - val_mae: 0.0189 - learning_rate: 4.0960e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0095\n",
      "Epoch 52: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0188 - val_mae: 0.0188 - learning_rate: 4.0960e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0095\n",
      "Epoch 53: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0193 - val_mae: 0.0193 - learning_rate: 4.0960e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0094 - mae: 0.0094\n",
      "Epoch 54: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0186 - val_mae: 0.0186 - learning_rate: 4.0960e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0096 - mae: 0.0096\n",
      "Epoch 55: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0194 - val_mae: 0.0194 - learning_rate: 4.0960e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0095\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 56: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0191 - val_mae: 0.0191 - learning_rate: 4.0960e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0095\n",
      "Epoch 57: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0195 - val_mae: 0.0195 - learning_rate: 3.2768e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0094 - mae: 0.0094\n",
      "Epoch 58: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0194 - val_mae: 0.0194 - learning_rate: 3.2768e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0094 - mae: 0.0094\n",
      "Epoch 59: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0194 - val_mae: 0.0194 - learning_rate: 3.2768e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0094 - mae: 0.0094\n",
      "Epoch 60: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0198 - val_mae: 0.0198 - learning_rate: 3.2768e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0095\n",
      "Epoch 61: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0195 - val_mae: 0.0195 - learning_rate: 3.2768e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 62: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0201 - val_mae: 0.0201 - learning_rate: 3.2768e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 63: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0190 - val_mae: 0.0190 - learning_rate: 3.2768e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 64: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0197 - val_mae: 0.0197 - learning_rate: 3.2768e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 65: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0193 - val_mae: 0.0193 - learning_rate: 3.2768e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 66: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0195 - val_mae: 0.0195 - learning_rate: 3.2768e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 67: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0193 - val_mae: 0.0193 - learning_rate: 2.6214e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 68: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0198 - val_mae: 0.0198 - learning_rate: 2.6214e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 69: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0193 - val_mae: 0.0193 - learning_rate: 2.6214e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 70: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0194 - val_mae: 0.0194 - learning_rate: 2.6214e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 71: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0197 - val_mae: 0.0197 - learning_rate: 2.6214e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 72: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0200 - val_mae: 0.0200 - learning_rate: 2.6214e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 73: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0198 - val_mae: 0.0198 - learning_rate: 2.6214e-04\n",
      "Epoch 74/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 74: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0201 - val_mae: 0.0201 - learning_rate: 2.6214e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 75: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0196 - val_mae: 0.0196 - learning_rate: 2.6214e-04\n",
      "Epoch 76/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 76: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0192 - val_mae: 0.0192 - learning_rate: 2.6214e-04\n",
      "Epoch 77/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 77: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0198 - val_mae: 0.0198 - learning_rate: 2.0972e-04\n",
      "Epoch 78/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 78: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0197 - val_mae: 0.0197 - learning_rate: 2.0972e-04\n",
      "Epoch 79/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 79: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0196 - val_mae: 0.0196 - learning_rate: 2.0972e-04\n",
      "Epoch 80/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 80: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0198 - val_mae: 0.0198 - learning_rate: 2.0972e-04\n",
      "Epoch 81/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090\n",
      "Epoch 81: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0192 - val_mae: 0.0192 - learning_rate: 2.0972e-04\n",
      "Epoch 82/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090\n",
      "Epoch 82: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0198 - val_mae: 0.0198 - learning_rate: 2.0972e-04\n",
      "Epoch 83/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 83: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0202 - val_mae: 0.0202 - learning_rate: 2.0972e-04\n",
      "Epoch 84/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 84: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0198 - val_mae: 0.0198 - learning_rate: 2.0972e-04\n",
      "Epoch 85/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 85: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0198 - val_mae: 0.0198 - learning_rate: 2.0972e-04\n",
      "Epoch 86/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 86: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0197 - val_mae: 0.0197 - learning_rate: 2.0972e-04\n",
      "Epoch 87/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089\n",
      "Epoch 87: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0203 - val_mae: 0.0203 - learning_rate: 1.6777e-04\n",
      "Epoch 88/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 88: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0197 - val_mae: 0.0197 - learning_rate: 1.6777e-04\n",
      "Epoch 89/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089\n",
      "Epoch 89: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0199 - val_mae: 0.0199 - learning_rate: 1.6777e-04\n",
      "Epoch 90/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090\n",
      "Epoch 90: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0204 - val_mae: 0.0204 - learning_rate: 1.6777e-04\n",
      "Epoch 91/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089\n",
      "Epoch 91: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0199 - val_mae: 0.0199 - learning_rate: 1.6777e-04\n",
      "Epoch 92/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089\n",
      "Epoch 92: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0200 - val_mae: 0.0200 - learning_rate: 1.6777e-04\n",
      "Epoch 93/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090\n",
      "Epoch 93: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0200 - val_mae: 0.0200 - learning_rate: 1.6777e-04\n",
      "Epoch 94/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089\n",
      "Epoch 94: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0204 - val_mae: 0.0204 - learning_rate: 1.6777e-04\n",
      "Epoch 95/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 95: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0201 - val_mae: 0.0201 - learning_rate: 1.6777e-04\n",
      "Epoch 96/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0088\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 96: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0200 - val_mae: 0.0200 - learning_rate: 1.6777e-04\n",
      "Epoch 97/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0088\n",
      "Epoch 97: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0202 - val_mae: 0.0202 - learning_rate: 1.3422e-04\n",
      "Epoch 98/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089\n",
      "Epoch 98: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0203 - val_mae: 0.0203 - learning_rate: 1.3422e-04\n",
      "Epoch 99/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090\n",
      "Epoch 99: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0205 - val_mae: 0.0205 - learning_rate: 1.3422e-04\n",
      "Epoch 100/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089\n",
      "Epoch 100: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0203 - val_mae: 0.0203 - learning_rate: 1.3422e-04\n",
      "Epoch 101/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090\n",
      "Epoch 101: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0202 - val_mae: 0.0202 - learning_rate: 1.3422e-04\n",
      "Epoch 102/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089\n",
      "Epoch 102: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0200 - val_mae: 0.0200 - learning_rate: 1.3422e-04\n",
      "Epoch 103/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089\n",
      "Epoch 103: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0205 - val_mae: 0.0205 - learning_rate: 1.3422e-04\n",
      "Epoch 104/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - mae: 0.0087\n",
      "Epoch 104: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0203 - val_mae: 0.0203 - learning_rate: 1.3422e-04\n",
      "Epoch 105/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089\n",
      "Epoch 105: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0201 - val_mae: 0.0201 - learning_rate: 1.3422e-04\n",
      "Epoch 106/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0088\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 106: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0197 - val_mae: 0.0197 - learning_rate: 1.3422e-04\n",
      "Epoch 107/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090\n",
      "Epoch 107: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0201 - val_mae: 0.0201 - learning_rate: 1.0737e-04\n",
      "Epoch 108/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0088\n",
      "Epoch 108: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0200 - val_mae: 0.0200 - learning_rate: 1.0737e-04\n",
      "Epoch 109/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0088\n",
      "Epoch 109: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0203 - val_mae: 0.0203 - learning_rate: 1.0737e-04\n",
      "Epoch 110/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089\n",
      "Epoch 110: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0208 - val_mae: 0.0208 - learning_rate: 1.0737e-04\n",
      "Epoch 111/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - mae: 0.0087\n",
      "Epoch 111: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0200 - val_mae: 0.0200 - learning_rate: 1.0737e-04\n",
      "Epoch 112/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0088\n",
      "Epoch 112: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0201 - val_mae: 0.0201 - learning_rate: 1.0737e-04\n",
      "Epoch 113/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - mae: 0.0087\n",
      "Epoch 113: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0205 - val_mae: 0.0205 - learning_rate: 1.0737e-04\n",
      "Epoch 114/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0088\n",
      "Epoch 114: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0200 - val_mae: 0.0200 - learning_rate: 1.0737e-04\n",
      "Epoch 115/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - mae: 0.0087\n",
      "Epoch 115: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0200 - val_mae: 0.0200 - learning_rate: 1.0737e-04\n",
      "Epoch 116/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0088\n",
      "Epoch 116: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 116: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0201 - val_mae: 0.0201 - learning_rate: 1.0737e-04\n",
      "Epoch 117/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089\n",
      "Epoch 117: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0203 - val_mae: 0.0203 - learning_rate: 8.5899e-05\n",
      "Epoch 118/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - mae: 0.0087\n",
      "Epoch 118: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0199 - val_mae: 0.0199 - learning_rate: 8.5899e-05\n",
      "Epoch 119/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089\n",
      "Epoch 119: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0207 - val_mae: 0.0207 - learning_rate: 8.5899e-05\n",
      "Epoch 120/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0088\n",
      "Epoch 120: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0202 - val_mae: 0.0202 - learning_rate: 8.5899e-05\n",
      "Epoch 121/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - mae: 0.0087\n",
      "Epoch 121: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0202 - val_mae: 0.0202 - learning_rate: 8.5899e-05\n",
      "Epoch 122/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0088\n",
      "Epoch 122: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0202 - val_mae: 0.0202 - learning_rate: 8.5899e-05\n",
      "Epoch 123/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0086 - mae: 0.0086\n",
      "Epoch 123: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0199 - val_mae: 0.0199 - learning_rate: 8.5899e-05\n",
      "Epoch 124/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - mae: 0.0087\n",
      "Epoch 124: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0201 - val_mae: 0.0201 - learning_rate: 8.5899e-05\n",
      "Epoch 125/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - mae: 0.0087\n",
      "Epoch 125: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0201 - val_mae: 0.0201 - learning_rate: 8.5899e-05\n",
      "Epoch 126/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089\n",
      "Epoch 126: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 126: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0202 - val_mae: 0.0202 - learning_rate: 8.5899e-05\n",
      "Epoch 127/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - mae: 0.0087\n",
      "Epoch 127: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0203 - val_mae: 0.0203 - learning_rate: 6.8719e-05\n",
      "Epoch 128/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - mae: 0.0087\n",
      "Epoch 128: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0202 - val_mae: 0.0202 - learning_rate: 6.8719e-05\n",
      "Epoch 129/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089\n",
      "Epoch 129: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0202 - val_mae: 0.0202 - learning_rate: 6.8719e-05\n",
      "Epoch 130/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0088\n",
      "Epoch 130: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0203 - val_mae: 0.0203 - learning_rate: 6.8719e-05\n",
      "Epoch 131/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0088\n",
      "Epoch 131: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0204 - val_mae: 0.0204 - learning_rate: 6.8719e-05\n",
      "Epoch 132/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089\n",
      "Epoch 132: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0201 - val_mae: 0.0201 - learning_rate: 6.8719e-05\n",
      "Epoch 133/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0088\n",
      "Epoch 133: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0204 - val_mae: 0.0204 - learning_rate: 6.8719e-05\n",
      "Epoch 134/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0086 - mae: 0.0086\n",
      "Epoch 134: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0203 - val_mae: 0.0203 - learning_rate: 6.8719e-05\n",
      "Epoch 135/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - mae: 0.0087\n",
      "Epoch 135: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0204 - val_mae: 0.0204 - learning_rate: 6.8719e-05\n",
      "Epoch 136/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090\n",
      "Epoch 136: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "\n",
      "Epoch 136: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0205 - val_mae: 0.0205 - learning_rate: 6.8719e-05\n",
      "Epoch 137/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0086 - mae: 0.0086\n",
      "Epoch 137: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0204 - val_mae: 0.0204 - learning_rate: 5.4976e-05\n",
      "Epoch 138/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0086 - mae: 0.0086\n",
      "Epoch 138: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0203 - val_mae: 0.0203 - learning_rate: 5.4976e-05\n",
      "Epoch 139/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0086 - mae: 0.0086\n",
      "Epoch 139: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0201 - val_mae: 0.0201 - learning_rate: 5.4976e-05\n",
      "Epoch 140/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - mae: 0.0087\n",
      "Epoch 140: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0204 - val_mae: 0.0204 - learning_rate: 5.4976e-05\n",
      "Epoch 141/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0086 - mae: 0.0086\n",
      "Epoch 141: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0202 - val_mae: 0.0202 - learning_rate: 5.4976e-05\n",
      "Epoch 142/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0088\n",
      "Epoch 142: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0207 - val_mae: 0.0207 - learning_rate: 5.4976e-05\n",
      "Epoch 143/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - mae: 0.0087\n",
      "Epoch 143: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0206 - val_mae: 0.0206 - learning_rate: 5.4976e-05\n",
      "Epoch 144/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - mae: 0.0087\n",
      "Epoch 144: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0202 - val_mae: 0.0202 - learning_rate: 5.4976e-05\n",
      "Epoch 145/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0086 - mae: 0.0086\n",
      "Epoch 145: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0203 - val_mae: 0.0203 - learning_rate: 5.4976e-05\n",
      "Epoch 146/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - mae: 0.0087\n",
      "Epoch 146: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "\n",
      "Epoch 146: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0206 - val_mae: 0.0206 - learning_rate: 5.4976e-05\n",
      "Epoch 147/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089\n",
      "Epoch 147: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0203 - val_mae: 0.0203 - learning_rate: 4.3980e-05\n",
      "Epoch 148/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0085 - mae: 0.0085\n",
      "Epoch 148: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0202 - val_mae: 0.0202 - learning_rate: 4.3980e-05\n",
      "Epoch 149/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0088\n",
      "Epoch 149: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0201 - val_mae: 0.0201 - learning_rate: 4.3980e-05\n",
      "Epoch 150/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0088\n",
      "Epoch 150: val_mae did not improve from 0.01219\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0203 - val_mae: 0.0203 - learning_rate: 4.3980e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mae', 'val_loss', 'val_mae', 'learning_rate'])\n",
      "✅ Loaded saved model from: best_model_6_1.h5\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "📊 Evaluation Metrics:\n",
      "MAE:  0.4739\n",
      "RMSE: 0.8161\n",
      "MAPE: 21.06%\n",
      "\n",
      "🔁 Training with lookback=6, horizon=2\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janav\\.pyenv\\pyenv-win\\versions\\3.10.6\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0515 - mae: 0.0515\n",
      "Epoch 1: val_mae improved from inf to 0.02156, saving model to best_model_6_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0514 - mae: 0.0514 - val_loss: 0.0216 - val_mae: 0.0216 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0238 - mae: 0.0238\n",
      "Epoch 2: val_mae improved from 0.02156 to 0.01968, saving model to best_model_6_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0238 - mae: 0.0238 - val_loss: 0.0197 - val_mae: 0.0197 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0211 - mae: 0.0211\n",
      "Epoch 3: val_mae improved from 0.01968 to 0.01797, saving model to best_model_6_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0211 - mae: 0.0211 - val_loss: 0.0180 - val_mae: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0192 - mae: 0.0192\n",
      "Epoch 4: val_mae did not improve from 0.01797\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.0191 - val_mae: 0.0191 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0177 - mae: 0.0177\n",
      "Epoch 5: val_mae improved from 0.01797 to 0.01675, saving model to best_model_6_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0167 - val_mae: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0168 - mae: 0.0168\n",
      "Epoch 6: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0184 - val_mae: 0.0184 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0167 - mae: 0.0167\n",
      "Epoch 7: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0197 - val_mae: 0.0197 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0159 - mae: 0.0159\n",
      "Epoch 8: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0200 - val_mae: 0.0200 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0156 - mae: 0.0156\n",
      "Epoch 9: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0193 - val_mae: 0.0193 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0154 - mae: 0.0154\n",
      "Epoch 10: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0154 - mae: 0.0154 - val_loss: 0.0222 - val_mae: 0.0222 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0152 - mae: 0.0152\n",
      "Epoch 11: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.0215 - val_mae: 0.0215 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0151 - mae: 0.0151\n",
      "Epoch 12: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.0183 - val_mae: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0146 - mae: 0.0146\n",
      "Epoch 13: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0220 - val_mae: 0.0220 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0147 - mae: 0.0147\n",
      "Epoch 14: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0213 - val_mae: 0.0213 - learning_rate: 0.0010\n",
      "Epoch 15/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0144 - mae: 0.0144\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 15: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0203 - val_mae: 0.0203 - learning_rate: 0.0010\n",
      "Epoch 16/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0140 - mae: 0.0140\n",
      "Epoch 16: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0196 - val_mae: 0.0196 - learning_rate: 8.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0140 - mae: 0.0140\n",
      "Epoch 17: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0222 - val_mae: 0.0222 - learning_rate: 8.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0138 - mae: 0.0138\n",
      "Epoch 18: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0218 - val_mae: 0.0218 - learning_rate: 8.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0138 - mae: 0.0138\n",
      "Epoch 19: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0220 - val_mae: 0.0220 - learning_rate: 8.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0135 - mae: 0.0135\n",
      "Epoch 20: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0225 - val_mae: 0.0225 - learning_rate: 8.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0137 - mae: 0.0137\n",
      "Epoch 21: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0224 - val_mae: 0.0224 - learning_rate: 8.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0136 - mae: 0.0136\n",
      "Epoch 22: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0221 - val_mae: 0.0221 - learning_rate: 8.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0137 - mae: 0.0137\n",
      "Epoch 23: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0213 - val_mae: 0.0213 - learning_rate: 8.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0135 - mae: 0.0135\n",
      "Epoch 24: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0212 - val_mae: 0.0212 - learning_rate: 8.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0136 - mae: 0.0136\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 25: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0241 - val_mae: 0.0241 - learning_rate: 8.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0133 - mae: 0.0133\n",
      "Epoch 26: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0230 - val_mae: 0.0230 - learning_rate: 6.4000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0132 - mae: 0.0132\n",
      "Epoch 27: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0230 - val_mae: 0.0230 - learning_rate: 6.4000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 28: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0233 - val_mae: 0.0233 - learning_rate: 6.4000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 29: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0233 - val_mae: 0.0233 - learning_rate: 6.4000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0131 - mae: 0.0131\n",
      "Epoch 30: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0220 - val_mae: 0.0220 - learning_rate: 6.4000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0131 - mae: 0.0131\n",
      "Epoch 31: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0218 - val_mae: 0.0218 - learning_rate: 6.4000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 32: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 6.4000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 33: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0226 - val_mae: 0.0226 - learning_rate: 6.4000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0131 - mae: 0.0131\n",
      "Epoch 34: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0233 - val_mae: 0.0233 - learning_rate: 6.4000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0131 - mae: 0.0131\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 35: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 6.4000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 36: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0229 - val_mae: 0.0229 - learning_rate: 5.1200e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0127 - mae: 0.0127\n",
      "Epoch 37: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0218 - val_mae: 0.0218 - learning_rate: 5.1200e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0127 - mae: 0.0127\n",
      "Epoch 38: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0230 - val_mae: 0.0230 - learning_rate: 5.1200e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0127 - mae: 0.0127\n",
      "Epoch 39: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 5.1200e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0126 - mae: 0.0126\n",
      "Epoch 40: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0221 - val_mae: 0.0221 - learning_rate: 5.1200e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0127 - mae: 0.0127\n",
      "Epoch 41: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0222 - val_mae: 0.0222 - learning_rate: 5.1200e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0127 - mae: 0.0127\n",
      "Epoch 42: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0245 - val_mae: 0.0245 - learning_rate: 5.1200e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0126 - mae: 0.0126\n",
      "Epoch 43: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 5.1200e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0124 - mae: 0.0124\n",
      "Epoch 44: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0229 - val_mae: 0.0229 - learning_rate: 5.1200e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0126 - mae: 0.0126\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 45: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0215 - val_mae: 0.0215 - learning_rate: 5.1200e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0127 - mae: 0.0127\n",
      "Epoch 46: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 4.0960e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 47: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 4.0960e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 48: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 4.0960e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0124 - mae: 0.0124\n",
      "Epoch 49: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0245 - val_mae: 0.0245 - learning_rate: 4.0960e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0126 - mae: 0.0126\n",
      "Epoch 50: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 4.0960e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0124 - mae: 0.0124\n",
      "Epoch 51: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 4.0960e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 52: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0232 - val_mae: 0.0232 - learning_rate: 4.0960e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0124 - mae: 0.0124\n",
      "Epoch 53: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 4.0960e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 54: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0230 - val_mae: 0.0230 - learning_rate: 4.0960e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0127 - mae: 0.0127\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 55: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0227 - val_mae: 0.0227 - learning_rate: 4.0960e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 56: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0230 - val_mae: 0.0230 - learning_rate: 3.2768e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 57: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0232 - val_mae: 0.0232 - learning_rate: 3.2768e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0122 - mae: 0.0122\n",
      "Epoch 58: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0230 - val_mae: 0.0230 - learning_rate: 3.2768e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 59: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0233 - val_mae: 0.0233 - learning_rate: 3.2768e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0122 - mae: 0.0122\n",
      "Epoch 60: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0228 - val_mae: 0.0228 - learning_rate: 3.2768e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 61: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 3.2768e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0122 - mae: 0.0122\n",
      "Epoch 62: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 3.2768e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 63: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 3.2768e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 64: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0241 - val_mae: 0.0241 - learning_rate: 3.2768e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 65: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 3.2768e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 66: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0226 - val_mae: 0.0226 - learning_rate: 2.6214e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 67: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0242 - val_mae: 0.0242 - learning_rate: 2.6214e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 68: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0232 - val_mae: 0.0232 - learning_rate: 2.6214e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 69: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0242 - val_mae: 0.0242 - learning_rate: 2.6214e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0122 - mae: 0.0122\n",
      "Epoch 70: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 2.6214e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 71: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0241 - val_mae: 0.0241 - learning_rate: 2.6214e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 72: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 2.6214e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 73: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0241 - val_mae: 0.0241 - learning_rate: 2.6214e-04\n",
      "Epoch 74/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 74: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 2.6214e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 75: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 2.6214e-04\n",
      "Epoch 76/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0119\n",
      "Epoch 76: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0232 - val_mae: 0.0232 - learning_rate: 2.0972e-04\n",
      "Epoch 77/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0119\n",
      "Epoch 77: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 2.0972e-04\n",
      "Epoch 78/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 78: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0230 - val_mae: 0.0230 - learning_rate: 2.0972e-04\n",
      "Epoch 79/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 79: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 2.0972e-04\n",
      "Epoch 80/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0119\n",
      "Epoch 80: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 2.0972e-04\n",
      "Epoch 81/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 81: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 2.0972e-04\n",
      "Epoch 82/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 82: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0230 - val_mae: 0.0230 - learning_rate: 2.0972e-04\n",
      "Epoch 83/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0122 - mae: 0.0122\n",
      "Epoch 83: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0241 - val_mae: 0.0241 - learning_rate: 2.0972e-04\n",
      "Epoch 84/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0119\n",
      "Epoch 84: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0243 - val_mae: 0.0243 - learning_rate: 2.0972e-04\n",
      "Epoch 85/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 85: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0239 - val_mae: 0.0239 - learning_rate: 2.0972e-04\n",
      "Epoch 86/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 86: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0241 - val_mae: 0.0241 - learning_rate: 1.6777e-04\n",
      "Epoch 87/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 87: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 1.6777e-04\n",
      "Epoch 88/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0117\n",
      "Epoch 88: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 1.6777e-04\n",
      "Epoch 89/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 89: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0241 - val_mae: 0.0241 - learning_rate: 1.6777e-04\n",
      "Epoch 90/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 90: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0236 - val_mae: 0.0236 - learning_rate: 1.6777e-04\n",
      "Epoch 91/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0119\n",
      "Epoch 91: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0236 - val_mae: 0.0236 - learning_rate: 1.6777e-04\n",
      "Epoch 92/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0119\n",
      "Epoch 92: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 1.6777e-04\n",
      "Epoch 93/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0116\n",
      "Epoch 93: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 1.6777e-04\n",
      "Epoch 94/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0119\n",
      "Epoch 94: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 1.6777e-04\n",
      "Epoch 95/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0119\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 95: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0232 - val_mae: 0.0232 - learning_rate: 1.6777e-04\n",
      "Epoch 96/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 96: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 1.3422e-04\n",
      "Epoch 97/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0119\n",
      "Epoch 97: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 1.3422e-04\n",
      "Epoch 98/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0117\n",
      "Epoch 98: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 1.3422e-04\n",
      "Epoch 99/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 99: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0239 - val_mae: 0.0239 - learning_rate: 1.3422e-04\n",
      "Epoch 100/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0119\n",
      "Epoch 100: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 1.3422e-04\n",
      "Epoch 101/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 101: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 1.3422e-04\n",
      "Epoch 102/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 102: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 1.3422e-04\n",
      "Epoch 103/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0119\n",
      "Epoch 103: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 1.3422e-04\n",
      "Epoch 104/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 104: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0239 - val_mae: 0.0239 - learning_rate: 1.3422e-04\n",
      "Epoch 105/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 105: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0236 - val_mae: 0.0236 - learning_rate: 1.3422e-04\n",
      "Epoch 106/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0116\n",
      "Epoch 106: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0236 - val_mae: 0.0236 - learning_rate: 1.0737e-04\n",
      "Epoch 107/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0116\n",
      "Epoch 107: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 1.0737e-04\n",
      "Epoch 108/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0119\n",
      "Epoch 108: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0236 - val_mae: 0.0236 - learning_rate: 1.0737e-04\n",
      "Epoch 109/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0117\n",
      "Epoch 109: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 1.0737e-04\n",
      "Epoch 110/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0115 - mae: 0.0115\n",
      "Epoch 110: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 1.0737e-04\n",
      "Epoch 111/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0117\n",
      "Epoch 111: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0236 - val_mae: 0.0236 - learning_rate: 1.0737e-04\n",
      "Epoch 112/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0116\n",
      "Epoch 112: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 1.0737e-04\n",
      "Epoch 113/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0117\n",
      "Epoch 113: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 1.0737e-04\n",
      "Epoch 114/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0117\n",
      "Epoch 114: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 1.0737e-04\n",
      "Epoch 115/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0116\n",
      "Epoch 115: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 115: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0239 - val_mae: 0.0239 - learning_rate: 1.0737e-04\n",
      "Epoch 116/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 116: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0239 - val_mae: 0.0239 - learning_rate: 8.5899e-05\n",
      "Epoch 117/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0116\n",
      "Epoch 117: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 8.5899e-05\n",
      "Epoch 118/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0117\n",
      "Epoch 118: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 8.5899e-05\n",
      "Epoch 119/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0116\n",
      "Epoch 119: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 8.5899e-05\n",
      "Epoch 120/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 120: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0243 - val_mae: 0.0243 - learning_rate: 8.5899e-05\n",
      "Epoch 121/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0117\n",
      "Epoch 121: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 8.5899e-05\n",
      "Epoch 122/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 122: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 8.5899e-05\n",
      "Epoch 123/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0116\n",
      "Epoch 123: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0242 - val_mae: 0.0242 - learning_rate: 8.5899e-05\n",
      "Epoch 124/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0116\n",
      "Epoch 124: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0239 - val_mae: 0.0239 - learning_rate: 8.5899e-05\n",
      "Epoch 125/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0115 - mae: 0.0115\n",
      "Epoch 125: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 125: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0241 - val_mae: 0.0241 - learning_rate: 8.5899e-05\n",
      "Epoch 126/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0117\n",
      "Epoch 126: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0239 - val_mae: 0.0239 - learning_rate: 6.8719e-05\n",
      "Epoch 127/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 127: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0241 - val_mae: 0.0241 - learning_rate: 6.8719e-05\n",
      "Epoch 128/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0115 - mae: 0.0115\n",
      "Epoch 128: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0243 - val_mae: 0.0243 - learning_rate: 6.8719e-05\n",
      "Epoch 129/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0116\n",
      "Epoch 129: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 6.8719e-05\n",
      "Epoch 130/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0117\n",
      "Epoch 130: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0239 - val_mae: 0.0239 - learning_rate: 6.8719e-05\n",
      "Epoch 131/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0116\n",
      "Epoch 131: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 6.8719e-05\n",
      "Epoch 132/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0114 - mae: 0.0114\n",
      "Epoch 132: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 6.8719e-05\n",
      "Epoch 133/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0115 - mae: 0.0115\n",
      "Epoch 133: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 6.8719e-05\n",
      "Epoch 134/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 134: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0239 - val_mae: 0.0239 - learning_rate: 6.8719e-05\n",
      "Epoch 135/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0117\n",
      "Epoch 135: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "\n",
      "Epoch 135: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 6.8719e-05\n",
      "Epoch 136/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0116\n",
      "Epoch 136: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0239 - val_mae: 0.0239 - learning_rate: 5.4976e-05\n",
      "Epoch 137/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0117\n",
      "Epoch 137: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 5.4976e-05\n",
      "Epoch 138/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0116\n",
      "Epoch 138: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 5.4976e-05\n",
      "Epoch 139/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0113 - mae: 0.0113\n",
      "Epoch 139: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 5.4976e-05\n",
      "Epoch 140/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0116\n",
      "Epoch 140: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 5.4976e-05\n",
      "Epoch 141/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0114 - mae: 0.0114\n",
      "Epoch 141: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 5.4976e-05\n",
      "Epoch 142/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0116\n",
      "Epoch 142: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 5.4976e-05\n",
      "Epoch 143/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0116\n",
      "Epoch 143: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 5.4976e-05\n",
      "Epoch 144/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0117\n",
      "Epoch 144: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0239 - val_mae: 0.0239 - learning_rate: 5.4976e-05\n",
      "Epoch 145/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0116\n",
      "Epoch 145: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "\n",
      "Epoch 145: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 5.4976e-05\n",
      "Epoch 146/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0115 - mae: 0.0115\n",
      "Epoch 146: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 4.3980e-05\n",
      "Epoch 147/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0115 - mae: 0.0115\n",
      "Epoch 147: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 4.3980e-05\n",
      "Epoch 148/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0116\n",
      "Epoch 148: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0241 - val_mae: 0.0241 - learning_rate: 4.3980e-05\n",
      "Epoch 149/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0114 - mae: 0.0114\n",
      "Epoch 149: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 4.3980e-05\n",
      "Epoch 150/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 150: val_mae did not improve from 0.01675\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0236 - val_mae: 0.0236 - learning_rate: 4.3980e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mae', 'val_loss', 'val_mae', 'learning_rate'])\n",
      "✅ Loaded saved model from: best_model_6_2.h5\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "📊 Evaluation Metrics:\n",
      "MAE:  0.6412\n",
      "RMSE: 1.0515\n",
      "MAPE: 27.00%\n",
      "\n",
      "🔁 Training with lookback=6, horizon=6\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janav\\.pyenv\\pyenv-win\\versions\\3.10.6\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0541 - mae: 0.0541\n",
      "Epoch 1: val_mae improved from inf to 0.02935, saving model to best_model_6_6.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0540 - mae: 0.0540 - val_loss: 0.0293 - val_mae: 0.0293 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0290 - mae: 0.0290\n",
      "Epoch 2: val_mae improved from 0.02935 to 0.02571, saving model to best_model_6_6.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0290 - mae: 0.0290 - val_loss: 0.0257 - val_mae: 0.0257 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0269 - mae: 0.0269\n",
      "Epoch 3: val_mae improved from 0.02571 to 0.02426, saving model to best_model_6_6.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0269 - mae: 0.0269 - val_loss: 0.0243 - val_mae: 0.0243 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0257 - mae: 0.0257\n",
      "Epoch 4: val_mae improved from 0.02426 to 0.02406, saving model to best_model_6_6.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0257 - mae: 0.0257 - val_loss: 0.0241 - val_mae: 0.0241 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0250 - mae: 0.0250\n",
      "Epoch 5: val_mae improved from 0.02406 to 0.02282, saving model to best_model_6_6.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0250 - mae: 0.0250 - val_loss: 0.0228 - val_mae: 0.0228 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0242 - mae: 0.0242\n",
      "Epoch 6: val_mae improved from 0.02282 to 0.02260, saving model to best_model_6_6.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0242 - mae: 0.0242 - val_loss: 0.0226 - val_mae: 0.0226 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0238 - mae: 0.0238\n",
      "Epoch 7: val_mae did not improve from 0.02260\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0238 - mae: 0.0238 - val_loss: 0.0230 - val_mae: 0.0230 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0232 - mae: 0.0232\n",
      "Epoch 8: val_mae did not improve from 0.02260\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0232 - mae: 0.0232 - val_loss: 0.0228 - val_mae: 0.0228 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0227 - mae: 0.0227\n",
      "Epoch 9: val_mae improved from 0.02260 to 0.02240, saving model to best_model_6_6.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0227 - mae: 0.0227 - val_loss: 0.0224 - val_mae: 0.0224 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0225 - mae: 0.0225\n",
      "Epoch 10: val_mae did not improve from 0.02240\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0225 - mae: 0.0225 - val_loss: 0.0229 - val_mae: 0.0229 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0222 - mae: 0.0222\n",
      "Epoch 11: val_mae did not improve from 0.02240\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0222 - mae: 0.0222 - val_loss: 0.0228 - val_mae: 0.0228 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0222 - mae: 0.0222\n",
      "Epoch 12: val_mae did not improve from 0.02240\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0222 - mae: 0.0222 - val_loss: 0.0226 - val_mae: 0.0226 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0217 - mae: 0.0217\n",
      "Epoch 13: val_mae improved from 0.02240 to 0.02213, saving model to best_model_6_6.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0217 - mae: 0.0217 - val_loss: 0.0221 - val_mae: 0.0221 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0217 - mae: 0.0217\n",
      "Epoch 14: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0217 - mae: 0.0217 - val_loss: 0.0224 - val_mae: 0.0224 - learning_rate: 0.0010\n",
      "Epoch 15/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0214 - mae: 0.0214\n",
      "Epoch 15: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0214 - mae: 0.0214 - val_loss: 0.0230 - val_mae: 0.0230 - learning_rate: 0.0010\n",
      "Epoch 16/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0211 - mae: 0.0211\n",
      "Epoch 16: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0211 - mae: 0.0211 - val_loss: 0.0224 - val_mae: 0.0224 - learning_rate: 0.0010\n",
      "Epoch 17/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0212 - mae: 0.0212\n",
      "Epoch 17: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0212 - mae: 0.0212 - val_loss: 0.0222 - val_mae: 0.0222 - learning_rate: 0.0010\n",
      "Epoch 18/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0215 - mae: 0.0215\n",
      "Epoch 18: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0215 - mae: 0.0215 - val_loss: 0.0223 - val_mae: 0.0223 - learning_rate: 0.0010\n",
      "Epoch 19/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0212 - mae: 0.0212\n",
      "Epoch 19: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0212 - mae: 0.0212 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 0.0010\n",
      "Epoch 20/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0211 - mae: 0.0211\n",
      "Epoch 20: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0211 - mae: 0.0211 - val_loss: 0.0233 - val_mae: 0.0233 - learning_rate: 0.0010\n",
      "Epoch 21/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0206 - mae: 0.0206\n",
      "Epoch 21: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0206 - mae: 0.0206 - val_loss: 0.0233 - val_mae: 0.0233 - learning_rate: 0.0010\n",
      "Epoch 22/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0211 - mae: 0.0211\n",
      "Epoch 22: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0211 - mae: 0.0211 - val_loss: 0.0229 - val_mae: 0.0229 - learning_rate: 0.0010\n",
      "Epoch 23/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0207 - mae: 0.0207\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 23: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0207 - mae: 0.0207 - val_loss: 0.0228 - val_mae: 0.0228 - learning_rate: 0.0010\n",
      "Epoch 24/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0207 - mae: 0.0207\n",
      "Epoch 24: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0207 - mae: 0.0207 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 8.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0202 - mae: 0.0202\n",
      "Epoch 25: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0202 - mae: 0.0202 - val_loss: 0.0226 - val_mae: 0.0226 - learning_rate: 8.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0204 - mae: 0.0204\n",
      "Epoch 26: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0204 - mae: 0.0204 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 8.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0202 - mae: 0.0202\n",
      "Epoch 27: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0202 - mae: 0.0202 - val_loss: 0.0241 - val_mae: 0.0241 - learning_rate: 8.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0201 - mae: 0.0201\n",
      "Epoch 28: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0201 - mae: 0.0201 - val_loss: 0.0236 - val_mae: 0.0236 - learning_rate: 8.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0201 - mae: 0.0201\n",
      "Epoch 29: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0201 - mae: 0.0201 - val_loss: 0.0239 - val_mae: 0.0239 - learning_rate: 8.0000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0201 - mae: 0.0201\n",
      "Epoch 30: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0201 - mae: 0.0201 - val_loss: 0.0246 - val_mae: 0.0246 - learning_rate: 8.0000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0200 - mae: 0.0200\n",
      "Epoch 31: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0200 - mae: 0.0200 - val_loss: 0.0248 - val_mae: 0.0248 - learning_rate: 8.0000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0200 - mae: 0.0200\n",
      "Epoch 32: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0200 - mae: 0.0200 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 8.0000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0201 - mae: 0.0201\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 33: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0201 - mae: 0.0201 - val_loss: 0.0244 - val_mae: 0.0244 - learning_rate: 8.0000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0199 - mae: 0.0199\n",
      "Epoch 34: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0199 - mae: 0.0199 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 6.4000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0197 - mae: 0.0197\n",
      "Epoch 35: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0197 - mae: 0.0197 - val_loss: 0.0249 - val_mae: 0.0249 - learning_rate: 6.4000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0196 - mae: 0.0196\n",
      "Epoch 36: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0196 - mae: 0.0196 - val_loss: 0.0245 - val_mae: 0.0245 - learning_rate: 6.4000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0195 - mae: 0.0195\n",
      "Epoch 37: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0195 - mae: 0.0195 - val_loss: 0.0246 - val_mae: 0.0246 - learning_rate: 6.4000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0193 - mae: 0.0193\n",
      "Epoch 38: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 6.4000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0197 - mae: 0.0197\n",
      "Epoch 39: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0197 - mae: 0.0197 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 6.4000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0194 - mae: 0.0194\n",
      "Epoch 40: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0239 - val_mae: 0.0239 - learning_rate: 6.4000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0197 - mae: 0.0197\n",
      "Epoch 41: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0197 - mae: 0.0197 - val_loss: 0.0246 - val_mae: 0.0246 - learning_rate: 6.4000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0194 - mae: 0.0194\n",
      "Epoch 42: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0246 - val_mae: 0.0246 - learning_rate: 6.4000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0193 - mae: 0.0193\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 43: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0246 - val_mae: 0.0246 - learning_rate: 6.4000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0192 - mae: 0.0192\n",
      "Epoch 44: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.0248 - val_mae: 0.0248 - learning_rate: 5.1200e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0195 - mae: 0.0195\n",
      "Epoch 45: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0195 - mae: 0.0195 - val_loss: 0.0247 - val_mae: 0.0247 - learning_rate: 5.1200e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0192 - mae: 0.0192\n",
      "Epoch 46: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.0245 - val_mae: 0.0245 - learning_rate: 5.1200e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0189 - mae: 0.0189\n",
      "Epoch 47: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0244 - val_mae: 0.0244 - learning_rate: 5.1200e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0193 - mae: 0.0193\n",
      "Epoch 48: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0248 - val_mae: 0.0248 - learning_rate: 5.1200e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0191 - mae: 0.0191\n",
      "Epoch 49: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0191 - mae: 0.0191 - val_loss: 0.0247 - val_mae: 0.0247 - learning_rate: 5.1200e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0192 - mae: 0.0192\n",
      "Epoch 50: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.0245 - val_mae: 0.0245 - learning_rate: 5.1200e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0192 - mae: 0.0192\n",
      "Epoch 51: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.0247 - val_mae: 0.0247 - learning_rate: 5.1200e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0191 - mae: 0.0191\n",
      "Epoch 52: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0191 - mae: 0.0191 - val_loss: 0.0247 - val_mae: 0.0247 - learning_rate: 5.1200e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0192 - mae: 0.0192\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 53: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.0245 - val_mae: 0.0245 - learning_rate: 5.1200e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0190 - mae: 0.0190\n",
      "Epoch 54: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0249 - val_mae: 0.0249 - learning_rate: 4.0960e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0190 - mae: 0.0190\n",
      "Epoch 55: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0246 - val_mae: 0.0246 - learning_rate: 4.0960e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0188\n",
      "Epoch 56: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0248 - val_mae: 0.0248 - learning_rate: 4.0960e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0192 - mae: 0.0192\n",
      "Epoch 57: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.0245 - val_mae: 0.0245 - learning_rate: 4.0960e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0189 - mae: 0.0189\n",
      "Epoch 58: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0247 - val_mae: 0.0247 - learning_rate: 4.0960e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0189 - mae: 0.0189\n",
      "Epoch 59: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0249 - val_mae: 0.0249 - learning_rate: 4.0960e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0189 - mae: 0.0189\n",
      "Epoch 60: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0246 - val_mae: 0.0246 - learning_rate: 4.0960e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0188\n",
      "Epoch 61: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0248 - val_mae: 0.0248 - learning_rate: 4.0960e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0189 - mae: 0.0189\n",
      "Epoch 62: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0249 - val_mae: 0.0249 - learning_rate: 4.0960e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0188\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 63: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0249 - val_mae: 0.0249 - learning_rate: 4.0960e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0187 - mae: 0.0187\n",
      "Epoch 64: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0247 - val_mae: 0.0247 - learning_rate: 3.2768e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0189 - mae: 0.0189\n",
      "Epoch 65: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0249 - val_mae: 0.0249 - learning_rate: 3.2768e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0188\n",
      "Epoch 66: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 3.2768e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0186 - mae: 0.0186\n",
      "Epoch 67: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0253 - val_mae: 0.0253 - learning_rate: 3.2768e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0186 - mae: 0.0186\n",
      "Epoch 68: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0253 - val_mae: 0.0253 - learning_rate: 3.2768e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0187 - mae: 0.0187\n",
      "Epoch 69: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 3.2768e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0187 - mae: 0.0187\n",
      "Epoch 70: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 3.2768e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0186 - mae: 0.0186\n",
      "Epoch 71: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0250 - val_mae: 0.0250 - learning_rate: 3.2768e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0185 - mae: 0.0185\n",
      "Epoch 72: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 3.2768e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0188\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 73: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0250 - val_mae: 0.0250 - learning_rate: 3.2768e-04\n",
      "Epoch 74/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0187 - mae: 0.0187\n",
      "Epoch 74: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0251 - val_mae: 0.0251 - learning_rate: 2.6214e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0182 - mae: 0.0182\n",
      "Epoch 75: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0249 - val_mae: 0.0249 - learning_rate: 2.6214e-04\n",
      "Epoch 76/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0185 - mae: 0.0185\n",
      "Epoch 76: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0251 - val_mae: 0.0251 - learning_rate: 2.6214e-04\n",
      "Epoch 77/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0184 - mae: 0.0184\n",
      "Epoch 77: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 2.6214e-04\n",
      "Epoch 78/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0185 - mae: 0.0185\n",
      "Epoch 78: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0256 - val_mae: 0.0256 - learning_rate: 2.6214e-04\n",
      "Epoch 79/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0185 - mae: 0.0185\n",
      "Epoch 79: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0250 - val_mae: 0.0250 - learning_rate: 2.6214e-04\n",
      "Epoch 80/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0185 - mae: 0.0185\n",
      "Epoch 80: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0250 - val_mae: 0.0250 - learning_rate: 2.6214e-04\n",
      "Epoch 81/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - mae: 0.0183\n",
      "Epoch 81: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 2.6214e-04\n",
      "Epoch 82/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - mae: 0.0183\n",
      "Epoch 82: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 2.6214e-04\n",
      "Epoch 83/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0185 - mae: 0.0185\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 83: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0253 - val_mae: 0.0253 - learning_rate: 2.6214e-04\n",
      "Epoch 84/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - mae: 0.0183\n",
      "Epoch 84: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0251 - val_mae: 0.0251 - learning_rate: 2.0972e-04\n",
      "Epoch 85/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - mae: 0.0183\n",
      "Epoch 85: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0253 - val_mae: 0.0253 - learning_rate: 2.0972e-04\n",
      "Epoch 86/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0182 - mae: 0.0182\n",
      "Epoch 86: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 2.0972e-04\n",
      "Epoch 87/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - mae: 0.0183\n",
      "Epoch 87: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0251 - val_mae: 0.0251 - learning_rate: 2.0972e-04\n",
      "Epoch 88/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - mae: 0.0179\n",
      "Epoch 88: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0253 - val_mae: 0.0253 - learning_rate: 2.0972e-04\n",
      "Epoch 89/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - mae: 0.0183\n",
      "Epoch 89: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 2.0972e-04\n",
      "Epoch 90/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0185 - mae: 0.0185\n",
      "Epoch 90: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0256 - val_mae: 0.0256 - learning_rate: 2.0972e-04\n",
      "Epoch 91/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0186 - mae: 0.0186\n",
      "Epoch 91: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0255 - val_mae: 0.0255 - learning_rate: 2.0972e-04\n",
      "Epoch 92/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - mae: 0.0183\n",
      "Epoch 92: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0251 - val_mae: 0.0251 - learning_rate: 2.0972e-04\n",
      "Epoch 93/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0183 - mae: 0.0183\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 93: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 2.0972e-04\n",
      "Epoch 94/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0181 - mae: 0.0181\n",
      "Epoch 94: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 1.6777e-04\n",
      "Epoch 95/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0185 - mae: 0.0185\n",
      "Epoch 95: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 1.6777e-04\n",
      "Epoch 96/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0181 - mae: 0.0181\n",
      "Epoch 96: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0248 - val_mae: 0.0248 - learning_rate: 1.6777e-04\n",
      "Epoch 97/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0183 - mae: 0.0183\n",
      "Epoch 97: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0255 - val_mae: 0.0255 - learning_rate: 1.6777e-04\n",
      "Epoch 98/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0183 - mae: 0.0183\n",
      "Epoch 98: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0256 - val_mae: 0.0256 - learning_rate: 1.6777e-04\n",
      "Epoch 99/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0179 - mae: 0.0179\n",
      "Epoch 99: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 1.6777e-04\n",
      "Epoch 100/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0183 - mae: 0.0183\n",
      "Epoch 100: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0253 - val_mae: 0.0253 - learning_rate: 1.6777e-04\n",
      "Epoch 101/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0183 - mae: 0.0183\n",
      "Epoch 101: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0258 - val_mae: 0.0258 - learning_rate: 1.6777e-04\n",
      "Epoch 102/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0181 - mae: 0.0181\n",
      "Epoch 102: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 1.6777e-04\n",
      "Epoch 103/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0181 - mae: 0.0181\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 103: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 1.6777e-04\n",
      "Epoch 104/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0182 - mae: 0.0182\n",
      "Epoch 104: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0257 - val_mae: 0.0257 - learning_rate: 1.3422e-04\n",
      "Epoch 105/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0179 - mae: 0.0179\n",
      "Epoch 105: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0250 - val_mae: 0.0250 - learning_rate: 1.3422e-04\n",
      "Epoch 106/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0182 - mae: 0.0182\n",
      "Epoch 106: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0253 - val_mae: 0.0253 - learning_rate: 1.3422e-04\n",
      "Epoch 107/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0180 - mae: 0.0180\n",
      "Epoch 107: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0256 - val_mae: 0.0256 - learning_rate: 1.3422e-04\n",
      "Epoch 108/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0181 - mae: 0.0181\n",
      "Epoch 108: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0256 - val_mae: 0.0256 - learning_rate: 1.3422e-04\n",
      "Epoch 109/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0180 - mae: 0.0180\n",
      "Epoch 109: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0253 - val_mae: 0.0253 - learning_rate: 1.3422e-04\n",
      "Epoch 110/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0182 - mae: 0.0182\n",
      "Epoch 110: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 1.3422e-04\n",
      "Epoch 111/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0181 - mae: 0.0181\n",
      "Epoch 111: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 1.3422e-04\n",
      "Epoch 112/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0181 - mae: 0.0181\n",
      "Epoch 112: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 1.3422e-04\n",
      "Epoch 113/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - mae: 0.0179\n",
      "Epoch 113: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 113: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0253 - val_mae: 0.0253 - learning_rate: 1.3422e-04\n",
      "Epoch 114/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - mae: 0.0180\n",
      "Epoch 114: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0255 - val_mae: 0.0255 - learning_rate: 1.0737e-04\n",
      "Epoch 115/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - mae: 0.0181\n",
      "Epoch 115: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 1.0737e-04\n",
      "Epoch 116/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0182 - mae: 0.0182\n",
      "Epoch 116: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0255 - val_mae: 0.0255 - learning_rate: 1.0737e-04\n",
      "Epoch 117/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - mae: 0.0181\n",
      "Epoch 117: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 1.0737e-04\n",
      "Epoch 118/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - mae: 0.0181\n",
      "Epoch 118: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 1.0737e-04\n",
      "Epoch 119/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - mae: 0.0180\n",
      "Epoch 119: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 1.0737e-04\n",
      "Epoch 120/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - mae: 0.0180\n",
      "Epoch 120: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0255 - val_mae: 0.0255 - learning_rate: 1.0737e-04\n",
      "Epoch 121/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0180 - mae: 0.0180\n",
      "Epoch 121: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 1.0737e-04\n",
      "Epoch 122/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0179 - mae: 0.0179\n",
      "Epoch 122: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 1.0737e-04\n",
      "Epoch 123/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0179 - mae: 0.0179\n",
      "Epoch 123: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 123: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0255 - val_mae: 0.0255 - learning_rate: 1.0737e-04\n",
      "Epoch 124/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0180 - mae: 0.0180\n",
      "Epoch 124: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 8.5899e-05\n",
      "Epoch 125/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0181 - mae: 0.0181\n",
      "Epoch 125: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0255 - val_mae: 0.0255 - learning_rate: 8.5899e-05\n",
      "Epoch 126/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0180 - mae: 0.0180\n",
      "Epoch 126: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0253 - val_mae: 0.0253 - learning_rate: 8.5899e-05\n",
      "Epoch 127/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0181 - mae: 0.0181\n",
      "Epoch 127: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 8.5899e-05\n",
      "Epoch 128/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0179 - mae: 0.0179\n",
      "Epoch 128: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 8.5899e-05\n",
      "Epoch 129/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0182 - mae: 0.0182\n",
      "Epoch 129: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0255 - val_mae: 0.0255 - learning_rate: 8.5899e-05\n",
      "Epoch 130/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0178 - mae: 0.0178\n",
      "Epoch 130: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0253 - val_mae: 0.0253 - learning_rate: 8.5899e-05\n",
      "Epoch 131/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0179 - mae: 0.0179\n",
      "Epoch 131: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0256 - val_mae: 0.0256 - learning_rate: 8.5899e-05\n",
      "Epoch 132/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0180 - mae: 0.0180\n",
      "Epoch 132: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0255 - val_mae: 0.0255 - learning_rate: 8.5899e-05\n",
      "Epoch 133/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0180 - mae: 0.0180\n",
      "Epoch 133: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 133: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 8.5899e-05\n",
      "Epoch 134/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0180 - mae: 0.0180\n",
      "Epoch 134: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0255 - val_mae: 0.0255 - learning_rate: 6.8719e-05\n",
      "Epoch 135/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - mae: 0.0179\n",
      "Epoch 135: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 6.8719e-05\n",
      "Epoch 136/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - mae: 0.0180\n",
      "Epoch 136: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0253 - val_mae: 0.0253 - learning_rate: 6.8719e-05\n",
      "Epoch 137/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - mae: 0.0181\n",
      "Epoch 137: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0257 - val_mae: 0.0257 - learning_rate: 6.8719e-05\n",
      "Epoch 138/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - mae: 0.0180\n",
      "Epoch 138: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0255 - val_mae: 0.0255 - learning_rate: 6.8719e-05\n",
      "Epoch 139/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - mae: 0.0178\n",
      "Epoch 139: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0257 - val_mae: 0.0257 - learning_rate: 6.8719e-05\n",
      "Epoch 140/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - mae: 0.0179\n",
      "Epoch 140: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 6.8719e-05\n",
      "Epoch 141/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - mae: 0.0180\n",
      "Epoch 141: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0253 - val_mae: 0.0253 - learning_rate: 6.8719e-05\n",
      "Epoch 142/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - mae: 0.0179\n",
      "Epoch 142: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 6.8719e-05\n",
      "Epoch 143/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - mae: 0.0177\n",
      "Epoch 143: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "\n",
      "Epoch 143: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0256 - val_mae: 0.0256 - learning_rate: 6.8719e-05\n",
      "Epoch 144/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - mae: 0.0180\n",
      "Epoch 144: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0255 - val_mae: 0.0255 - learning_rate: 5.4976e-05\n",
      "Epoch 145/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - mae: 0.0179\n",
      "Epoch 145: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0255 - val_mae: 0.0255 - learning_rate: 5.4976e-05\n",
      "Epoch 146/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - mae: 0.0179\n",
      "Epoch 146: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0255 - val_mae: 0.0255 - learning_rate: 5.4976e-05\n",
      "Epoch 147/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - mae: 0.0178\n",
      "Epoch 147: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 5.4976e-05\n",
      "Epoch 148/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - mae: 0.0178\n",
      "Epoch 148: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 5.4976e-05\n",
      "Epoch 149/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - mae: 0.0180\n",
      "Epoch 149: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0256 - val_mae: 0.0256 - learning_rate: 5.4976e-05\n",
      "Epoch 150/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - mae: 0.0180\n",
      "Epoch 150: val_mae did not improve from 0.02213\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 5.4976e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mae', 'val_loss', 'val_mae', 'learning_rate'])\n",
      "✅ Loaded saved model from: best_model_6_6.h5\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "📊 Evaluation Metrics:\n",
      "MAE:  0.8766\n",
      "RMSE: 1.4022\n",
      "MAPE: 37.83%\n",
      "\n",
      "🔁 Training with lookback=12, horizon=1\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janav\\.pyenv\\pyenv-win\\versions\\3.10.6\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0522 - mae: 0.0522\n",
      "Epoch 1: val_mae improved from inf to 0.02276, saving model to best_model_12_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0520 - mae: 0.0520 - val_loss: 0.0228 - val_mae: 0.0228 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0247 - mae: 0.0247\n",
      "Epoch 2: val_mae improved from 0.02276 to 0.01789, saving model to best_model_12_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0246 - mae: 0.0246 - val_loss: 0.0179 - val_mae: 0.0179 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0192 - mae: 0.0192\n",
      "Epoch 3: val_mae improved from 0.01789 to 0.01666, saving model to best_model_12_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.0167 - val_mae: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0171 - mae: 0.0171\n",
      "Epoch 4: val_mae improved from 0.01666 to 0.01443, saving model to best_model_12_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0144 - val_mae: 0.0144 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0161 - mae: 0.0161\n",
      "Epoch 5: val_mae improved from 0.01443 to 0.01380, saving model to best_model_12_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0138 - val_mae: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0150 - mae: 0.0150\n",
      "Epoch 6: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0151 - val_mae: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0146 - mae: 0.0146\n",
      "Epoch 7: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0139 - val_mae: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0141 - mae: 0.0141\n",
      "Epoch 8: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0147 - val_mae: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0138 - mae: 0.0138\n",
      "Epoch 9: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0149 - val_mae: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0134 - mae: 0.0134\n",
      "Epoch 10: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0156 - val_mae: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 11: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0154 - val_mae: 0.0154 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0128 - mae: 0.0128\n",
      "Epoch 12: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0165 - val_mae: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0129 - mae: 0.0129\n",
      "Epoch 13: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0160 - val_mae: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 14: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0165 - val_mae: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 15/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 15: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0150 - val_mae: 0.0150 - learning_rate: 0.0010\n",
      "Epoch 16/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 16: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0191 - val_mae: 0.0191 - learning_rate: 8.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0117\n",
      "Epoch 17: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0167 - val_mae: 0.0167 - learning_rate: 8.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0115 - mae: 0.0115\n",
      "Epoch 18: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0171 - val_mae: 0.0171 - learning_rate: 8.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0115 - mae: 0.0115\n",
      "Epoch 19: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0176 - val_mae: 0.0176 - learning_rate: 8.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0112 - mae: 0.0112\n",
      "Epoch 20: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0187 - val_mae: 0.0187 - learning_rate: 8.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0115 - mae: 0.0115\n",
      "Epoch 21: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0172 - val_mae: 0.0172 - learning_rate: 8.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0112 - mae: 0.0112\n",
      "Epoch 22: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0185 - val_mae: 0.0185 - learning_rate: 8.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0112 - mae: 0.0112\n",
      "Epoch 23: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0175 - val_mae: 0.0175 - learning_rate: 8.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0111 - mae: 0.0111\n",
      "Epoch 24: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0194 - val_mae: 0.0194 - learning_rate: 8.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0109 - mae: 0.0109\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 25: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0183 - val_mae: 0.0183 - learning_rate: 8.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0108 - mae: 0.0108\n",
      "Epoch 26: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0182 - val_mae: 0.0182 - learning_rate: 6.4000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0107 - mae: 0.0107\n",
      "Epoch 27: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0107 - mae: 0.0107 - val_loss: 0.0189 - val_mae: 0.0189 - learning_rate: 6.4000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0107 - mae: 0.0107\n",
      "Epoch 28: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0107 - mae: 0.0107 - val_loss: 0.0181 - val_mae: 0.0181 - learning_rate: 6.4000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0103 - mae: 0.0103\n",
      "Epoch 29: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0188 - val_mae: 0.0188 - learning_rate: 6.4000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0106 - mae: 0.0106\n",
      "Epoch 30: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0180 - val_mae: 0.0180 - learning_rate: 6.4000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0105 - mae: 0.0105\n",
      "Epoch 31: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0191 - val_mae: 0.0191 - learning_rate: 6.4000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0104 - mae: 0.0104\n",
      "Epoch 32: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0193 - val_mae: 0.0193 - learning_rate: 6.4000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0105 - mae: 0.0105\n",
      "Epoch 33: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0196 - val_mae: 0.0196 - learning_rate: 6.4000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0105 - mae: 0.0105\n",
      "Epoch 34: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0192 - val_mae: 0.0192 - learning_rate: 6.4000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0103 - mae: 0.0103\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 35: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0199 - val_mae: 0.0199 - learning_rate: 6.4000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0104 - mae: 0.0104\n",
      "Epoch 36: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0203 - val_mae: 0.0203 - learning_rate: 5.1200e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0104 - mae: 0.0104\n",
      "Epoch 37: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0188 - val_mae: 0.0188 - learning_rate: 5.1200e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0101 - mae: 0.0101\n",
      "Epoch 38: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0188 - val_mae: 0.0188 - learning_rate: 5.1200e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0102 - mae: 0.0102\n",
      "Epoch 39: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0188 - val_mae: 0.0188 - learning_rate: 5.1200e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0099 - mae: 0.0099\n",
      "Epoch 40: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0209 - val_mae: 0.0209 - learning_rate: 5.1200e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0102 - mae: 0.0102\n",
      "Epoch 41: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0204 - val_mae: 0.0204 - learning_rate: 5.1200e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0099 - mae: 0.0099\n",
      "Epoch 42: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0196 - val_mae: 0.0196 - learning_rate: 5.1200e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0103 - mae: 0.0103\n",
      "Epoch 43: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0204 - val_mae: 0.0204 - learning_rate: 5.1200e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0102 - mae: 0.0102\n",
      "Epoch 44: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0210 - val_mae: 0.0210 - learning_rate: 5.1200e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0102 - mae: 0.0102\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 45: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0192 - val_mae: 0.0192 - learning_rate: 5.1200e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0099 - mae: 0.0099\n",
      "Epoch 46: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0194 - val_mae: 0.0194 - learning_rate: 4.0960e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0097 - mae: 0.0097\n",
      "Epoch 47: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0198 - val_mae: 0.0198 - learning_rate: 4.0960e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0099 - mae: 0.0099\n",
      "Epoch 48: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0193 - val_mae: 0.0193 - learning_rate: 4.0960e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0100 - mae: 0.0100\n",
      "Epoch 49: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0199 - val_mae: 0.0199 - learning_rate: 4.0960e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0101 - mae: 0.0101\n",
      "Epoch 50: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0190 - val_mae: 0.0190 - learning_rate: 4.0960e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0098 - mae: 0.0098\n",
      "Epoch 51: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0197 - val_mae: 0.0197 - learning_rate: 4.0960e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0098 - mae: 0.0098\n",
      "Epoch 52: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0196 - val_mae: 0.0196 - learning_rate: 4.0960e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0097 - mae: 0.0097\n",
      "Epoch 53: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0203 - val_mae: 0.0203 - learning_rate: 4.0960e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0099 - mae: 0.0099\n",
      "Epoch 54: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0200 - val_mae: 0.0200 - learning_rate: 4.0960e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0099 - mae: 0.0099\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 55: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0201 - val_mae: 0.0201 - learning_rate: 4.0960e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0096 - mae: 0.0096\n",
      "Epoch 56: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0199 - val_mae: 0.0199 - learning_rate: 3.2768e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0098 - mae: 0.0098\n",
      "Epoch 57: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0197 - val_mae: 0.0197 - learning_rate: 3.2768e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0097 - mae: 0.0097\n",
      "Epoch 58: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0196 - val_mae: 0.0196 - learning_rate: 3.2768e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0096 - mae: 0.0096\n",
      "Epoch 59: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0195 - val_mae: 0.0195 - learning_rate: 3.2768e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0098 - mae: 0.0098\n",
      "Epoch 60: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0199 - val_mae: 0.0199 - learning_rate: 3.2768e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0097 - mae: 0.0097\n",
      "Epoch 61: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0197 - val_mae: 0.0197 - learning_rate: 3.2768e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0097 - mae: 0.0097\n",
      "Epoch 62: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0202 - val_mae: 0.0202 - learning_rate: 3.2768e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0095\n",
      "Epoch 63: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0193 - val_mae: 0.0193 - learning_rate: 3.2768e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0096 - mae: 0.0096\n",
      "Epoch 64: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0197 - val_mae: 0.0197 - learning_rate: 3.2768e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0097 - mae: 0.0097\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 65: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0197 - val_mae: 0.0197 - learning_rate: 3.2768e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0095\n",
      "Epoch 66: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0188 - val_mae: 0.0188 - learning_rate: 2.6214e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0094 - mae: 0.0094\n",
      "Epoch 67: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0198 - val_mae: 0.0198 - learning_rate: 2.6214e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0095\n",
      "Epoch 68: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0193 - val_mae: 0.0193 - learning_rate: 2.6214e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0095\n",
      "Epoch 69: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0198 - val_mae: 0.0198 - learning_rate: 2.6214e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0096 - mae: 0.0096\n",
      "Epoch 70: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0200 - val_mae: 0.0200 - learning_rate: 2.6214e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0095\n",
      "Epoch 71: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0200 - val_mae: 0.0200 - learning_rate: 2.6214e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0095\n",
      "Epoch 72: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0189 - val_mae: 0.0189 - learning_rate: 2.6214e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 73: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0196 - val_mae: 0.0196 - learning_rate: 2.6214e-04\n",
      "Epoch 74/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 74: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0203 - val_mae: 0.0203 - learning_rate: 2.6214e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0095\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 75: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0195 - val_mae: 0.0195 - learning_rate: 2.6214e-04\n",
      "Epoch 76/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0095\n",
      "Epoch 76: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0196 - val_mae: 0.0196 - learning_rate: 2.0972e-04\n",
      "Epoch 77/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 77: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0196 - val_mae: 0.0196 - learning_rate: 2.0972e-04\n",
      "Epoch 78/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 78: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0193 - val_mae: 0.0193 - learning_rate: 2.0972e-04\n",
      "Epoch 79/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 79: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0198 - val_mae: 0.0198 - learning_rate: 2.0972e-04\n",
      "Epoch 80/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 80: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0195 - val_mae: 0.0195 - learning_rate: 2.0972e-04\n",
      "Epoch 81/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 81: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0206 - val_mae: 0.0206 - learning_rate: 2.0972e-04\n",
      "Epoch 82/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0094 - mae: 0.0094\n",
      "Epoch 82: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0195 - val_mae: 0.0195 - learning_rate: 2.0972e-04\n",
      "Epoch 83/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0095\n",
      "Epoch 83: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0194 - val_mae: 0.0194 - learning_rate: 2.0972e-04\n",
      "Epoch 84/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 84: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0197 - val_mae: 0.0197 - learning_rate: 2.0972e-04\n",
      "Epoch 85/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0095\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 85: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0190 - val_mae: 0.0190 - learning_rate: 2.0972e-04\n",
      "Epoch 86/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 86: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0201 - val_mae: 0.0201 - learning_rate: 1.6777e-04\n",
      "Epoch 87/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 87: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0201 - val_mae: 0.0201 - learning_rate: 1.6777e-04\n",
      "Epoch 88/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0094 - mae: 0.0094\n",
      "Epoch 88: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0198 - val_mae: 0.0198 - learning_rate: 1.6777e-04\n",
      "Epoch 89/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 89: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0203 - val_mae: 0.0203 - learning_rate: 1.6777e-04\n",
      "Epoch 90/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 90: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0196 - val_mae: 0.0196 - learning_rate: 1.6777e-04\n",
      "Epoch 91/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 91: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0196 - val_mae: 0.0196 - learning_rate: 1.6777e-04\n",
      "Epoch 92/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 92: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0193 - val_mae: 0.0193 - learning_rate: 1.6777e-04\n",
      "Epoch 93/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0095\n",
      "Epoch 93: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0195 - val_mae: 0.0195 - learning_rate: 1.6777e-04\n",
      "Epoch 94/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 94: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0196 - val_mae: 0.0196 - learning_rate: 1.6777e-04\n",
      "Epoch 95/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 95: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0197 - val_mae: 0.0197 - learning_rate: 1.6777e-04\n",
      "Epoch 96/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 96: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0199 - val_mae: 0.0199 - learning_rate: 1.3422e-04\n",
      "Epoch 97/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 97: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0193 - val_mae: 0.0193 - learning_rate: 1.3422e-04\n",
      "Epoch 98/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 98: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0198 - val_mae: 0.0198 - learning_rate: 1.3422e-04\n",
      "Epoch 99/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 99: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0196 - val_mae: 0.0196 - learning_rate: 1.3422e-04\n",
      "Epoch 100/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 100: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0200 - val_mae: 0.0200 - learning_rate: 1.3422e-04\n",
      "Epoch 101/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 101: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0194 - val_mae: 0.0194 - learning_rate: 1.3422e-04\n",
      "Epoch 102/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 102: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0190 - val_mae: 0.0190 - learning_rate: 1.3422e-04\n",
      "Epoch 103/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 103: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0200 - val_mae: 0.0200 - learning_rate: 1.3422e-04\n",
      "Epoch 104/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 104: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0196 - val_mae: 0.0196 - learning_rate: 1.3422e-04\n",
      "Epoch 105/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 105: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0194 - val_mae: 0.0194 - learning_rate: 1.3422e-04\n",
      "Epoch 106/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 106: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0199 - val_mae: 0.0199 - learning_rate: 1.0737e-04\n",
      "Epoch 107/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 107: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0193 - val_mae: 0.0193 - learning_rate: 1.0737e-04\n",
      "Epoch 108/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 108: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0199 - val_mae: 0.0199 - learning_rate: 1.0737e-04\n",
      "Epoch 109/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 109: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0199 - val_mae: 0.0199 - learning_rate: 1.0737e-04\n",
      "Epoch 110/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 110: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0198 - val_mae: 0.0198 - learning_rate: 1.0737e-04\n",
      "Epoch 111/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 111: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0197 - val_mae: 0.0197 - learning_rate: 1.0737e-04\n",
      "Epoch 112/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 112: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0196 - val_mae: 0.0196 - learning_rate: 1.0737e-04\n",
      "Epoch 113/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 113: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0196 - val_mae: 0.0196 - learning_rate: 1.0737e-04\n",
      "Epoch 114/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0094 - mae: 0.0094\n",
      "Epoch 114: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0200 - val_mae: 0.0200 - learning_rate: 1.0737e-04\n",
      "Epoch 115/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090\n",
      "Epoch 115: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 115: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0197 - val_mae: 0.0197 - learning_rate: 1.0737e-04\n",
      "Epoch 116/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 116: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0195 - val_mae: 0.0195 - learning_rate: 8.5899e-05\n",
      "Epoch 117/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 117: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0198 - val_mae: 0.0198 - learning_rate: 8.5899e-05\n",
      "Epoch 118/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093\n",
      "Epoch 118: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0195 - val_mae: 0.0195 - learning_rate: 8.5899e-05\n",
      "Epoch 119/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 119: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0196 - val_mae: 0.0196 - learning_rate: 8.5899e-05\n",
      "Epoch 120/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090\n",
      "Epoch 120: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0193 - val_mae: 0.0193 - learning_rate: 8.5899e-05\n",
      "Epoch 121/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 121: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0197 - val_mae: 0.0197 - learning_rate: 8.5899e-05\n",
      "Epoch 122/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090\n",
      "Epoch 122: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0199 - val_mae: 0.0199 - learning_rate: 8.5899e-05\n",
      "Epoch 123/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 123: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0194 - val_mae: 0.0194 - learning_rate: 8.5899e-05\n",
      "Epoch 124/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 124: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0195 - val_mae: 0.0195 - learning_rate: 8.5899e-05\n",
      "Epoch 125/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090\n",
      "Epoch 125: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 125: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0192 - val_mae: 0.0192 - learning_rate: 8.5899e-05\n",
      "Epoch 126/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 126: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0202 - val_mae: 0.0202 - learning_rate: 6.8719e-05\n",
      "Epoch 127/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090\n",
      "Epoch 127: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0199 - val_mae: 0.0199 - learning_rate: 6.8719e-05\n",
      "Epoch 128/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 128: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0195 - val_mae: 0.0195 - learning_rate: 6.8719e-05\n",
      "Epoch 129/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090\n",
      "Epoch 129: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0193 - val_mae: 0.0193 - learning_rate: 6.8719e-05\n",
      "Epoch 130/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090\n",
      "Epoch 130: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0197 - val_mae: 0.0197 - learning_rate: 6.8719e-05\n",
      "Epoch 131/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 131: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0197 - val_mae: 0.0197 - learning_rate: 6.8719e-05\n",
      "Epoch 132/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 132: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0202 - val_mae: 0.0202 - learning_rate: 6.8719e-05\n",
      "Epoch 133/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 133: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0195 - val_mae: 0.0195 - learning_rate: 6.8719e-05\n",
      "Epoch 134/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0089 - mae: 0.0089\n",
      "Epoch 134: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0199 - val_mae: 0.0199 - learning_rate: 6.8719e-05\n",
      "Epoch 135/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0089 - mae: 0.0089\n",
      "Epoch 135: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "\n",
      "Epoch 135: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0196 - val_mae: 0.0196 - learning_rate: 6.8719e-05\n",
      "Epoch 136/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 136: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0193 - val_mae: 0.0193 - learning_rate: 5.4976e-05\n",
      "Epoch 137/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - mae: 0.0092\n",
      "Epoch 137: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0197 - val_mae: 0.0197 - learning_rate: 5.4976e-05\n",
      "Epoch 138/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 138: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0199 - val_mae: 0.0199 - learning_rate: 5.4976e-05\n",
      "Epoch 139/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 139: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0200 - val_mae: 0.0200 - learning_rate: 5.4976e-05\n",
      "Epoch 140/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091\n",
      "Epoch 140: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0196 - val_mae: 0.0196 - learning_rate: 5.4976e-05\n",
      "Epoch 141/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0088 - mae: 0.0088\n",
      "Epoch 141: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0196 - val_mae: 0.0196 - learning_rate: 5.4976e-05\n",
      "Epoch 142/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089\n",
      "Epoch 142: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0195 - val_mae: 0.0195 - learning_rate: 5.4976e-05\n",
      "Epoch 143/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0090 - mae: 0.0090\n",
      "Epoch 143: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0196 - val_mae: 0.0196 - learning_rate: 5.4976e-05\n",
      "Epoch 144/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090\n",
      "Epoch 144: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0198 - val_mae: 0.0198 - learning_rate: 5.4976e-05\n",
      "Epoch 145/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0089 - mae: 0.0089\n",
      "Epoch 145: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "\n",
      "Epoch 145: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0197 - val_mae: 0.0197 - learning_rate: 5.4976e-05\n",
      "Epoch 146/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0090 - mae: 0.0090\n",
      "Epoch 146: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0201 - val_mae: 0.0201 - learning_rate: 4.3980e-05\n",
      "Epoch 147/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089\n",
      "Epoch 147: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0197 - val_mae: 0.0197 - learning_rate: 4.3980e-05\n",
      "Epoch 148/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089\n",
      "Epoch 148: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0200 - val_mae: 0.0200 - learning_rate: 4.3980e-05\n",
      "Epoch 149/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089\n",
      "Epoch 149: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0199 - val_mae: 0.0199 - learning_rate: 4.3980e-05\n",
      "Epoch 150/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090\n",
      "Epoch 150: val_mae did not improve from 0.01380\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0196 - val_mae: 0.0196 - learning_rate: 4.3980e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mae', 'val_loss', 'val_mae', 'learning_rate'])\n",
      "✅ Loaded saved model from: best_model_12_1.h5\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "📊 Evaluation Metrics:\n",
      "MAE:  0.5455\n",
      "RMSE: 0.8893\n",
      "MAPE: 23.49%\n",
      "\n",
      "🔁 Training with lookback=12, horizon=2\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janav\\.pyenv\\pyenv-win\\versions\\3.10.6\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0520 - mae: 0.0520\n",
      "Epoch 1: val_mae improved from inf to 0.02480, saving model to best_model_12_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0516 - mae: 0.0516 - val_loss: 0.0248 - val_mae: 0.0248 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0260 - mae: 0.0260\n",
      "Epoch 2: val_mae improved from 0.02480 to 0.02040, saving model to best_model_12_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0260 - mae: 0.0260 - val_loss: 0.0204 - val_mae: 0.0204 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0217 - mae: 0.0217\n",
      "Epoch 3: val_mae improved from 0.02040 to 0.01764, saving model to best_model_12_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0217 - mae: 0.0217 - val_loss: 0.0176 - val_mae: 0.0176 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0196 - mae: 0.0196\n",
      "Epoch 4: val_mae improved from 0.01764 to 0.01742, saving model to best_model_12_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0196 - mae: 0.0196 - val_loss: 0.0174 - val_mae: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0191 - mae: 0.0191\n",
      "Epoch 5: val_mae did not improve from 0.01742\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0191 - mae: 0.0191 - val_loss: 0.0184 - val_mae: 0.0184 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - mae: 0.0179\n",
      "Epoch 6: val_mae improved from 0.01742 to 0.01639, saving model to best_model_12_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0164 - val_mae: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - mae: 0.0174\n",
      "Epoch 7: val_mae did not improve from 0.01639\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0166 - val_mae: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0170 - mae: 0.0170\n",
      "Epoch 8: val_mae improved from 0.01639 to 0.01591, saving model to best_model_12_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0159 - val_mae: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0165 - mae: 0.0165\n",
      "Epoch 9: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0162 - val_mae: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0164 - mae: 0.0164\n",
      "Epoch 10: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0171 - val_mae: 0.0171 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0157 - mae: 0.0157\n",
      "Epoch 11: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0166 - val_mae: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0159 - mae: 0.0159\n",
      "Epoch 12: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0171 - val_mae: 0.0171 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0155 - mae: 0.0155\n",
      "Epoch 13: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0177 - val_mae: 0.0177 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0152 - mae: 0.0152\n",
      "Epoch 14: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.0176 - val_mae: 0.0176 - learning_rate: 0.0010\n",
      "Epoch 15/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0151 - mae: 0.0151\n",
      "Epoch 15: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.0188 - val_mae: 0.0188 - learning_rate: 0.0010\n",
      "Epoch 16/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0150 - mae: 0.0150\n",
      "Epoch 16: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0192 - val_mae: 0.0192 - learning_rate: 0.0010\n",
      "Epoch 17/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0149 - mae: 0.0149\n",
      "Epoch 17: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0149 - mae: 0.0149 - val_loss: 0.0181 - val_mae: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 18/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0144 - mae: 0.0144\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 18: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0190 - val_mae: 0.0190 - learning_rate: 0.0010\n",
      "Epoch 19/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0143 - mae: 0.0143\n",
      "Epoch 19: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0198 - val_mae: 0.0198 - learning_rate: 8.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0142 - mae: 0.0142\n",
      "Epoch 20: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.0194 - val_mae: 0.0194 - learning_rate: 8.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0141 - mae: 0.0141\n",
      "Epoch 21: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0194 - val_mae: 0.0194 - learning_rate: 8.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0141 - mae: 0.0141\n",
      "Epoch 22: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0200 - val_mae: 0.0200 - learning_rate: 8.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0140 - mae: 0.0140\n",
      "Epoch 23: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0199 - val_mae: 0.0199 - learning_rate: 8.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0142 - mae: 0.0142\n",
      "Epoch 24: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.0202 - val_mae: 0.0202 - learning_rate: 8.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0138 - mae: 0.0138\n",
      "Epoch 25: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0206 - val_mae: 0.0206 - learning_rate: 8.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0140 - mae: 0.0140\n",
      "Epoch 26: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0212 - val_mae: 0.0212 - learning_rate: 8.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0138 - mae: 0.0138\n",
      "Epoch 27: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0198 - val_mae: 0.0198 - learning_rate: 8.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0138 - mae: 0.0138\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 28: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0212 - val_mae: 0.0212 - learning_rate: 8.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0137 - mae: 0.0137\n",
      "Epoch 29: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0213 - val_mae: 0.0213 - learning_rate: 6.4000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0133 - mae: 0.0133\n",
      "Epoch 30: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0213 - val_mae: 0.0213 - learning_rate: 6.4000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0135 - mae: 0.0135\n",
      "Epoch 31: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0214 - val_mae: 0.0214 - learning_rate: 6.4000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0134 - mae: 0.0134\n",
      "Epoch 32: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0205 - val_mae: 0.0205 - learning_rate: 6.4000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0132 - mae: 0.0132\n",
      "Epoch 33: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0211 - val_mae: 0.0211 - learning_rate: 6.4000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0133 - mae: 0.0133\n",
      "Epoch 34: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0211 - val_mae: 0.0211 - learning_rate: 6.4000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0133 - mae: 0.0133\n",
      "Epoch 35: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0215 - val_mae: 0.0215 - learning_rate: 6.4000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0131 - mae: 0.0131\n",
      "Epoch 36: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0221 - val_mae: 0.0221 - learning_rate: 6.4000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0133 - mae: 0.0133\n",
      "Epoch 37: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0218 - val_mae: 0.0218 - learning_rate: 6.4000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0131 - mae: 0.0131\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 38: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0218 - val_mae: 0.0218 - learning_rate: 6.4000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 39: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0222 - val_mae: 0.0222 - learning_rate: 5.1200e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0132 - mae: 0.0132\n",
      "Epoch 40: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0217 - val_mae: 0.0217 - learning_rate: 5.1200e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 41: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0222 - val_mae: 0.0222 - learning_rate: 5.1200e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0132 - mae: 0.0132\n",
      "Epoch 42: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0216 - val_mae: 0.0216 - learning_rate: 5.1200e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 43: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0220 - val_mae: 0.0220 - learning_rate: 5.1200e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0129 - mae: 0.0129\n",
      "Epoch 44: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0213 - val_mae: 0.0213 - learning_rate: 5.1200e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0129 - mae: 0.0129\n",
      "Epoch 45: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0222 - val_mae: 0.0222 - learning_rate: 5.1200e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0131 - mae: 0.0131\n",
      "Epoch 46: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0215 - val_mae: 0.0215 - learning_rate: 5.1200e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 47: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0216 - val_mae: 0.0216 - learning_rate: 5.1200e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0131 - mae: 0.0131\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 48: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0221 - val_mae: 0.0221 - learning_rate: 5.1200e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0129 - mae: 0.0129\n",
      "Epoch 49: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0216 - val_mae: 0.0216 - learning_rate: 4.0960e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0128 - mae: 0.0128\n",
      "Epoch 50: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0220 - val_mae: 0.0220 - learning_rate: 4.0960e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0127 - mae: 0.0127\n",
      "Epoch 51: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0220 - val_mae: 0.0220 - learning_rate: 4.0960e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0128 - mae: 0.0128\n",
      "Epoch 52: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0216 - val_mae: 0.0216 - learning_rate: 4.0960e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0127 - mae: 0.0127\n",
      "Epoch 53: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0226 - val_mae: 0.0226 - learning_rate: 4.0960e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0126 - mae: 0.0126\n",
      "Epoch 54: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0219 - val_mae: 0.0219 - learning_rate: 4.0960e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0126 - mae: 0.0126\n",
      "Epoch 55: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0224 - val_mae: 0.0224 - learning_rate: 4.0960e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0127 - mae: 0.0127\n",
      "Epoch 56: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0222 - val_mae: 0.0222 - learning_rate: 4.0960e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 57: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0224 - val_mae: 0.0224 - learning_rate: 4.0960e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0128 - mae: 0.0128\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 58: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0222 - val_mae: 0.0222 - learning_rate: 4.0960e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 59: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0224 - val_mae: 0.0224 - learning_rate: 3.2768e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0127 - mae: 0.0127\n",
      "Epoch 60: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0224 - val_mae: 0.0224 - learning_rate: 3.2768e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0124 - mae: 0.0124\n",
      "Epoch 61: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0218 - val_mae: 0.0218 - learning_rate: 3.2768e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0126 - mae: 0.0126\n",
      "Epoch 62: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0225 - val_mae: 0.0225 - learning_rate: 3.2768e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0124 - mae: 0.0124\n",
      "Epoch 63: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0227 - val_mae: 0.0227 - learning_rate: 3.2768e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 64: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0230 - val_mae: 0.0230 - learning_rate: 3.2768e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 65: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0223 - val_mae: 0.0223 - learning_rate: 3.2768e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0124 - mae: 0.0124\n",
      "Epoch 66: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0236 - val_mae: 0.0236 - learning_rate: 3.2768e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0124 - mae: 0.0124\n",
      "Epoch 67: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0229 - val_mae: 0.0229 - learning_rate: 3.2768e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0124 - mae: 0.0124\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 68: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0220 - val_mae: 0.0220 - learning_rate: 3.2768e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 69: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0229 - val_mae: 0.0229 - learning_rate: 2.6214e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0124 - mae: 0.0124\n",
      "Epoch 70: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 2.6214e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0124 - mae: 0.0124\n",
      "Epoch 71: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0227 - val_mae: 0.0227 - learning_rate: 2.6214e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0124 - mae: 0.0124\n",
      "Epoch 72: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0226 - val_mae: 0.0226 - learning_rate: 2.6214e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 73: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0229 - val_mae: 0.0229 - learning_rate: 2.6214e-04\n",
      "Epoch 74/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 74: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0224 - val_mae: 0.0224 - learning_rate: 2.6214e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 75: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0228 - val_mae: 0.0228 - learning_rate: 2.6214e-04\n",
      "Epoch 76/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 76: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0229 - val_mae: 0.0229 - learning_rate: 2.6214e-04\n",
      "Epoch 77/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0122 - mae: 0.0122\n",
      "Epoch 77: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0230 - val_mae: 0.0230 - learning_rate: 2.6214e-04\n",
      "Epoch 78/150\n",
      "\u001b[1m319/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 78: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0226 - val_mae: 0.0226 - learning_rate: 2.6214e-04\n",
      "Epoch 79/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 79: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0229 - val_mae: 0.0229 - learning_rate: 2.0972e-04\n",
      "Epoch 80/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 80: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0232 - val_mae: 0.0232 - learning_rate: 2.0972e-04\n",
      "Epoch 81/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 81: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0229 - val_mae: 0.0229 - learning_rate: 2.0972e-04\n",
      "Epoch 82/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 82: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0228 - val_mae: 0.0228 - learning_rate: 2.0972e-04\n",
      "Epoch 83/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 83: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0230 - val_mae: 0.0230 - learning_rate: 2.0972e-04\n",
      "Epoch 84/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 84: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0229 - val_mae: 0.0229 - learning_rate: 2.0972e-04\n",
      "Epoch 85/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 85: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0226 - val_mae: 0.0226 - learning_rate: 2.0972e-04\n",
      "Epoch 86/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0122 - mae: 0.0122\n",
      "Epoch 86: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0233 - val_mae: 0.0233 - learning_rate: 2.0972e-04\n",
      "Epoch 87/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 87: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0227 - val_mae: 0.0227 - learning_rate: 2.0972e-04\n",
      "Epoch 88/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 88: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 2.0972e-04\n",
      "Epoch 89/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 89: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 1.6777e-04\n",
      "Epoch 90/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0122 - mae: 0.0122\n",
      "Epoch 90: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 1.6777e-04\n",
      "Epoch 91/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 91: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0232 - val_mae: 0.0232 - learning_rate: 1.6777e-04\n",
      "Epoch 92/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 92: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0230 - val_mae: 0.0230 - learning_rate: 1.6777e-04\n",
      "Epoch 93/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 93: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0229 - val_mae: 0.0229 - learning_rate: 1.6777e-04\n",
      "Epoch 94/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 94: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0228 - val_mae: 0.0228 - learning_rate: 1.6777e-04\n",
      "Epoch 95/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0122 - mae: 0.0122\n",
      "Epoch 95: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 1.6777e-04\n",
      "Epoch 96/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 96: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 1.6777e-04\n",
      "Epoch 97/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0119 - mae: 0.0119\n",
      "Epoch 97: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0229 - val_mae: 0.0229 - learning_rate: 1.6777e-04\n",
      "Epoch 98/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 98: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 1.6777e-04\n",
      "Epoch 99/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 99: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 1.3422e-04\n",
      "Epoch 100/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 100: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0233 - val_mae: 0.0233 - learning_rate: 1.3422e-04\n",
      "Epoch 101/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 101: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 1.3422e-04\n",
      "Epoch 102/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 102: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 1.3422e-04\n",
      "Epoch 103/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 103: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0230 - val_mae: 0.0230 - learning_rate: 1.3422e-04\n",
      "Epoch 104/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 104: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 1.3422e-04\n",
      "Epoch 105/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0119 - mae: 0.0119\n",
      "Epoch 105: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0229 - val_mae: 0.0229 - learning_rate: 1.3422e-04\n",
      "Epoch 106/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 106: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0232 - val_mae: 0.0232 - learning_rate: 1.3422e-04\n",
      "Epoch 107/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0119\n",
      "Epoch 107: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0233 - val_mae: 0.0233 - learning_rate: 1.3422e-04\n",
      "Epoch 108/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 108: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 108: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 1.3422e-04\n",
      "Epoch 109/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 109: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 1.0737e-04\n",
      "Epoch 110/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 110: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 1.0737e-04\n",
      "Epoch 111/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 111: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0233 - val_mae: 0.0233 - learning_rate: 1.0737e-04\n",
      "Epoch 112/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 112: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 1.0737e-04\n",
      "Epoch 113/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 113: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 1.0737e-04\n",
      "Epoch 114/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0117 - mae: 0.0117\n",
      "Epoch 114: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 1.0737e-04\n",
      "Epoch 115/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 115: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0233 - val_mae: 0.0233 - learning_rate: 1.0737e-04\n",
      "Epoch 116/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0119 - mae: 0.0119\n",
      "Epoch 116: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 1.0737e-04\n",
      "Epoch 117/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 117: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 1.0737e-04\n",
      "Epoch 118/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 118: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 118: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0236 - val_mae: 0.0236 - learning_rate: 1.0737e-04\n",
      "Epoch 119/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 119: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0236 - val_mae: 0.0236 - learning_rate: 8.5899e-05\n",
      "Epoch 120/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 120: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0236 - val_mae: 0.0236 - learning_rate: 8.5899e-05\n",
      "Epoch 121/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 121: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 8.5899e-05\n",
      "Epoch 122/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 122: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 8.5899e-05\n",
      "Epoch 123/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 123: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 8.5899e-05\n",
      "Epoch 124/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 124: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 8.5899e-05\n",
      "Epoch 125/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0119 - mae: 0.0119\n",
      "Epoch 125: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0236 - val_mae: 0.0236 - learning_rate: 8.5899e-05\n",
      "Epoch 126/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 126: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 8.5899e-05\n",
      "Epoch 127/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0119\n",
      "Epoch 127: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 8.5899e-05\n",
      "Epoch 128/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0117\n",
      "Epoch 128: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 128: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 8.5899e-05\n",
      "Epoch 129/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0119\n",
      "Epoch 129: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0236 - val_mae: 0.0236 - learning_rate: 6.8719e-05\n",
      "Epoch 130/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0117\n",
      "Epoch 130: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 6.8719e-05\n",
      "Epoch 131/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0119\n",
      "Epoch 131: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 6.8719e-05\n",
      "Epoch 132/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 132: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 6.8719e-05\n",
      "Epoch 133/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 133: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 6.8719e-05\n",
      "Epoch 134/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0117 - mae: 0.0117\n",
      "Epoch 134: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0233 - val_mae: 0.0233 - learning_rate: 6.8719e-05\n",
      "Epoch 135/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 135: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0236 - val_mae: 0.0236 - learning_rate: 6.8719e-05\n",
      "Epoch 136/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 136: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 6.8719e-05\n",
      "Epoch 137/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0119 - mae: 0.0119\n",
      "Epoch 137: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0236 - val_mae: 0.0236 - learning_rate: 6.8719e-05\n",
      "Epoch 138/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 138: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "\n",
      "Epoch 138: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 6.8719e-05\n",
      "Epoch 139/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0119 - mae: 0.0119\n",
      "Epoch 139: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 5.4976e-05\n",
      "Epoch 140/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 140: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 5.4976e-05\n",
      "Epoch 141/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0117 - mae: 0.0117\n",
      "Epoch 141: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 5.4976e-05\n",
      "Epoch 142/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0119 - mae: 0.0119\n",
      "Epoch 142: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 5.4976e-05\n",
      "Epoch 143/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 143: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 5.4976e-05\n",
      "Epoch 144/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 144: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0236 - val_mae: 0.0236 - learning_rate: 5.4976e-05\n",
      "Epoch 145/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0117 - mae: 0.0117\n",
      "Epoch 145: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0236 - val_mae: 0.0236 - learning_rate: 5.4976e-05\n",
      "Epoch 146/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 146: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 5.4976e-05\n",
      "Epoch 147/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 147: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 5.4976e-05\n",
      "Epoch 148/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0117 - mae: 0.0117\n",
      "Epoch 148: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "\n",
      "Epoch 148: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0236 - val_mae: 0.0236 - learning_rate: 5.4976e-05\n",
      "Epoch 149/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0118\n",
      "Epoch 149: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0236 - val_mae: 0.0236 - learning_rate: 4.3980e-05\n",
      "Epoch 150/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0116\n",
      "Epoch 150: val_mae did not improve from 0.01591\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 4.3980e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mae', 'val_loss', 'val_mae', 'learning_rate'])\n",
      "✅ Loaded saved model from: best_model_12_2.h5\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "📊 Evaluation Metrics:\n",
      "MAE:  0.6331\n",
      "RMSE: 1.0395\n",
      "MAPE: 25.97%\n",
      "\n",
      "🔁 Training with lookback=12, horizon=6\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janav\\.pyenv\\pyenv-win\\versions\\3.10.6\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0565 - mae: 0.0565\n",
      "Epoch 1: val_mae improved from inf to 0.02947, saving model to best_model_12_6.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0563 - mae: 0.0563 - val_loss: 0.0295 - val_mae: 0.0295 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0304 - mae: 0.0304\n",
      "Epoch 2: val_mae improved from 0.02947 to 0.02721, saving model to best_model_12_6.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0304 - mae: 0.0304 - val_loss: 0.0272 - val_mae: 0.0272 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0279 - mae: 0.0279\n",
      "Epoch 3: val_mae improved from 0.02721 to 0.02592, saving model to best_model_12_6.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0279 - mae: 0.0279 - val_loss: 0.0259 - val_mae: 0.0259 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0265 - mae: 0.0265\n",
      "Epoch 4: val_mae improved from 0.02592 to 0.02541, saving model to best_model_12_6.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0265 - mae: 0.0265 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0260 - mae: 0.0260\n",
      "Epoch 5: val_mae improved from 0.02541 to 0.02478, saving model to best_model_12_6.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0260 - mae: 0.0260 - val_loss: 0.0248 - val_mae: 0.0248 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0247 - mae: 0.0247\n",
      "Epoch 6: val_mae improved from 0.02478 to 0.02447, saving model to best_model_12_6.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0247 - mae: 0.0247 - val_loss: 0.0245 - val_mae: 0.0245 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0237 - mae: 0.0237\n",
      "Epoch 7: val_mae improved from 0.02447 to 0.02340, saving model to best_model_12_6.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0237 - mae: 0.0237 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0231 - mae: 0.0231\n",
      "Epoch 8: val_mae did not improve from 0.02340\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0231 - mae: 0.0231 - val_loss: 0.0239 - val_mae: 0.0239 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0226 - mae: 0.0226\n",
      "Epoch 9: val_mae did not improve from 0.02340\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0226 - mae: 0.0226 - val_loss: 0.0236 - val_mae: 0.0236 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0221 - mae: 0.0221\n",
      "Epoch 10: val_mae did not improve from 0.02340\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0221 - mae: 0.0221 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0218 - mae: 0.0218\n",
      "Epoch 11: val_mae did not improve from 0.02340\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0218 - mae: 0.0218 - val_loss: 0.0238 - val_mae: 0.0238 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0217 - mae: 0.0217\n",
      "Epoch 12: val_mae did not improve from 0.02340\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0217 - mae: 0.0217 - val_loss: 0.0242 - val_mae: 0.0242 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0213 - mae: 0.0213\n",
      "Epoch 13: val_mae did not improve from 0.02340\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0213 - mae: 0.0213 - val_loss: 0.0243 - val_mae: 0.0243 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0215 - mae: 0.0215\n",
      "Epoch 14: val_mae improved from 0.02340 to 0.02322, saving model to best_model_12_6.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0215 - mae: 0.0215 - val_loss: 0.0232 - val_mae: 0.0232 - learning_rate: 0.0010\n",
      "Epoch 15/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0210 - mae: 0.0210\n",
      "Epoch 15: val_mae improved from 0.02322 to 0.02310, saving model to best_model_12_6.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0210 - mae: 0.0210 - val_loss: 0.0231 - val_mae: 0.0231 - learning_rate: 0.0010\n",
      "Epoch 16/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0212 - mae: 0.0212\n",
      "Epoch 16: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0212 - mae: 0.0212 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 0.0010\n",
      "Epoch 17/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0208 - mae: 0.0208\n",
      "Epoch 17: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0208 - mae: 0.0208 - val_loss: 0.0242 - val_mae: 0.0242 - learning_rate: 0.0010\n",
      "Epoch 18/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0207 - mae: 0.0207\n",
      "Epoch 18: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0207 - mae: 0.0207 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 0.0010\n",
      "Epoch 19/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0205 - mae: 0.0205\n",
      "Epoch 19: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0205 - mae: 0.0205 - val_loss: 0.0247 - val_mae: 0.0247 - learning_rate: 0.0010\n",
      "Epoch 20/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0206 - mae: 0.0206\n",
      "Epoch 20: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0206 - mae: 0.0206 - val_loss: 0.0234 - val_mae: 0.0234 - learning_rate: 0.0010\n",
      "Epoch 21/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0202 - mae: 0.0202\n",
      "Epoch 21: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0202 - mae: 0.0202 - val_loss: 0.0249 - val_mae: 0.0249 - learning_rate: 0.0010\n",
      "Epoch 22/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0202 - mae: 0.0202\n",
      "Epoch 22: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0202 - mae: 0.0202 - val_loss: 0.0237 - val_mae: 0.0237 - learning_rate: 0.0010\n",
      "Epoch 23/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0203 - mae: 0.0203\n",
      "Epoch 23: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0203 - mae: 0.0203 - val_loss: 0.0240 - val_mae: 0.0240 - learning_rate: 0.0010\n",
      "Epoch 24/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0202 - mae: 0.0202\n",
      "Epoch 24: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0202 - mae: 0.0202 - val_loss: 0.0246 - val_mae: 0.0246 - learning_rate: 0.0010\n",
      "Epoch 25/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0201 - mae: 0.0201\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 25: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0201 - mae: 0.0201 - val_loss: 0.0246 - val_mae: 0.0246 - learning_rate: 0.0010\n",
      "Epoch 26/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0197 - mae: 0.0197\n",
      "Epoch 26: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0197 - mae: 0.0197 - val_loss: 0.0246 - val_mae: 0.0246 - learning_rate: 8.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0199 - mae: 0.0199\n",
      "Epoch 27: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0199 - mae: 0.0199 - val_loss: 0.0243 - val_mae: 0.0243 - learning_rate: 8.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0194 - mae: 0.0194\n",
      "Epoch 28: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0243 - val_mae: 0.0243 - learning_rate: 8.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0197 - mae: 0.0197\n",
      "Epoch 29: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0197 - mae: 0.0197 - val_loss: 0.0248 - val_mae: 0.0248 - learning_rate: 8.0000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0193 - mae: 0.0193\n",
      "Epoch 30: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0248 - val_mae: 0.0248 - learning_rate: 8.0000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0195 - mae: 0.0195\n",
      "Epoch 31: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0195 - mae: 0.0195 - val_loss: 0.0247 - val_mae: 0.0247 - learning_rate: 8.0000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0195 - mae: 0.0195\n",
      "Epoch 32: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0195 - mae: 0.0195 - val_loss: 0.0247 - val_mae: 0.0247 - learning_rate: 8.0000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0194 - mae: 0.0194\n",
      "Epoch 33: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 8.0000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0196 - mae: 0.0196\n",
      "Epoch 34: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0196 - mae: 0.0196 - val_loss: 0.0253 - val_mae: 0.0253 - learning_rate: 8.0000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0193 - mae: 0.0193\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 35: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0253 - val_mae: 0.0253 - learning_rate: 8.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0194 - mae: 0.0194\n",
      "Epoch 36: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 6.4000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0190 - mae: 0.0190\n",
      "Epoch 37: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0250 - val_mae: 0.0250 - learning_rate: 6.4000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0191 - mae: 0.0191\n",
      "Epoch 38: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0191 - mae: 0.0191 - val_loss: 0.0255 - val_mae: 0.0255 - learning_rate: 6.4000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0191 - mae: 0.0191\n",
      "Epoch 39: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0191 - mae: 0.0191 - val_loss: 0.0256 - val_mae: 0.0256 - learning_rate: 6.4000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0188\n",
      "Epoch 40: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0253 - val_mae: 0.0253 - learning_rate: 6.4000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0188\n",
      "Epoch 41: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0256 - val_mae: 0.0256 - learning_rate: 6.4000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0186 - mae: 0.0186\n",
      "Epoch 42: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0261 - val_mae: 0.0261 - learning_rate: 6.4000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0190 - mae: 0.0190\n",
      "Epoch 43: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0258 - val_mae: 0.0258 - learning_rate: 6.4000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0189 - mae: 0.0189\n",
      "Epoch 44: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0255 - val_mae: 0.0255 - learning_rate: 6.4000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0186 - mae: 0.0186\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 45: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0257 - val_mae: 0.0257 - learning_rate: 6.4000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0188\n",
      "Epoch 46: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0258 - val_mae: 0.0258 - learning_rate: 5.1200e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0186 - mae: 0.0186\n",
      "Epoch 47: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0256 - val_mae: 0.0256 - learning_rate: 5.1200e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0186 - mae: 0.0186\n",
      "Epoch 48: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 5.1200e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0186 - mae: 0.0186\n",
      "Epoch 49: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0257 - val_mae: 0.0257 - learning_rate: 5.1200e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0184 - mae: 0.0184\n",
      "Epoch 50: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0262 - val_mae: 0.0262 - learning_rate: 5.1200e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0185 - mae: 0.0185\n",
      "Epoch 51: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0251 - val_mae: 0.0251 - learning_rate: 5.1200e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0185 - mae: 0.0185\n",
      "Epoch 52: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0263 - val_mae: 0.0263 - learning_rate: 5.1200e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0184 - mae: 0.0184\n",
      "Epoch 53: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0260 - val_mae: 0.0260 - learning_rate: 5.1200e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0183 - mae: 0.0183\n",
      "Epoch 54: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0253 - val_mae: 0.0253 - learning_rate: 5.1200e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0186 - mae: 0.0186\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 55: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0262 - val_mae: 0.0262 - learning_rate: 5.1200e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0184 - mae: 0.0184\n",
      "Epoch 56: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0259 - val_mae: 0.0259 - learning_rate: 4.0960e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0182 - mae: 0.0182\n",
      "Epoch 57: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0260 - val_mae: 0.0260 - learning_rate: 4.0960e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0182 - mae: 0.0182\n",
      "Epoch 58: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0264 - val_mae: 0.0264 - learning_rate: 4.0960e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0183 - mae: 0.0183\n",
      "Epoch 59: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0257 - val_mae: 0.0257 - learning_rate: 4.0960e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0182 - mae: 0.0182\n",
      "Epoch 60: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0254 - val_mae: 0.0254 - learning_rate: 4.0960e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0183 - mae: 0.0183\n",
      "Epoch 61: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0261 - val_mae: 0.0261 - learning_rate: 4.0960e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0183 - mae: 0.0183\n",
      "Epoch 62: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0264 - val_mae: 0.0264 - learning_rate: 4.0960e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0183 - mae: 0.0183\n",
      "Epoch 63: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0259 - val_mae: 0.0259 - learning_rate: 4.0960e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0183 - mae: 0.0183\n",
      "Epoch 64: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0256 - val_mae: 0.0256 - learning_rate: 4.0960e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0186 - mae: 0.0186\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 65: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0262 - val_mae: 0.0262 - learning_rate: 4.0960e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0182 - mae: 0.0182\n",
      "Epoch 66: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0252 - val_mae: 0.0252 - learning_rate: 3.2768e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0179 - mae: 0.0179\n",
      "Epoch 67: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0261 - val_mae: 0.0261 - learning_rate: 3.2768e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0181 - mae: 0.0181\n",
      "Epoch 68: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0260 - val_mae: 0.0260 - learning_rate: 3.2768e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0180 - mae: 0.0180\n",
      "Epoch 69: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0263 - val_mae: 0.0263 - learning_rate: 3.2768e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0179 - mae: 0.0179\n",
      "Epoch 70: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0255 - val_mae: 0.0255 - learning_rate: 3.2768e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0179 - mae: 0.0179\n",
      "Epoch 71: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0265 - val_mae: 0.0265 - learning_rate: 3.2768e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0180 - mae: 0.0180\n",
      "Epoch 72: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0263 - val_mae: 0.0263 - learning_rate: 3.2768e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0179 - mae: 0.0179\n",
      "Epoch 73: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0264 - val_mae: 0.0264 - learning_rate: 3.2768e-04\n",
      "Epoch 74/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0178 - mae: 0.0178\n",
      "Epoch 74: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0262 - val_mae: 0.0262 - learning_rate: 3.2768e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0180 - mae: 0.0180\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 75: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0261 - val_mae: 0.0261 - learning_rate: 3.2768e-04\n",
      "Epoch 76/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0177 - mae: 0.0177\n",
      "Epoch 76: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0263 - val_mae: 0.0263 - learning_rate: 2.6214e-04\n",
      "Epoch 77/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0180 - mae: 0.0180\n",
      "Epoch 77: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0262 - val_mae: 0.0262 - learning_rate: 2.6214e-04\n",
      "Epoch 78/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0181 - mae: 0.0181\n",
      "Epoch 78: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0258 - val_mae: 0.0258 - learning_rate: 2.6214e-04\n",
      "Epoch 79/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - mae: 0.0180\n",
      "Epoch 79: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0266 - val_mae: 0.0266 - learning_rate: 2.6214e-04\n",
      "Epoch 80/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - mae: 0.0180\n",
      "Epoch 80: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0265 - val_mae: 0.0265 - learning_rate: 2.6214e-04\n",
      "Epoch 81/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0179 - mae: 0.0179\n",
      "Epoch 81: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0255 - val_mae: 0.0255 - learning_rate: 2.6214e-04\n",
      "Epoch 82/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0181 - mae: 0.0181\n",
      "Epoch 82: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0261 - val_mae: 0.0261 - learning_rate: 2.6214e-04\n",
      "Epoch 83/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0179 - mae: 0.0179\n",
      "Epoch 83: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0259 - val_mae: 0.0259 - learning_rate: 2.6214e-04\n",
      "Epoch 84/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0178 - mae: 0.0178\n",
      "Epoch 84: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0265 - val_mae: 0.0265 - learning_rate: 2.6214e-04\n",
      "Epoch 85/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0177 - mae: 0.0177\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 85: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0263 - val_mae: 0.0263 - learning_rate: 2.6214e-04\n",
      "Epoch 86/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0176 - mae: 0.0176\n",
      "Epoch 86: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0259 - val_mae: 0.0259 - learning_rate: 2.0972e-04\n",
      "Epoch 87/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - mae: 0.0176\n",
      "Epoch 87: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0262 - val_mae: 0.0262 - learning_rate: 2.0972e-04\n",
      "Epoch 88/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0179 - mae: 0.0179\n",
      "Epoch 88: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0264 - val_mae: 0.0264 - learning_rate: 2.0972e-04\n",
      "Epoch 89/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0179 - mae: 0.0179\n",
      "Epoch 89: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0267 - val_mae: 0.0267 - learning_rate: 2.0972e-04\n",
      "Epoch 90/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - mae: 0.0179\n",
      "Epoch 90: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0260 - val_mae: 0.0260 - learning_rate: 2.0972e-04\n",
      "Epoch 91/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - mae: 0.0177\n",
      "Epoch 91: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0263 - val_mae: 0.0263 - learning_rate: 2.0972e-04\n",
      "Epoch 92/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - mae: 0.0177\n",
      "Epoch 92: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0263 - val_mae: 0.0263 - learning_rate: 2.0972e-04\n",
      "Epoch 93/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0178 - mae: 0.0178\n",
      "Epoch 93: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0258 - val_mae: 0.0258 - learning_rate: 2.0972e-04\n",
      "Epoch 94/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0177 - mae: 0.0177\n",
      "Epoch 94: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0259 - val_mae: 0.0259 - learning_rate: 2.0972e-04\n",
      "Epoch 95/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0178 - mae: 0.0178\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 95: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0265 - val_mae: 0.0265 - learning_rate: 2.0972e-04\n",
      "Epoch 96/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0179 - mae: 0.0179\n",
      "Epoch 96: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0259 - val_mae: 0.0259 - learning_rate: 1.6777e-04\n",
      "Epoch 97/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - mae: 0.0176\n",
      "Epoch 97: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0261 - val_mae: 0.0261 - learning_rate: 1.6777e-04\n",
      "Epoch 98/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0176 - mae: 0.0176\n",
      "Epoch 98: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0260 - val_mae: 0.0260 - learning_rate: 1.6777e-04\n",
      "Epoch 99/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0179 - mae: 0.0179\n",
      "Epoch 99: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0262 - val_mae: 0.0262 - learning_rate: 1.6777e-04\n",
      "Epoch 100/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0176 - mae: 0.0176\n",
      "Epoch 100: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0264 - val_mae: 0.0264 - learning_rate: 1.6777e-04\n",
      "Epoch 101/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0175 - mae: 0.0175\n",
      "Epoch 101: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0268 - val_mae: 0.0268 - learning_rate: 1.6777e-04\n",
      "Epoch 102/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0176 - mae: 0.0176\n",
      "Epoch 102: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0263 - val_mae: 0.0263 - learning_rate: 1.6777e-04\n",
      "Epoch 103/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0175 - mae: 0.0175\n",
      "Epoch 103: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0266 - val_mae: 0.0266 - learning_rate: 1.6777e-04\n",
      "Epoch 104/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0175 - mae: 0.0175\n",
      "Epoch 104: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0264 - val_mae: 0.0264 - learning_rate: 1.6777e-04\n",
      "Epoch 105/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0176 - mae: 0.0176\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 105: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0265 - val_mae: 0.0265 - learning_rate: 1.6777e-04\n",
      "Epoch 106/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0175 - mae: 0.0175\n",
      "Epoch 106: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0266 - val_mae: 0.0266 - learning_rate: 1.3422e-04\n",
      "Epoch 107/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0178 - mae: 0.0178\n",
      "Epoch 107: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0265 - val_mae: 0.0265 - learning_rate: 1.3422e-04\n",
      "Epoch 108/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0176 - mae: 0.0176\n",
      "Epoch 108: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0261 - val_mae: 0.0261 - learning_rate: 1.3422e-04\n",
      "Epoch 109/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0176 - mae: 0.0176\n",
      "Epoch 109: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0259 - val_mae: 0.0259 - learning_rate: 1.3422e-04\n",
      "Epoch 110/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0176 - mae: 0.0176\n",
      "Epoch 110: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0263 - val_mae: 0.0263 - learning_rate: 1.3422e-04\n",
      "Epoch 111/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0175 - mae: 0.0175\n",
      "Epoch 111: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0262 - val_mae: 0.0262 - learning_rate: 1.3422e-04\n",
      "Epoch 112/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - mae: 0.0174\n",
      "Epoch 112: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0264 - val_mae: 0.0264 - learning_rate: 1.3422e-04\n",
      "Epoch 113/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - mae: 0.0177\n",
      "Epoch 113: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0263 - val_mae: 0.0263 - learning_rate: 1.3422e-04\n",
      "Epoch 114/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - mae: 0.0177\n",
      "Epoch 114: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0265 - val_mae: 0.0265 - learning_rate: 1.3422e-04\n",
      "Epoch 115/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0172 - mae: 0.0172\n",
      "Epoch 115: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 115: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0267 - val_mae: 0.0267 - learning_rate: 1.3422e-04\n",
      "Epoch 116/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0174 - mae: 0.0174\n",
      "Epoch 116: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0263 - val_mae: 0.0263 - learning_rate: 1.0737e-04\n",
      "Epoch 117/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - mae: 0.0174\n",
      "Epoch 117: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0264 - val_mae: 0.0264 - learning_rate: 1.0737e-04\n",
      "Epoch 118/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0173 - mae: 0.0173\n",
      "Epoch 118: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0264 - val_mae: 0.0264 - learning_rate: 1.0737e-04\n",
      "Epoch 119/150\n",
      "\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - mae: 0.0176\n",
      "Epoch 119: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0267 - val_mae: 0.0267 - learning_rate: 1.0737e-04\n",
      "Epoch 120/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0175 - mae: 0.0175\n",
      "Epoch 120: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0261 - val_mae: 0.0261 - learning_rate: 1.0737e-04\n",
      "Epoch 121/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0171 - mae: 0.0171\n",
      "Epoch 121: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0265 - val_mae: 0.0265 - learning_rate: 1.0737e-04\n",
      "Epoch 122/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0175 - mae: 0.0175\n",
      "Epoch 122: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0262 - val_mae: 0.0262 - learning_rate: 1.0737e-04\n",
      "Epoch 123/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - mae: 0.0174\n",
      "Epoch 123: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0264 - val_mae: 0.0264 - learning_rate: 1.0737e-04\n",
      "Epoch 124/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0173 - mae: 0.0173\n",
      "Epoch 124: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0264 - val_mae: 0.0264 - learning_rate: 1.0737e-04\n",
      "Epoch 125/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0174 - mae: 0.0174\n",
      "Epoch 125: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 125: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0262 - val_mae: 0.0262 - learning_rate: 1.0737e-04\n",
      "Epoch 126/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0174 - mae: 0.0174\n",
      "Epoch 126: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0265 - val_mae: 0.0265 - learning_rate: 8.5899e-05\n",
      "Epoch 127/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0174 - mae: 0.0174\n",
      "Epoch 127: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0265 - val_mae: 0.0265 - learning_rate: 8.5899e-05\n",
      "Epoch 128/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - mae: 0.0172\n",
      "Epoch 128: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0263 - val_mae: 0.0263 - learning_rate: 8.5899e-05\n",
      "Epoch 129/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - mae: 0.0174\n",
      "Epoch 129: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0267 - val_mae: 0.0267 - learning_rate: 8.5899e-05\n",
      "Epoch 130/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0174 - mae: 0.0174\n",
      "Epoch 130: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0264 - val_mae: 0.0264 - learning_rate: 8.5899e-05\n",
      "Epoch 131/150\n",
      "\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - mae: 0.0174\n",
      "Epoch 131: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0262 - val_mae: 0.0262 - learning_rate: 8.5899e-05\n",
      "Epoch 132/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - mae: 0.0174\n",
      "Epoch 132: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0262 - val_mae: 0.0262 - learning_rate: 8.5899e-05\n",
      "Epoch 133/150\n",
      "\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0177 - mae: 0.0177\n",
      "Epoch 133: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0260 - val_mae: 0.0260 - learning_rate: 8.5899e-05\n",
      "Epoch 134/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0174 - mae: 0.0174\n",
      "Epoch 134: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0264 - val_mae: 0.0264 - learning_rate: 8.5899e-05\n",
      "Epoch 135/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0173 - mae: 0.0173\n",
      "Epoch 135: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 135: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0262 - val_mae: 0.0262 - learning_rate: 8.5899e-05\n",
      "Epoch 136/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0172 - mae: 0.0172\n",
      "Epoch 136: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0267 - val_mae: 0.0267 - learning_rate: 6.8719e-05\n",
      "Epoch 137/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0175 - mae: 0.0175\n",
      "Epoch 137: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0264 - val_mae: 0.0264 - learning_rate: 6.8719e-05\n",
      "Epoch 138/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0173 - mae: 0.0173\n",
      "Epoch 138: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0265 - val_mae: 0.0265 - learning_rate: 6.8719e-05\n",
      "Epoch 139/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0174 - mae: 0.0174\n",
      "Epoch 139: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0264 - val_mae: 0.0264 - learning_rate: 6.8719e-05\n",
      "Epoch 140/150\n",
      "\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0173 - mae: 0.0173\n",
      "Epoch 140: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0263 - val_mae: 0.0263 - learning_rate: 6.8719e-05\n",
      "Epoch 141/150\n",
      "\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0173 - mae: 0.0173\n",
      "Epoch 141: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0263 - val_mae: 0.0263 - learning_rate: 6.8719e-05\n",
      "Epoch 142/150\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0172 - mae: 0.0172\n",
      "Epoch 142: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0264 - val_mae: 0.0264 - learning_rate: 6.8719e-05\n",
      "Epoch 143/150\n",
      "\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0174 - mae: 0.0174\n",
      "Epoch 143: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0267 - val_mae: 0.0267 - learning_rate: 6.8719e-05\n",
      "Epoch 144/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0175 - mae: 0.0175\n",
      "Epoch 144: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0264 - val_mae: 0.0264 - learning_rate: 6.8719e-05\n",
      "Epoch 145/150\n",
      "\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0174 - mae: 0.0174\n",
      "Epoch 145: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "\n",
      "Epoch 145: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0265 - val_mae: 0.0265 - learning_rate: 6.8719e-05\n",
      "Epoch 146/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0173 - mae: 0.0173\n",
      "Epoch 146: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0265 - val_mae: 0.0265 - learning_rate: 5.4976e-05\n",
      "Epoch 147/150\n",
      "\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0170 - mae: 0.0170\n",
      "Epoch 147: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0265 - val_mae: 0.0265 - learning_rate: 5.4976e-05\n",
      "Epoch 148/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0175 - mae: 0.0175\n",
      "Epoch 148: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0266 - val_mae: 0.0266 - learning_rate: 5.4976e-05\n",
      "Epoch 149/150\n",
      "\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0172 - mae: 0.0172\n",
      "Epoch 149: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0264 - val_mae: 0.0264 - learning_rate: 5.4976e-05\n",
      "Epoch 150/150\n",
      "\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0172 - mae: 0.0172\n",
      "Epoch 150: val_mae did not improve from 0.02310\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0264 - val_mae: 0.0264 - learning_rate: 5.4976e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mae', 'val_loss', 'val_mae', 'learning_rate'])\n",
      "✅ Loaded saved model from: best_model_12_6.h5\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "📊 Evaluation Metrics:\n",
      "MAE:  0.9104\n",
      "RMSE: 1.4310\n",
      "MAPE: 36.88%\n",
      "\n",
      "✅ Final Results:\n",
      "   lookback  lookahead       mae      rmse       mape\n",
      "0         2          1  0.527333  0.905622  22.382654\n",
      "1         2          2  0.612271  1.052628  26.539233\n",
      "2         2          6  0.875939  1.412999  36.997665\n",
      "3         6          1  0.473922  0.816099  21.056187\n",
      "4         6          2  0.641234  1.051489  26.998993\n",
      "5         6          6  0.876572  1.402155  37.825529\n",
      "6        12          1  0.545471  0.889349  23.492209\n",
      "7        12          2  0.633103  1.039474  25.970486\n",
      "8        12          6  0.910429  1.430973  36.882742\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "import os \n",
    "\n",
    "results = []\n",
    "\n",
    "timesteps_list = [2, 6, 12]\n",
    "horizon_list = [1, 2, 6]\n",
    "\n",
    "for input_window in timesteps_list:\n",
    "    for forecast_horizon in horizon_list:\n",
    "        print(f\"\\n🔁 Training with lookback={input_window}, horizon={forecast_horizon}\")\n",
    "        try:\n",
    "            # Prepare sequences\n",
    "            X_train, y_train, X_val, y_val, X_test, y_test, scaler = prepare_sequences(\n",
    "                df, input_window=input_window, forecast_horizon=forecast_horizon,\n",
    "                val_ratio=0.2, test_ratio=0.1\n",
    "            )\n",
    "\n",
    "            # Build model\n",
    "            model = build_cnn_lstm_model(\n",
    "                input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "                output_size=y_train.shape[1]\n",
    "            )\n",
    "\n",
    "            model_path = f\"best_model_{input_window}_{forecast_horizon}.h5\"\n",
    "\n",
    "            # Train and save the best model\n",
    "            model, history = train_model(model, X_train, y_train, X_val, y_val, model_path=model_path)\n",
    "\n",
    "            # Try to load the best saved model; fallback to last epoch model if not saved\n",
    "            if os.path.exists(model_path):\n",
    "                print(f\"✅ Loaded saved model from: {model_path}\")\n",
    "                best_model = load_model(model_path)\n",
    "            else:\n",
    "                print(f\"⚠️ No saved model found for {input_window}-{forecast_horizon}. Using model from last epoch.\")\n",
    "                best_model = model\n",
    "\n",
    "            # Evaluate loaded model\n",
    "            metrics = evaluate_forecasting_model(best_model, X_test, y_test, scaler)\n",
    "\n",
    "            # Save results\n",
    "            results.append({\n",
    "                \"lookback\": input_window,\n",
    "                \"lookahead\": forecast_horizon,\n",
    "                \"mae\": metrics[\"mae\"],\n",
    "                \"rmse\": metrics[\"rmse\"],\n",
    "                \"mape\": metrics[\"mape\"]\n",
    "            })\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed for lookback={input_window}, horizon={forecast_horizon}: {e}\")\n",
    "            results.append({\n",
    "                \"lookback\": input_window,\n",
    "                \"lookahead\": forecast_horizon,\n",
    "                \"mae\": None,\n",
    "                \"rmse\": None,\n",
    "                \"mape\": None\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n✅ Final Results:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34fccbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
